{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Samuel Middleton <br>\n",
    "Email: samuelmiddleton93@gmail.com <br>\n",
    "Project: Bot Generated Review Detection using BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Consumer-Trust\" data-toc-modified-id=\"Consumer-Trust-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Consumer Trust</a></span><ul class=\"toc-item\"><li><span><a href=\"#The-Issue-with-Online-Reviews\" data-toc-modified-id=\"The-Issue-with-Online-Reviews-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>The Issue with Online Reviews</a></span></li><li><span><a href=\"#The-Solution\" data-toc-modified-id=\"The-Solution-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>The Solution</a></span></li></ul></li><li><span><a href=\"#Importations\" data-toc-modified-id=\"Importations-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Importations</a></span></li><li><span><a href=\"#Helper-Functions\" data-toc-modified-id=\"Helper-Functions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Helper Functions</a></span></li><li><span><a href=\"#Data-prep\" data-toc-modified-id=\"Data-prep-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Data prep</a></span></li><li><span><a href=\"#Model-Prep\" data-toc-modified-id=\"Model-Prep-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Model Prep</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-test-split\" data-toc-modified-id=\"Train-test-split-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Train-test split</a></span></li><li><span><a href=\"#Model-and-tokenizer-assignment\" data-toc-modified-id=\"Model-and-tokenizer-assignment-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Model and tokenizer assignment</a></span></li><li><span><a href=\"#Bidirectional-Encoder-Representations-from-Transformers-(BERT)--Model\" data-toc-modified-id=\"Bidirectional-Encoder-Representations-from-Transformers-(BERT)--Model-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Bidirectional Encoder Representations from Transformers (BERT)  Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Transformers\" data-toc-modified-id=\"Transformers-5.3.1\"><span class=\"toc-item-num\">5.3.1&nbsp;&nbsp;</span>Transformers</a></span></li><li><span><a href=\"#BERT-Mechanics\" data-toc-modified-id=\"BERT-Mechanics-5.3.2\"><span class=\"toc-item-num\">5.3.2&nbsp;&nbsp;</span>BERT Mechanics</a></span></li><li><span><a href=\"#BERT-Metrics\" data-toc-modified-id=\"BERT-Metrics-5.3.3\"><span class=\"toc-item-num\">5.3.3&nbsp;&nbsp;</span>BERT Metrics</a></span></li></ul></li><li><span><a href=\"#Length-Analysis\" data-toc-modified-id=\"Length-Analysis-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Length Analysis</a></span></li><li><span><a href=\"#Tokenization\" data-toc-modified-id=\"Tokenization-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Tokenization</a></span></li></ul></li><li><span><a href=\"#Dataloaders\" data-toc-modified-id=\"Dataloaders-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Dataloaders</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#PyTorch-Dataloader\" data-toc-modified-id=\"PyTorch-Dataloader-6.0.1\"><span class=\"toc-item-num\">6.0.1&nbsp;&nbsp;</span>PyTorch Dataloader</a></span></li></ul></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Model-Architecture\" data-toc-modified-id=\"Model-Architecture-7.0.1\"><span class=\"toc-item-num\">7.0.1&nbsp;&nbsp;</span>Model Architecture</a></span></li></ul></li><li><span><a href=\"#Hyperparameters\" data-toc-modified-id=\"Hyperparameters-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Hyperparameters</a></span><ul class=\"toc-item\"><li><span><a href=\"#AdamW\" data-toc-modified-id=\"AdamW-7.1.1\"><span class=\"toc-item-num\">7.1.1&nbsp;&nbsp;</span>AdamW</a></span></li><li><span><a href=\"#Training-Epochs\" data-toc-modified-id=\"Training-Epochs-7.1.2\"><span class=\"toc-item-num\">7.1.2&nbsp;&nbsp;</span>Training Epochs</a></span></li></ul></li><li><span><a href=\"#Training-loop\" data-toc-modified-id=\"Training-loop-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Training loop</a></span></li></ul></li><li><span><a href=\"#Testing\" data-toc-modified-id=\"Testing-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Testing</a></span><ul class=\"toc-item\"><li><span><a href=\"#Saving\" data-toc-modified-id=\"Saving-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Saving</a></span></li></ul></li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Conclusion</a></span><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#1.-Transfer-Learning\" data-toc-modified-id=\"1.-Transfer-Learning-9.0.1\"><span class=\"toc-item-num\">9.0.1&nbsp;&nbsp;</span>1. Transfer Learning</a></span></li><li><span><a href=\"#2.-Training-Times\" data-toc-modified-id=\"2.-Training-Times-9.0.2\"><span class=\"toc-item-num\">9.0.2&nbsp;&nbsp;</span>2. Training Times</a></span></li><li><span><a href=\"#3.-Market-Backend-or-Customer-Frontend\" data-toc-modified-id=\"3.-Market-Backend-or-Customer-Frontend-9.0.3\"><span class=\"toc-item-num\">9.0.3&nbsp;&nbsp;</span>3. Market Backend or Customer Frontend</a></span></li></ul></li><li><span><a href=\"#Future-Work\" data-toc-modified-id=\"Future-Work-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Future Work</a></span><ul class=\"toc-item\"><li><span><a href=\"#1.-Deployment\" data-toc-modified-id=\"1.-Deployment-9.1.1\"><span class=\"toc-item-num\">9.1.1&nbsp;&nbsp;</span>1. Deployment</a></span></li><li><span><a href=\"#2.-Further-Tuning\" data-toc-modified-id=\"2.-Further-Tuning-9.1.2\"><span class=\"toc-item-num\">9.1.2&nbsp;&nbsp;</span>2. Further Tuning</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Consumer Trust"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important consumer metrics for shopping in general, but even more so for online shopping, is almost immeasurable. \n",
    "\n",
    "Trust is an invaluable tool that wielded correctly can build a platform, product, or service to must-have status in our *have-it-now* society. The flip side of that coin is that a single viral video can destroy your brand or product overnight. These are both exciting and scary prospects for any business that are facing them. The entire world is peer reviewed now and one of the ways that this is most obvious is through customer interaction via reviews. Customer reviews sell products. \n",
    "\n",
    "According to *Insider Intelligence*, a market leader in marketing and business insights: \n",
    "\n",
    "> In yet another sign that online reviews can make or break the path to purchase, June 2019 research from Trustpilot found that consumers would lose trust in a brand not only if they saw negative reviews—but also if the brand went one step further and deleted them.<br><br>\n",
    "For a majority **(95.0%)** of the digital shoppers surveyed worldwide, that type of behavior played a big role in their distrust of a company, as did not having any reviews at all **(cited by 81.0%)**.<br><br>\n",
    "**When asked what factors would lead to an increase in brand trust, three of the top 10 factors centered around reviews.** Nearly all respondents said positive customer reviews increased their trust in a brand, while 80.1% said they trusted companies that have a lot of customers reviews. Interestingly, if a company responded to negative customer comments, that would drive up trust for 79.9% of those surveyed.\n",
    "\n",
    "*(emphasis added)*\n",
    "\n",
    "![Review image](Images/consumer_trust.png)\n",
    "\n",
    "![Review image](Images/reviews_graph.png)\n",
    "\n",
    "<br><br>\n",
    "As the pandemic has further transitioned our economy into an online and digital economy these consumer reviews hold even more weight. We can see the rapid growth of online shopping visits in just the first half of 2020 in this chart on Statista:\n",
    "\n",
    "![Review image](Images/coronavirus_header.png)\n",
    "![Review image](Images/ronashopping.png)\n",
    "\n",
    "\n",
    "## The Issue with Online Reviews\n",
    "\n",
    "Online reviews are one of the many forms of semi-anonymous means of communication that are available on the internet. As we've seen with the numbers provided by TrustPilot and Insider Intelligence **95%** of individuals are influenced by a positive online reputation and **93%** are influenced by positive reviews. The inverse is also true with **95%** of respondents being influenced by negative reviews or comments. This system and influence can be greatly abused by our advancing technology.\n",
    "\n",
    "There is a dark side to the exponential advances in machine learning that we have seen in relation to things such as **Natural Language Processing (NLP)**. These techniques are being applied to the manipulation of customers. \n",
    "\n",
    "The [*Scientific American*](https://www.scientificamerican.com/article/could-ai-be-the-future-of-fake-news-and-product-reviews/) covered this in an article in late 2017:\n",
    "\n",
    "> When Hillary Clinton’s new book What Happened debuted on Amazon’s Web site last month, the response was incredible. So incredible, that of the 1,600 reviews posted on the book’s Amazon page in just a few hours, the company soon deleted 900 it suspected of being bogus: written by people who said they loved or hated the book, but had neither purchased nor likely even read it. Fake product reviews—prompted by payola or more nefarious motives—are nothing new, but they are set to become a bigger problem as tricksters find new ways of automating online misinformation campaigns launched to sway public opinion.\n",
    "\n",
    "Consider that 3 years in tech development is exponential as our research advances at an incredible pace these fake review generations have become easier and easier. Generating fake reviews, once the domain of University research labs, is now available to anyone with enough technical acumen and seed money to rent GPU power. It has become easier and easier to cheat the system, and while the opposition technology increases at a similar rate edge cases will always fall through the cracks.\n",
    "\n",
    "It isn't difficult to imagine a full pipeline of ML assisted tools that could be deployed from front to back to assist with anything from fake review generation to political twitter bots. \n",
    "\n",
    "- Simple web-interaction scripts to create bogus accounts and email addresses.\n",
    "- Use of open datasets to train cloud based ML solutions through one of the widely available frameworks. \n",
    "    1. Allows for flexible maintenance\n",
    "    2. Continual updates and improvement to maintain relevance\n",
    "    3. Easy distribution\n",
    "- Dashboard deployment for use of the product as a service (SaaS).\n",
    "\n",
    "## The Solution\n",
    "\n",
    "Fight fire with fire.\n",
    "\n",
    "Push has came to shove in this end-user manipulation fight. We can use the same tools that the black-hat users leverage to beat them at their own game. Fortune 500s are using their resources to combat this issue, but the nefarious users abusing these review systems are more agile in most cases. Large scale deployment and corporate-bureaucratic are slow processes that will always be behind the curve. It is important to employ a faster and more efficient method.\n",
    "\n",
    "This efficient method is using one of the robust and pre-trained models to base the foundation of our fake detection bots. Making use of deeply researched and efficiently trained models will allow for a quicker turnaround and a more fine-tuned approach to modeling."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-30T18:53:21.833396Z",
     "start_time": "2020-11-30T18:53:21.796396Z"
    }
   },
   "outputs": [],
   "source": [
    "# Standard visualization and data management libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "\n",
    "# Torch and Transformers libraries used\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast, AdamW, DistilBertConfig, DistilBertModel\n",
    "from transformers import DistilBertTokenizerFast\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "\n",
    "# Scikit Learn library selection\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Utility libraries\n",
    "import time\n",
    "import os\n",
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.174033Z",
     "start_time": "2020-11-27T21:01:43.171032Z"
    }
   },
   "outputs": [],
   "source": [
    "# Supress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.179034Z",
     "start_time": "2020-11-27T21:01:43.176034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Save model functionality \n",
    "save = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A small helper function that takes in a dataframe of text and returns only entries with under *N* tokens. (A token being a single word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.185036Z",
     "start_time": "2020-11-27T21:01:43.180036Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_over(df, leng = 512, target='reviews', labels='label'):\n",
    "    '''Checks text length for being over 512 tokens, \n",
    "    which bert-base does not support. Returns a dataframe of all\n",
    "    entries under 512 tokens.'''\n",
    "    seq_list = []\n",
    "    seq_len = [len(i.split()) for i in df[target]]\n",
    "    ugh = []\n",
    "    for x, y in enumerate(seq_len):\n",
    "        if y > leng:\n",
    "            ugh.append(x)\n",
    "            \n",
    "    df_tuple = zip(df[target], df[labels])\n",
    "    \n",
    "    for x, text in enumerate(df_tuple):\n",
    "        if x not in ugh:\n",
    "            seq_list.append(text)\n",
    "            \n",
    "    seq_df = pd.DataFrame(seq_list, columns=['reviews','label'])\n",
    "    \n",
    "    return seq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulling in our generated fake reviews and our saved real reviews. \n",
    "\n",
    "Fake reviews are generated by a **GPT2** text generator tuned with **50,000** Amazon book reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.662035Z",
     "start_time": "2020-11-27T21:01:43.186034Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41830</td>\n",
       "      <td>So enjoyable!!! If you are a fan of the serie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23419</td>\n",
       "      <td>This book brings together a lot of history an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>31825</td>\n",
       "      <td>Good work but I would have liked to see more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27356</td>\n",
       "      <td>(Im writing this review in the order it is re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9883</td>\n",
       "      <td>excelente libro de hyenuk, en uno poco, cono ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>10505</td>\n",
       "      <td>Russells Introduction is a page-turner, and i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>12747</td>\n",
       "      <td>Quick and easy ordering and shipping.  It arr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>48702</td>\n",
       "      <td>Im used to hearing about a series by John Gri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>7944</td>\n",
       "      <td>fun book. What a great ending for the series....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>18540</td>\n",
       "      <td>Just finished reading this.  I loved the char...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0                                            reviews  label\n",
       "0           41830   So enjoyable!!! If you are a fan of the serie...      1\n",
       "1           23419   This book brings together a lot of history an...      1\n",
       "2           31825   Good work but I would have liked to see more ...      1\n",
       "3           27356   (Im writing this review in the order it is re...      1\n",
       "4            9883   excelente libro de hyenuk, en uno poco, cono ...      1\n",
       "...           ...                                                ...    ...\n",
       "49995       10505   Russells Introduction is a page-turner, and i...      1\n",
       "49996       12747   Quick and easy ordering and shipping.  It arr...      1\n",
       "49997       48702   Im used to hearing about a series by John Gri...      1\n",
       "49998        7944   fun book. What a great ending for the series....      1\n",
       "49999       18540   Just finished reading this.  I loved the char...      1\n",
       "\n",
       "[50000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_rev = pd.read_csv('Data/reviewseries.csv')\n",
    "real_rev = pd.read_csv('Data/realreviews.csv')\n",
    "fake_rev.rename({'reviewText':'reviews'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.669033Z",
     "start_time": "2020-11-27T21:01:43.663033Z"
    }
   },
   "outputs": [],
   "source": [
    "fake_rev.drop('Unnamed: 0', inplace=True, axis=1) # Drop unneeded index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.679034Z",
     "start_time": "2020-11-27T21:01:43.670035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>So enjoyable!!! If you are a fan of the serie...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This book brings together a lot of history an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Good work but I would have liked to see more ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(Im writing this review in the order it is re...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>excelente libro de hyenuk, en uno poco, cono ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Russells Introduction is a page-turner, and i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Quick and easy ordering and shipping.  It arr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Im used to hearing about a series by John Gri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>fun book. What a great ending for the series....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Just finished reading this.  I loved the char...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "0       So enjoyable!!! If you are a fan of the serie...      1\n",
       "1       This book brings together a lot of history an...      1\n",
       "2       Good work but I would have liked to see more ...      1\n",
       "3       (Im writing this review in the order it is re...      1\n",
       "4       excelente libro de hyenuk, en uno poco, cono ...      1\n",
       "...                                                  ...    ...\n",
       "49995   Russells Introduction is a page-turner, and i...      1\n",
       "49996   Quick and easy ordering and shipping.  It arr...      1\n",
       "49997   Im used to hearing about a series by John Gri...      1\n",
       "49998   fun book. What a great ending for the series....      1\n",
       "49999   Just finished reading this.  I loved the char...      1\n",
       "\n",
       "[50000 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_rev # Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.689034Z",
     "start_time": "2020-11-27T21:01:43.680033Z"
    }
   },
   "outputs": [],
   "source": [
    "real_rev.drop('Unnamed: 0', inplace=True, axis=1) # Drop unneeded index\n",
    "real_rev['reviews'] = real_rev['reviewText'] # Rename work-around\n",
    "real_rev.drop('reviewText', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.698034Z",
     "start_time": "2020-11-27T21:01:43.691033Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great book.... Keeps you coming back for more....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Required text book for college English class. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The good thing about this book is i have got h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off Heather Dahlgren this is an amazing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48703</th>\n",
       "      <td>Very interesting book. With a million new book...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48704</th>\n",
       "      <td>This was an excellent, grounded piece of liter...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48705</th>\n",
       "      <td>For this reader, Feverborn, the eighth of ten ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48706</th>\n",
       "      <td>I have been enjoying each one of the Ruth Gall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48707</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "0      Great book.... Keeps you coming back for more....      0\n",
       "1                                                Thanks!      0\n",
       "2      Required text book for college English class. ...      0\n",
       "3      The good thing about this book is i have got h...      0\n",
       "4      First off Heather Dahlgren this is an amazing ...      0\n",
       "...                                                  ...    ...\n",
       "48703  Very interesting book. With a million new book...      0\n",
       "48704  This was an excellent, grounded piece of liter...      0\n",
       "48705  For this reader, Feverborn, the eighth of ten ...      0\n",
       "48706  I have been enjoying each one of the Ruth Gall...      0\n",
       "48707                                                  0      0\n",
       "\n",
       "[48708 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "real_rev['label'] = 0 # Broadcast label for real-reviews\n",
    "display(real_rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.711037Z",
     "start_time": "2020-11-27T21:01:43.699036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Great book.... Keeps you coming back for more....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thanks!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Required text book for college English class. ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The good thing about this book is i have got h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>First off Heather Dahlgren this is an amazing ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>Russells Introduction is a page-turner, and i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>Quick and easy ordering and shipping.  It arr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>Im used to hearing about a series by John Gri...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>fun book. What a great ending for the series....</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>Just finished reading this.  I loved the char...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "0      Great book.... Keeps you coming back for more....      0\n",
       "1                                                Thanks!      0\n",
       "2      Required text book for college English class. ...      0\n",
       "3      The good thing about this book is i have got h...      0\n",
       "4      First off Heather Dahlgren this is an amazing ...      0\n",
       "...                                                  ...    ...\n",
       "49995   Russells Introduction is a page-turner, and i...      1\n",
       "49996   Quick and easy ordering and shipping.  It arr...      1\n",
       "49997   Im used to hearing about a series by John Gri...      1\n",
       "49998   fun book. What a great ending for the series....      1\n",
       "49999   Just finished reading this.  I loved the char...      1\n",
       "\n",
       "[98708 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df = pd.concat([real_rev, fake_rev], axis=0) # Join our two dataframes\n",
    "review_df # sanity check concatenation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.730033Z",
     "start_time": "2020-11-27T21:01:43.712035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14937</th>\n",
       "      <td>This was such a fun story of how two people l...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20255</th>\n",
       "      <td>It's ironic that the main character of this no...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39807</th>\n",
       "      <td>Such a great read! If you have an empathetic h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46106</th>\n",
       "      <td>Angels in the Bible for Little Ones by Allia Z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30009</th>\n",
       "      <td>Callanetics is my all time favorite exercise r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12287</th>\n",
       "      <td>Delightful reading. Who would have believed a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19272</th>\n",
       "      <td>ACT &amp; College Preparation Course (4/3) is a m...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46017</th>\n",
       "      <td>This is an excellent book. I recommend it for ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6966</th>\n",
       "      <td>Loved this book! Deacon is sexy and desirable....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9709</th>\n",
       "      <td>In Touch provides readers with practical advi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "14937   This was such a fun story of how two people l...      1\n",
       "20255  It's ironic that the main character of this no...      0\n",
       "39807  Such a great read! If you have an empathetic h...      0\n",
       "46106  Angels in the Bible for Little Ones by Allia Z...      0\n",
       "30009  Callanetics is my all time favorite exercise r...      0\n",
       "...                                                  ...    ...\n",
       "12287   Delightful reading. Who would have believed a...      1\n",
       "19272   ACT & College Preparation Course (4/3) is a m...      1\n",
       "46017  This is an excellent book. I recommend it for ...      0\n",
       "6966   Loved this book! Deacon is sexy and desirable....      0\n",
       "9709    In Touch provides readers with practical advi...      1\n",
       "\n",
       "[98708 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df.sample(frac=1) # Shuffle dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.737035Z",
     "start_time": "2020-11-27T21:01:43.731033Z"
    }
   },
   "outputs": [],
   "source": [
    "indexrange = list(range(len(review_df))) # Genereated list of integers for new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.764033Z",
     "start_time": "2020-11-27T21:01:43.738034Z"
    }
   },
   "outputs": [],
   "source": [
    "review_df['newdex'] = indexrange # Assign index as new columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.769034Z",
     "start_time": "2020-11-27T21:01:43.765034Z"
    }
   },
   "outputs": [],
   "source": [
    "review_df.set_index('newdex', inplace=True) # Swap to new index to avoid double assigned indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.782035Z",
     "start_time": "2020-11-27T21:01:43.770035Z"
    }
   },
   "outputs": [],
   "source": [
    "review_df = review_df.sample(frac=1) # Shuffle on new index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:43.790033Z",
     "start_time": "2020-11-27T21:01:43.783035Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>newdex</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>62839</th>\n",
       "      <td>I have high expectations for books about reli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34972</th>\n",
       "      <td>I really liked this book and the whole idea be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23731</th>\n",
       "      <td>Veryentertaining!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26697</th>\n",
       "      <td>I recently received a copy of the NIV Zonderva...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83378</th>\n",
       "      <td>A well paced novel that leaves you wanting more.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59869</th>\n",
       "      <td>Like reading 3 or 4 books in one day.  Great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67936</th>\n",
       "      <td>I satisfy aboout the basic concepts of living...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51621</th>\n",
       "      <td>it might seem a bit unrealistic but after rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3523</th>\n",
       "      <td>I received this book and agreed to read it eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71870</th>\n",
       "      <td>Great recipes and easy to follow directions. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>98708 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  reviews  label\n",
       "newdex                                                          \n",
       "62839    I have high expectations for books about reli...      1\n",
       "34972   I really liked this book and the whole idea be...      0\n",
       "23731                                   Veryentertaining!      0\n",
       "26697   I recently received a copy of the NIV Zonderva...      0\n",
       "83378    A well paced novel that leaves you wanting more.      1\n",
       "...                                                   ...    ...\n",
       "59869    Like reading 3 or 4 books in one day.  Great ...      1\n",
       "67936    I satisfy aboout the basic concepts of living...      1\n",
       "51621    it might seem a bit unrealistic but after rea...      1\n",
       "3523    I received this book and agreed to read it eve...      0\n",
       "71870    Great recipes and easy to follow directions. ...      1\n",
       "\n",
       "[98708 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review_df # Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:45.295037Z",
     "start_time": "2020-11-27T21:01:43.791034Z"
    }
   },
   "outputs": [],
   "source": [
    "test = remove_over(review_df) # Using our helper function to cut review length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:45.304035Z",
     "start_time": "2020-11-27T21:01:45.296036Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have high expectations for books about reli...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I really liked this book and the whole idea be...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Veryentertaining!</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A well paced novel that leaves you wanting more.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This book packs more emotion and realism than ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97366</th>\n",
       "      <td>Like reading 3 or 4 books in one day.  Great ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97367</th>\n",
       "      <td>I satisfy aboout the basic concepts of living...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97368</th>\n",
       "      <td>it might seem a bit unrealistic but after rea...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97369</th>\n",
       "      <td>I received this book and agreed to read it eve...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97370</th>\n",
       "      <td>Great recipes and easy to follow directions. ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>97371 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 reviews  label\n",
       "0       I have high expectations for books about reli...      1\n",
       "1      I really liked this book and the whole idea be...      0\n",
       "2                                      Veryentertaining!      0\n",
       "3       A well paced novel that leaves you wanting more.      1\n",
       "4      This book packs more emotion and realism than ...      0\n",
       "...                                                  ...    ...\n",
       "97366   Like reading 3 or 4 books in one day.  Great ...      1\n",
       "97367   I satisfy aboout the basic concepts of living...      1\n",
       "97368   it might seem a bit unrealistic but after rea...      1\n",
       "97369  I received this book and agreed to read it eve...      0\n",
       "97370   Great recipes and easy to follow directions. ...      1\n",
       "\n",
       "[97371 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test # Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:45.309037Z",
     "start_time": "2020-11-27T21:01:45.305034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Control for saving total concatenated dataframe\n",
    "if save:\n",
    "    test.to_csv('Data/total_review_df.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:45.360037Z",
     "start_time": "2020-11-27T21:01:45.310035Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "train_text, temp_text, train_labels, temp_labels = train_test_split(test['reviews'], test['label'], \n",
    "                                                                    random_state=42, \n",
    "                                                                    test_size=0.3, \n",
    "                                                                    stratify=test['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:45.377033Z",
     "start_time": "2020-11-27T21:01:45.361036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train test split our temp text/labels for a validation and test set\n",
    "val_text, test_text, val_labels, test_labels = train_test_split(temp_text, temp_labels, \n",
    "                                                                random_state=42, \n",
    "                                                                test_size=0.5, \n",
    "                                                                stratify=temp_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and tokenizer assignment\n",
    "\n",
    "## Bidirectional Encoder Representations from Transformers (BERT)  Model\n",
    "\n",
    "**Bidirectional Encoder Representations from Transformers (BERT)** was presented in a [white paper](https://arxiv.org/pdf/1810.04805.pdf) by **Google's AI Language** team in late 2018, and it caused an uproar in the **NLP** community for its wide variety of uses for everything from question answering to inference. As the name suggests its advancement is the bidirectional training of the Transformer architecture. \n",
    "\n",
    "Before the paper NLP training involved text paring left-to-right, or left-to-right and right-to-left training. The paper showed that a deeper context for language could be drawn from bidirectional transversal of sentences which allowed the model to draw deeper context and flow than a single direction model allowed. \n",
    "\n",
    "### Transformers\n",
    "**BERT** is based on a novel mechanism named **Transformer Architecture**. Transformers are models that are at a very base level a set of **encoder cells** and **decoder cells** that use **context** from sequences to provide output sequences. An encoder takes in a sequence and compiles it into a vector called **context**. The context is then passed to the decoder and the decoder uses this context vector to product a sequence token by token. These encoders and decoders tend to be **Recurrent Neural Networks**. \n",
    "![Transformer image](Images/transformer_decoding.gif)\n",
    "[Image Courtesy](http://jalammar.github.io/illustrated-transformer/)\n",
    "\n",
    "#### Recurrent Neural Networks\n",
    "**Reccurent Neural Networks (RNN)** are a **directed graph** network that works on data through various temporal steps. A basic RNN takes *N* **input vectors** and will output *N* **output vectors** based on the input, and it does this operation by remembering context of the sequence and training based on past decisions. RNNs *remember* past decisions in **hidden state vectors** that influence the outputs of the network, and it does this to consider context of a sequence at a given time (temporal) step in the sequence. RNNs represent the ability for a past step to influence a future step, and can increase depth by adding additional hidden states or add additional nonlinear layers between inputs and hidden states.\n",
    "\n",
    "![RNN image](Images/RNN.png)\n",
    "\n",
    "##### Encoders, Decoders and Context\n",
    "**Context** is a self-defined vector that is generated during token sequence encoding in a **Sequence-to-sequence model**. It is the number of hidden units that are used by the encoder RNN. RNNs take two inputs at each step: the input sequence and the hidden state. These context vectors need to be generated somehow and that is through **word embeddings**. These **embeddings** generally turn words into vectors that capture the meaning and information of the words. These encodings are generated to be passed to the **decoder** in order for it to *'understand'* the context of the token sequence.\n",
    "\n",
    "##### Attention Mechanism \n",
    "Though these context vectors provided context, it was supremely inefficient and therefore new mechanisms were developed to combat this but maintain the use of meaning and semantic information use in outputs. Several landmark papers introduced a method known as **Attention** which improved the efficiency of machine translation systems. \n",
    "\n",
    "A traditional sequence-to-sequence model only passes the end hidden state from the encoder to the decoder. An attention based network work different to this:\n",
    "\n",
    "**Encoder:**\n",
    "\n",
    "An encoder in an attention based network instead passes *all* of the hidden states of the encoding sequence. \n",
    "\n",
    "\n",
    "**Decoder:**\n",
    "\n",
    "The decoder also does significantly more work. It receives all hidden states, and therefore the hidden states provide context for each token in the sequence instead of just the final state. Next, all hidden states are scored. Finally, each of the scores are softmaxed. **Softmax** takes a vector of *K-real numbers* and transforms then sums them to one, thereby minimizing the low scoring states and maximizing the high scoring vectors.\n",
    "\n",
    "**Self-Attention** \n",
    "\n",
    "Self-attention is another branch of attention mechanism. It relates the position of tokens in a sequence in order to compute a representation of the same sequence. \n",
    "\n",
    "### BERT Mechanics\n",
    "\n",
    "BERT not only builds upon several years of research as a foundation it also adds its own twist to the mix.\n",
    "\n",
    "**Masked LM** \n",
    "\n",
    " Before feeding token sequences into BERT, ~15% of words are replaced by a masking token (`[MASK]` by default). The model then attempts to predict the words that mare masked based on the context provided by the other words in the sequence. This places a classification layer on the output of the transformer, which is then multiplied with the output vectors of the embedding matrix, and finally the probability of likely words are predicted using a softmax.\n",
    "\n",
    "**Next Sentence Prediciton** \n",
    "\n",
    " BERT receives pairs of sentences as part of the training input. It can learn to predict if the second sentence is subsequent to the first sentence. The model is trained on half subsequent sentence pairs and half random pairs from the corpus thereby learning subsequent context between sentences. It is aided in this task by special tokens:\n",
    " \n",
    " * `[CLS]` which is inserted at the beginning of a sentence\n",
    " * `[SEP]` which is inserted at the end of each sentence.\n",
    " \n",
    "### BERT Metrics \n",
    " \n",
    "1. Model size is important. BERT_large has 345 million parameters, which functions significantly better than BERT_base at 110 million parameteres.\n",
    "\n",
    "2. More training equates to more accuracy. The longer a model can fine-tune on the chosen corpus, the more accurate it becomes.\n",
    "\n",
    "3. BERT converges slower than sequence-to-sequence model since there are several extra layers stacked on top of the transformer architecture, but it outperforms other models at similar numbers of training steps.\n",
    "\n",
    "![BERT image](Images/bert.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:01:58.680036Z",
     "start_time": "2020-11-27T21:01:55.655035Z"
    }
   },
   "outputs": [],
   "source": [
    "bert = AutoModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokenizer = BertTokenizerFast.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-02T16:05:36.496258Z",
     "start_time": "2020-12-02T16:05:35.142258Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average length of review: 73.092\n",
      "Average length of review: 73.587\n",
      "Average length of review: 73.305\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAEICAYAAAC9E5gJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5gV1Znv8e9PUPCCAoKOoZFGg0ZUQGwUr1EJglecKAo6B8yYwRj1OGaighnF6xzNOEYdowaFgBPlokYlXgGvBw9eWkWDKIKK0oJyR5Ggtr7nj1rd2TS770DTze/zPPvZVW+tqlqrene9u1bVrlJEYGZmW7atGroCZmbW8JwMzMzMycDMzJwMzMwMJwMzM8PJwMzMcDJo8iQ9KWnoRlz+O5KO2ljLb0wkXS7pniqmny1p+qask+Un6XlJP2/oemxOnAw2Q5JW57y+l/S3nPGzarOsiDguIsbVsR7zJf2kQmydHVpE7BsRz1eznEJJIal5XerRWETEf0TEz2HDtjntuFZIalH/WjYsSVdJ+lNTX2dj5GSwGYqIHcpewCfASTmx+8rKNfWda0015e0gqRA4Agjg5I2w/Ca77ax2nAwaEUlHSSqRdJmkz4A/Smoj6TFJS9K3x8ckFeTMU344XPatXtJNqexHko6rZ53Kjx4kHSSpWNIXkj6XdHMq9mJ6X5mObg6RtJWkf5f0saTFku6VtFPOcoekacskXVFhPVdJelDSnyR9AZyd1j1D0kpJiyTdLmmbnOWFpF9KmivpS0nXStozzfOFpEm55Su08WNJB6bhf0rL6prGfy7pkZx6lX0DXa/NOcurzfYfArwMjAWGpvlbpHbul7PM9ukIcpc0fqKkmanc/5PUrcLf7DJJbwNfSWouabikD9K2mS3pH3PKN5P0X5KWpjpfkHvUI2knSaPTdv9U0nWSmlXTrnzbuXeq60pJbymn+zF9jq+V9FKq4xRJ7XKm5/28SOoPXA6ckf4Ob+WsslNly9sSORk0Pv8AtAU6AcPI/oZ/TOO7A38Dbq9i/oOBOUA74LfAaEnaQHW7Fbg1InYE9gQmpfiR6b11OrqZAZydXkcDewA7lNU77WjvAM4CdgN2AjpUWNcA4EGgNXAf8B1wcWrXIUAf4JcV5ukPHAj0Bi4FRqV1dAT2AwZX0q4XgKNy2vIh8OOc8RfyzJOvzVD77T8kte8+oJ+kXSPia+DPFep7OvBCRCyW1BMYA5wL7Az8AZisdbuZBgMnpPqVAh+QHYHsBFwN/EnSbqnsvwDHAT2AnsApFeo4DigFfggcABwL1Ko/XlIH4HHgOrLP96+BhyS1zyl2JvAzYBdgm1Smys9LRDwF/AcwMf0dule3vC2Vk0Hj8z0wMiK+joi/RcSyiHgoItZExJfA9fx9R5XPxxFxd0R8R/ZPvBuwaxXlH0nf1FZKWkn2T1eZb4EfSmoXEasj4uUqyp4F3BwRH0bEamAEMCh92zwN+EtETI+Ib4ArybpJcs2IiEci4vu0HV6PiJcjojQi5pPtACtuhxsj4ouIeAeYBUxJ618FPEm2I8vnhZxlHQH8n5zxH5M/GVSmxttf0uFkSX5SRLxOtsM+M02+n3WTwZkpBtnO+w8R8UpEfJfOGX1NlgTL3BYRCyLibwAR8UBELEzbcyIwFzgolT2dLMmXRMQK4IacOu5Klij+NSK+iojFwO+AQbXYJgD/BDwREU+kOkwFioHjc8r8MSLeT3WeRJacoGafl3wqW94Wycmg8VkSEWvLRiRtJ+kP6RD5C7LuidZVHKZ/VjYQEWvS4A5VrO+UiGhd9mL9b9u5zgH2At6T9JqkE6so+wPg45zxj4HmZDvGHwALKtRzWYX5F+SOSNpLWRfZZ2k7/AfZt+9cn+cM/y3PeGXb4QXgCEn/ADQDJgKHKevP3wmYWcl8+dRm+w8lS1hL0/j9KQbwLLCtpIMldSLbkT2cpnUC/q1CEu9Itl3LVNx+Q3K6lVaSHSmVbb8fVCifO9wJ2BpYlDPvH8i+bddGJ2BghTofTpYsy3yWM7yGv2+3mnxe8qlseVsknzxqfCp+4/k3YG/g4Ij4TFIP4E1gQ3X91LxiEXOBwZK2An4KPChpZ/J/S1tItgMosztZV8PnwCKyNgEgaVuy7o51Vldh/E6ydg+OiC8l/SvZN8Z6i4h5ktYA/xt4MS3/M7JuuukR8X2+2eqzztTm04FmaV0ALcgSffeIeEvSJLKjg8+Bx9KRIWQ7xusj4vqqmpWzrk7A3WRdazMi4jtJM/n7Z2gRUJAzb8ec4QVkRx3tUndTXS0A/ici/qUO81b3efGtmWvARwaNXyuyb7UrJbUFRjZURZSdXG2fdo4rU/g7YAlZ99YeOcXHAxdL6ixpB/7er1tKdi7gJEmHKjupezXVJ7dWwBfAakk/As7bYA3LvABcwN+7hJ6vMF5RvjbXxilk264r2bf+HsA+wP8lO48A2ZHCGWRdbvfnzHs38It01CBJ20s6QVKrSta1PdkOcwmApJ+RHRmUmQRcJKmDpNbAZWUTImIRMAX4L0k7KrswYE9JVXVVbiWpZc6rBfAnsr95v3TCuqWyCyYKqlhOmeo+L58DhelLilXCG6fxuwXYFlhKdtXJUw1Yl/7AO5JWk51MHhQRa9Nh+/XAS6kLoDfZCc7/IevW+ghYC1wIkPr0LwQmkH3r+xJYTPYNtDK/Jus3/5JsZzhxA7ftBbKE82Il4+uopM21MZSsT/uTiPis7EV2kv0sSc0j4hXgK7Jukidz1l1Mdt7gdmAFMI/sZH1eETEb+C9gBtmOc3/gpZwid5Pt8N8mO/p6guwo7rs0fQjZCdjZaX0Psm73TkWDyb7AlL0+iIgFZBcFXE6WlBYAl1CDfVQNPi8PpPdlkt6obnlbKvnhNra5S0cOK4EuEfFRQ9dnS6fscti7IqJTtYUbgD8vdeMjA9ssSTopnRzfHrgJ+Cswv2FrtWWStK2k45X9HqEDWVfkw9XNtyn581J/Tga2uRpAdpJ5IdCFrMvJh7ENQ2T98CvIuoneJbt8c3Piz0s9uZvIzMx8ZGBmZo34dwbt2rWLwsLChq7GxjVnTva+995VlzMzq6HXX399aUS0rxhvtMmgsLCQ4uLihq7GxnX00dn7c881bD3MrMmQ9HG+uLuJzMzMycDMzJwMzMyMRnzOwKwx+vbbbykpKWHt2rXVFzarh5YtW1JQUMDWW29do/JOBmabUElJCa1ataKwsJAN90whs3VFBMuWLaOkpITOnTvXaB53E5ltQmvXrmXnnXd2IrCNShI777xzrY5AnQzMNjEnAtsUavs5czIwM7Pqk4GkMZIWS5pVIX6hpDmS3pH025z4CEnz0rR+OfH+KTZP0vCceGdJr0iaK2liejiFmW1EDz/8MJJ47733Groq1SosLGTp0qXVF6yjsWPHsnDhwjqvb86cOfTo0aP8teOOO3LLLbcAcMUVV9CtWzd69OjBscceu856co0bN44uXbrQpUsXxo0bVx6fOHEi3bp1Y9999+XSSy8tj99888107dqVbt260adPHz7+OO/vyGonIqp8AUcCPYFZObGjgWlAizS+S3rvCrxF9ni+zmQP8G6WXh+QPfVpm1Sma5pnEtkdBgHuAs6rrk4RwYEHHhgbW6fLHqvRa6M56qjsZU3G7NmzG7oKERExcODAOPzww2PkyJEbZHmlpaUbZDn5dOrUKZYsWbLRlv/jH/84XnvttQ2yvtLS0th1111j/vz5ERGxatWq8mm33nprnHvuuevNs2zZsujcuXMsW7Ysli9fHp07d47ly5fH0qVLo2PHjrF48eKIiBgyZEhMmzYtIiKeffbZ+OqrryIi4o477ojTTz89b33yfd6A4sizT63JU4ReBJZXCJ8H3BARX6cyi1N8ADAhIr6O7KES84CD0mteRHwYEd+QPZFogLJOrWPInowEMI7scX9mtpGsXr2al156idGjRzNhwgQAnnzySU4//fTyMs8//zwnnXQSAFOmTOGQQw6hZ8+eDBw4kNWrVwPZN+hrrrmGww8/nAceeIC7776bXr160b17d0499VTWrFkDwAcffEDv3r3p1asXV155JTvs8Pfnzv/nf/4nvXr1olu3bowcWfMnti5ZsoRTTz2VXr160atXL156KXsw21VXXcU///M/c9RRR7HHHntw2223lc9z7bXX8qMf/Yi+ffsyePBgbrrpJh588EGKi4s566yz6NGjB3/7298A+O///m969uzJ/vvvX6ujp2eeeYY999yTTp2y5/7suOOO5dO++uqrvP34Tz/9NH379qVt27a0adOGvn378tRTT/Hhhx+y11570b59dhuhn/zkJzz00EMAHH300Wy33XYA9O7dm5KSkhrXsTJ1vbR0L+AISdeTPa7w1xHxGtCB7NGLZUpSDLLH2OXGDyZ7aPXK+PuDtHPLr0fSMLKHkLP77rvXsepmm4mye09taNXcy+qRRx6hf//+7LXXXrRt25Y33niDvn37cu655/LVV1+x/fbbM3HiRM444wyWLl3Kddddx7Rp09h+++258cYbufnmm7nyyuxxBi1btmT69OkALFu2jH/5l+x59v/+7//O6NGjufDCC7nooou46KKLGDx4MHfddVd5PaZMmcLcuXN59dVXiQhOPvlkXnzxRY488shqm3jRRRdx8cUXc/jhh/PJJ5/Qr18/3n33XQDee+89nnvuOb788kv23ntvzjvvPN566y0eeugh3nzzTUpLS+nZsycHHnggp512Grfffjs33XQTRUVF5ctv164db7zxBnfccQc33XQT99xzD8XFxdx1113cc889ldZrwoQJDB48eJ3Yb37zG+6991522mknnsvzt/n000/p2LFj+XhBQQGffvop/fv357333mP+/PkUFBTwyCOP8M0336w3/+jRoznuuOOq3WbVqesJ5OZAG6A32XNKJ6Vv+flOX0cd4nlFxKiIKIqIorJsaWa1M378eAYNGgTAoEGDGD9+PM2bN6d///785S9/obS0lMcff5wBAwbw8ssvM3v2bA477DB69OjBuHHj1umfPuOMM8qHZ82axRFHHMH+++/PfffdxzvvvAPAjBkzGDhwIABnnnlmefkpU6YwZcoUDjjgAHr27Ml7773H3Llza9SGadOmccEFF9CjRw9OPvlkvvjiC7788ksATjjhBFq0aEG7du3YZZdd+Pzzz5k+fToDBgxg2223pVWrVuVHPZX56U9/CsCBBx7I/PnzASgqKqoyEXzzzTdMnjy5vK1lrr/+ehYsWMBZZ53F7bffvt58keeZMpJo06YNd955J2eccQZHHHEEhYWFNG++7vf3P/3pTxQXF3PJJZdU2Z6aqOuRQQnw59T/9Kqk74F2Kd4xp1wB2ZOHqCS+FGidHu5dWqG8WdPWAHejXbZsGc8++yyzZs1CEt999x2S+O1vf8sZZ5zB73//e9q2bUuvXr1o1aoVEUHfvn0ZP3583uVtv/325cNnn302jzzyCN27d2fs2LE8//zzVdYlIhgxYgTnnnturdvx/fffM2PGDLbddtv1prVo0aJ8uFmzZpSWlubd4ValbBll89fEk08+Sc+ePdl1113zTj/zzDM54YQTuPrqq9eJFxQUrLOtSkpKOOqoowA46aSTyhPXqFGjaNasWXm5adOmcf311/PCCy+s0+a6quuRwSNkff1I2ovspPBSYDIwSFILSZ3JHj/3KvAa0CVdObQNMAiYnJLJc8BpablDgUfr2hgzq9qDDz7IkCFD+Pjjj5k/fz4LFiygc+fOTJ8+naOOOoo33niDu+++u/wbf+/evXnppZeYN28eAGvWrOH999/Pu+wvv/yS3XbbjW+//Zb77ruvPN67d+/yvu6ycxQA/fr1Y8yYMeXnID799FMWL15MTRx77LHrfMueOXNmleUPP/xw/vKXv7B27VpWr17N448/Xj6tVatW5UcV9TF+/Pj1uohyj3QmT57Mj370o/Xm69evH1OmTGHFihWsWLGCKVOm0K9fdiFm2fZYsWIFd9xxBz//+c8BePPNNzn33HOZPHkyu+yyS73rDjW7tHQ8MAPYW1KJpHOAMcAe6XLTCcDQdKL6HbKrg2YDTwHnR8R36Vv/BcDTZM9PnZTKAlwG/ErSPLJzCKM3SMvMbD3jx4/nH//xH9eJnXrqqdx///00a9aME088kSeffJITTzwRgPbt2zN27FgGDx5Mt27d6N27d6UnVK+99loOPvhg+vbtu85O75ZbbuHmm2/moIMOYtGiRey0005AtkM/88wzOeSQQ9h///057bTTKt0pd+vWjYKCAgoKCvjVr37FbbfdRnFxMd26daNr167rnIvIp1evXpx88sl0796dn/70pxQVFZXX4+yzz+YXv/jFOieQ8ykuLi7fGVe0Zs0apk6dWt69VGb48OHst99+dOvWjSlTpnDrrbeut6y2bdtyxRVXlJ8Mv/LKK2nbti2QnRvp2rUrhx12GMOHD2evvfYC4JJLLmH16tUMHDiwvKusvhrtM5CLiopiYz/cpnD449UXAubfcMLGqYAfbtPkvPvuu+yzzz4NXY1Nas2aNWy77bZIYsKECYwfP55HH930HQCrV69mhx12YM2aNRx55JGMGjWKnj17bvJ6bEr5Pm+SXo+IooplfaM6M9uoXn/9dS644AIigtatWzNmzJgGqcewYcOYPXs2a9euZejQoU0+EdSWk4GZbVRHHHEEb731VkNXg/vvv7+hq7BZ872JzMzMycDMzJwMzMwMJwMzM8MnkM0aVE0vX66p6i5zXrZsGX369AHgs88+o1mzZuU3Qnv11VfZZpvK7yBfXFzMvffeu87N36pTWFhIcXEx7dq1A7Ib4N1000089thjTJ48mdmzZzN8+PC8886cOZOFCxdy/PHH13h9VndOBmZbkJ133rn817pXXXUVO+ywA7/+9a/Lp5eWlq53/5syRUVF69zMrb5OPvnkKn8sNXPmTIqLizdIMii/TfNW7gypjLeM2Rbu7LPP5le/+hVHH300l112Ga+++iqHHnooBxxwAIceeihz5swBsm/1Zb9MrupW0TU1duxYLrjgAgAeeOAB9ttvP7p3786RRx7JN998w5VXXsnEiRPp0aMHEydOZPny5Zxyyinlv4R+++23gex21n379qVnz56ce+65dOrUiaVLlzJ//nz22WcffvnLX9KzZ08WLFjAeeedR1FREfvuu+86t8wuLCzk8ssv55BDDqGoqIg33niDfv36seeee1b76+amwkcGZsb777/PtGnTaNasGV988QUvvvgizZs3Z9q0aVx++eXl9xbKle9W0VtvvfV65Y4++ujyG6ytXr067/15rrnmGp5++mk6dOjAypUr2WabbbjmmmsoLi4uvwfRhRdeyAEHHMAjjzzCs88+y5AhQ5g5cyZXX301xxxzDCNGjOCpp55i1KhR5cudM2cOf/zjH7njjjuA7A6ibdu25bvvvqNPnz68/fbbdOvWDYCOHTsyY8YMLr74Ys4++2xeeukl1q5dy7777ssvfvGL+m/kzZyTgZkxcODA8h32qlWrGDp0KHPnzkUS3377bd55ym4V3aJFi/JbRRcUFKxX7rnnnlvvnEFFhx12GGeffTann376evf3KTN9+vTypHTMMcewbNkyVq1axfTp03n44YcB6N+/P23atCmfp1OnTvTu3bt8fNKkSYwaNYrS0lIWLVrE7Nmzy5NBWZfV/vvvz+rVq2nVqhWtWrWiZcuWrFy5ktatW1e9ERs5dxOZ2Tq3or7iiis4+uijmTVrVvmdPvPJd6vourrrrru47rrrWLBgAT169GDZsmXrlansvv9V3V8tt10fffQRN910E8888wxvv/02J5xwwjptK2vPVltttU7bttpqq3q1rbFwMjCzdaxatYoOHbIHDo4dO3aTrPODDz7g4IMP5pprrqFdu3YsWLBgvVtLH3nkkeW3xn7++edp164dO+64I4cffjiTJk0CKL8VdD5ffPEF22+/PTvttBOff/45Tz755MZvWCPibiKzBrTR7nhbD5deeilDhw7l5ptv5phjjtkk67zkkkuYO3cuEUGfPn3o3r07u+++OzfccAM9evRgxIgRXHXVVfzsZz+jW7dubLfddowbNw6AkSNHMnjwYCZOnMiPf/xjdtttN1q1alX+nIQy3bt354ADDmDfffdljz324LDDDtskbWssfAvrKvgW1rahbYm3sN7Yvv76a5o1a0bz5s2ZMWMG5513XrUPu9lS+BbWZrbF+OSTTzj99NP5/vvv2Wabbbj77rsbukqNUk2edDZG0uL0VLOK034tKSS1S+OSdJukeZLeltQzp+xQSXPTa2hO/EBJf03z3CZJG6pxZtb0denShTfffJO33nqL1157jV69ejV0lRqlmpxAHgv0rxiU1BHoC3ySEz6O7LnHXYBhwJ2pbFtgJHAwcBAwUlLZ9V93prJl8623LrOmpLF2zVrjUtvPWbXJICJeBJbnmfQ74FIgd40DgHvT85BfBlpL2g3oB0yNiOURsQKYCvRP03aMiBmR1fxe4JRatcCsEWnZsiXLli1zQrCNKiJYtmwZLVu2rPE8dTpnIOlk4NOIeKtCr04HYEHOeEmKVRUvyROvbL3DyI4i2H333etSdbMGVVBQQElJCUuWLGnoqlgT17Jly7w/AqxMrZOBpO2A3wDH5pucJxZ1iOcVEaOAUZBdTVRtZc02M1tvvTWdO3du6GqYracuPzrbE+gMvCVpPlAAvCHpH8i+2XfMKVsALKwmXpAnbmZmm1Ctk0FE/DUidomIwogoJNuh94yIz4DJwJB0VVFvYFVELAKeBo6V1CadOD4WeDpN+1JS73QV0RDg0Q3UNjMzq6GaXFo6HpgB7C2pRNI5VRR/AvgQmAfcDfwSICKWA9cCr6XXNSkGcB5wT5rnA8C/ETcz28SqPWcQEYOrmV6YMxzA+ZWUGwOMyRMvBvarrh5mZrbx+EZ1ZmbmZGBmZlvovYk29EPIzcwaOx8ZmJmZk4GZmTkZmJkZTgZmZoaTgZmZ4WRgZmY4GZiZGU4GZmaGk4GZmeFkYGZmOBmYmRlOBmZmhpOBmZnhZGBmZtTssZdjJC2WNCsn9p+S3pP0tqSHJbXOmTZC0jxJcyT1y4n3T7F5kobnxDtLekXSXEkTJW2zIRtoZmbVq8mRwVigf4XYVGC/iOgGvA+MAJDUFRgE7JvmuUNSM0nNgN8DxwFdgcGpLMCNwO8ioguwAqjqGctmZrYRVJsMIuJFYHmF2JSIKE2jLwMFaXgAMCEivo6Ij8gecn9Qes2LiA8j4htgAjBAkoBjgAfT/OOAU+rZJjMzq6UNcc7gn4En03AHYEHOtJIUqyy+M7AyJ7GUxfOSNExSsaTiJUuWbICqm5kZ1DMZSPoNUArcVxbKUyzqEM8rIkZFRFFEFLVv37621TUzs0rU+RnIkoYCJwJ9IqJsB14CdMwpVgAsTMP54kuB1pKap6OD3PJmZraJ1OnIQFJ/4DLg5IhYkzNpMjBIUgtJnYEuwKvAa0CXdOXQNmQnmSenJPIccFqafyjwaN2aYmZmdVWTS0vHAzOAvSWVSDoHuB1oBUyVNFPSXQAR8Q4wCZgNPAWcHxHfpW/9FwBPA+8Ck1JZyJLKryTNIzuHMHqDttDMzKpVbTdRRAzOE650hx0R1wPX54k/ATyRJ/4h2dVGZmbWQPwLZDMzczIwMzMnAzMzw8nAzMxwMjAzM5wMzMwMJwMzM8PJwMzMcDIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzw8nAzMyo2ZPOxkhaLGlWTqytpKmS5qb3NikuSbdJmifpbUk9c+YZmsrPTc9PLosfKOmvaZ7bJGlDN9LMzKpWkyODsUD/CrHhwDMR0QV4Jo0DHEf23OMuwDDgTsiSBzASOJjsqWYjyxJIKjMsZ76K6zIzs42s2mQQES8CyyuEBwDj0vA44JSc+L2ReRloLWk3oB8wNSKWR8QKYCrQP03bMSJmREQA9+Ysy8zMNpG6njPYNSIWAaT3XVK8A7Agp1xJilUVL8kTNzOzTWhDn0DO198fdYjnX7g0TFKxpOIlS5bUsYpmZlZRXZPB56mLh/S+OMVLgI455QqAhdXEC/LE84qIURFRFBFF7du3r2PVzcysoromg8lA2RVBQ4FHc+JD0lVFvYFVqRvpaeBYSW3SieNjgafTtC8l9U5XEQ3JWZaZmW0izasrIGk8cBTQTlIJ2VVBNwCTJJ0DfAIMTMWfAI4H5gFrgJ8BRMRySdcCr6Vy10RE2Unp88iuWNoWeDK9zMxsE6o2GUTE4Eom9clTNoDzK1nOGGBMnngxsF919TAzs43Hv0A2M7PqjwyseoXDH69Rufk3nLCRa2JmVjc+MjAzMycDMzNzMjAzM5wMzMwMJwMzM8PJwMzMcDIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzw8nAzMxwMjAzM+qZDCRdLOkdSbMkjZfUUlJnSa9ImitpoqRtUtkWaXxeml6Ys5wRKT5HUr/6NcnMzGqrzslAUgfgfwNFEbEf0AwYBNwI/C4iugArgHPSLOcAKyLih8DvUjkkdU3z7Qv0B+6Q1Kyu9TIzs9qrbzdRc2BbSc2B7YBFwDHAg2n6OOCUNDwgjZOm95GkFJ8QEV9HxEfAPOCgetbLzMxqoc7JICI+BW4CPiFLAquA14GVEVGaipUAHdJwB2BBmrc0ld85N55nnnVIGiapWFLxkiVL6lp1MzOroD7dRG3IvtV3Bn4AbA8cl6dolM1SybTK4usHI0ZFRFFEFLVv3772lTYzs7zq0030E+CjiFgSEd8CfwYOBVqnbiOAAmBhGi4BOgKk6TsBy3PjeeYxM7NNoD7J4BOgt6TtUt9/H2A28BxwWiozFHg0DU9O46Tpz0ZEpPigdLVRZ6AL8Go96mVmZrXUvPoi+UXEK5IeBN4ASoE3gVHA48AESdel2Og0y2jgfyTNIzsiGJSW846kSWSJpBQ4PyK+q2u9zMys9uqcDAAiYiQwskL4Q/JcDRQRa4GBlSzneuD6+tTFzMzqzr9ANjMzJwMzM3MyMDMznAzMzAwnAzMzw8nAzMxwMjAzMxD2qDMAAAr6SURBVJwMzMwMJwMzM8PJwMzMcDIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzo57JQFJrSQ9Kek/Su5IOkdRW0lRJc9N7m1RWkm6TNE/S25J65ixnaCo/V9LQytdoZmYbQ70eewncCjwVEadJ2gbYDrgceCYibpA0HBgOXAYcR/aw+y7AwcCdwMGS2pI9OrMICOB1SZMjYkU967bZKRz+eI3Lzr/hhI1YEzOzddX5yEDSjsCRpAfeR8Q3EbESGACMS8XGAaek4QHAvZF5GWgtaTegHzA1IpanBDAV6F/XepmZWe3Vp5toD2AJ8EdJb0q6R9L2wK4RsQggve+SyncAFuTMX5JilcXXI2mYpGJJxUuWLKlH1c3MLFd9kkFzoCdwZ0QcAHxF1iVUGeWJRRXx9YMRoyKiKCKK2rdvX9v6mplZJeqTDEqAkoh4JY0/SJYcPk/dP6T3xTnlO+bMXwAsrCJuZmabSJ2TQUR8BiyQtHcK9QFmA5OBsiuChgKPpuHJwJB0VVFvYFXqRnoaOFZSm3Tl0bEpZmZmm0h9rya6ELgvXUn0IfAzsgQzSdI5wCfAwFT2CeB4YB6wJpUlIpZLuhZ4LZW7JiKW17NeZmZWC/VKBhExk+yS0Ir65CkbwPmVLGcMMKY+dTEzs7rzL5DNzMzJwMzMnAzMzAwnAzMzw8nAzMxwMjAzM5wMzMwMJwMzM8PJwMzMcDIwMzOcDMzMDCcDMzPDycDMzHAyMDMznAzMzAwnAzMzYwMkA0nNJL0p6bE03lnSK5LmSpqYnoKGpBZpfF6aXpizjBEpPkdSv/rWyczMaqe+j70EuAh4F9gxjd8I/C4iJki6CzgHuDO9r4iIH0oalMqdIakrMAjYF/gBME3SXhHx3QaoW6NVOPxxxn+4DIDBwx+vtNz8G07YVFUysyasXkcGkgqAE4B70riAY4AHU5FxwClpeEAaJ03vk8oPACZExNcR8RHZM5IPqk+9zMysdurbTXQLcCnwfRrfGVgZEaVpvATokIY7AAsA0vRVqXx5PM88Zma2CdQ5GUg6EVgcEa/nhvMUjWqmVTVPxXUOk1QsqXjJkiW1qq+ZmVWuPkcGhwEnS5oPTCDrHroFaC2p7FxEAbAwDZcAHQHS9J2A5bnxPPOsIyJGRURRRBS1b9++HlU3M7NcdU4GETEiIgoiopDsBPCzEXEW8BxwWio2FHg0DU9O46Tpz0ZEpPigdLVRZ6AL8Gpd62VmZrW3Ia4mqugyYIKk64A3gdEpPhr4H0nzyI4IBgFExDuSJgGzgVLg/C39SiIzs01tgySDiHgeeD4Nf0ieq4EiYi0wsJL5rweu3xB1MTOz2vMvkM3MzMnAzMycDMzMDCcDMzPDycDMzNg4l5baJlRYxU3scvmGdmZWFR8ZmJmZk4GZmTkZmJkZTgZmZoaTgZmZ4WRgZmY4GZiZGU4GZmaGk4GZmeFkYGZm+HYUWwzftsLMqlLnIwNJHSU9J+ldSe9IuijF20qaKmluem+T4pJ0m6R5kt6W1DNnWUNT+bmShla2TjMz2zjq001UCvxbROwD9AbOl9QVGA48ExFdgGfSOMBxZA+77wIMA+6ELHkAI4GDyR6XObIsgZiZ2aZR52QQEYsi4o00/CXwLtABGACMS8XGAaek4QHAvZF5GWgtaTegHzA1IpZHxApgKtC/rvUyM7Pa2yDnDCQVAgcArwC7RsQiyBKGpF1SsQ7AgpzZSlKssni+9QwjO6pg99133xBVtybM50nMaq7eyUDSDsBDwL9GxBeSKi2aJxZVxNcPRowCRgEUFRXlLWP14x2o2ZapXpeWStqaLBHcFxF/TuHPU/cP6X1xipcAHXNmLwAWVhE3M7NNpM5HBsoOAUYD70bEzTmTJgNDgRvS+6M58QskTSA7WbwqdSM9DfxHzknjY4ERda2XNX01PXoxs5qrTzfRYcD/Av4qaWaKXU6WBCZJOgf4BBiYpj0BHA/MA9YAPwOIiOWSrgVeS+WuiYjl9aiXmZnVUp2TQURMJ39/P0CfPOUDOL+SZY0BxtS1LmZmVj/+BbLViU80mzUtvjeRmZk5GZiZmbuJbCNzd5JZ4+BkYJsFXy5q1rDcTWRmZk4GZmbmZGBmZjgZmJkZTgZmZoaTgZmZ4WRgZmY4GZiZGf7RmZl/JW2GjwzMzAwnAzMzw91EZjW2oe+f5G4n25xsNslAUn/gVqAZcE9E3NDAVTLbqBry5nxORFbRZpEMJDUDfg/0BUqA1yRNjojZDVszs6bJd4mtv6aWUDeLZAAcBMyLiA8BJE0ABgBOBma2WWqohLqxktDmkgw6AAtyxkuAgysWkjQMGJZGV0uaU4d1tQOW1mG+Te7QsoEbT6zPYhpNezeALamt4PY2ZZW2VTfWe9md8gU3l2SgPLFYLxAxChhVrxVJxRFRVJ9lNCZbUnu3pLaC29uUNURbN5dLS0uAjjnjBcDCBqqLmdkWZ3NJBq8BXSR1lrQNMAiY3MB1MjPbYmwW3UQRUSrpAuBpsktLx0TEOxtpdfXqZmqEtqT2bkltBbe3KdvkbVXEel3zZma2hdlcuonMzKwBORmYmdmWlQwk9Zc0R9I8ScMbuj4bgqQxkhZLmpUTaytpqqS56b1NikvSban9b0vq2XA1rz1JHSU9J+ldSe9IuijFm1x7JbWU9Kqkt1Jbr07xzpJeSW2dmC64QFKLND4vTS9syPrXlaRmkt6U9Fgab7LtlTRf0l8lzZRUnGIN9lneYpJBzi0vjgO6AoMldW3YWm0QY4H+FWLDgWciogvwTBqHrO1d0msYcOcmquOGUgr8W0TsA/QGzk9/w6bY3q+BYyKiO9AD6C+pN3Aj8LvU1hXAOan8OcCKiPgh8LtUrjG6CHg3Z7ypt/foiOiR85uChvssR8QW8QIOAZ7OGR8BjGjoem2gthUCs3LG5wC7peHdgDlp+A/A4HzlGuMLeJTsflZNur3AdsAbZL/KXwo0T/HyzzTZlXiHpOHmqZwauu61bGcB2Q7wGOAxsh+jNuX2zgfaVYg12Gd5izkyIP8tLzo0UF02tl0jYhFAet8lxZvMNkjdAgcAr9BE25u6TGYCi4GpwAfAyogoTUVy21Pe1jR9FbDzpq1xvd0CXAp8n8Z3pmm3N4Apkl5Pt9qBBvwsbxa/M9hEanTLiyauSWwDSTsADwH/GhFfSPmalRXNE2s07Y2I74AekloDDwP75CuW3ht1WyWdCCyOiNclHVUWzlO0SbQ3OSwiFkraBZgq6b0qym709m5JRwZb0i0vPpe0G0B6X5zijX4bSNqaLBHcFxF/TuEm216AiFgJPE92nqS1pLIvcbntKW9rmr4TsHzT1rReDgNOljQfmEDWVXQLTbe9RMTC9L6YLNkfRAN+lrekZLAl3fJiMjA0DQ8l61sviw9JVyb0BlaVHZI2BsoOAUYD70bEzTmTmlx7JbVPRwRI2hb4CdmJ1eeA01Kxim0t2wanAc9G6lxuDCJiREQUREQh2f/msxFxFk20vZK2l9SqbBg4FphFQ36WG/okyiY+YXM88D5Z3+tvGro+G6hN44FFwLdk3x7OIes7fQaYm97bprIiu6LqA+CvQFFD17+WbT2c7ND4bWBmeh3fFNsLdAPeTG2dBVyZ4nsArwLzgAeAFineMo3PS9P3aOg21KPtRwGPNeX2pna9lV7vlO2PGvKz7NtRmJnZFtVNZGZmlXAyMDMzJwMzM3MyMDMznAzMzAwnAzMzw8nAzMyA/w/WK5NtqMtVSgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split sequences into 'tokens'\n",
    "train_seq_len = [len(i.split()) for i in train_text]\n",
    "val_seq_len = [len(i.split()) for i in val_text]\n",
    "test_seq_len = [len(i.split()) for i in test_text]\n",
    "\n",
    "# Average length of sequences\n",
    "train_av = round(np.average(train_seq_len),3)\n",
    "val_av = round(np.average(val_seq_len),3)\n",
    "test_av = round(np.average(test_seq_len),3)\n",
    "print('Average length of review:', train_av)\n",
    "print('Average length of review:', val_av)\n",
    "print('Average length of review:', test_av)\n",
    "\n",
    "# Train historgram\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Train Histogram with Average Length')\n",
    "plt.hist(pd.Series(train_seq_len), bins=30)\n",
    "ax.axvline(train_av, color ='red', lw = 2, alpha = 0.75) \n",
    "plt.legend(['Average Length: {}'.format(train_av), 'Train Histogram'])\n",
    "plt.savefig('Images/trainlen.png')\n",
    "plt.show()\n",
    "\n",
    "# Validation historgram\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Validation Histogram with Average Length')\n",
    "plt.hist(pd.Series(val_seq_len), bins=30)\n",
    "ax.axvline(train_av, color ='red', lw = 2, alpha = 0.75) \n",
    "plt.legend(['Average Length: {}'.format(val_av), 'Validation Histogram'])\n",
    "plt.savefig('Images/vallen.png')\n",
    "plt.show()\n",
    "\n",
    "# Testing historgram\n",
    "fig, ax = plt.subplots()\n",
    "plt.title('Test Histogram with Average Length')\n",
    "plt.hist(pd.Series(test_seq_len), bins=30)\n",
    "ax.axvline(train_av, color ='red', lw = 2, alpha = 0.75) \n",
    "plt.legend(['Average Length: {}'.format(test_av), 'Test Histogram'])\n",
    "plt.savefig('Images/testlen.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computers do not natively understand words and that is an issue because a lot of the tasks we wish to automate involve processing language. There is a process that has been developed to change text into a medium that computers can ingest.\n",
    "\n",
    "**Tokenization** is the process by which words are converted to **tokens** that our models can process.\n",
    "\n",
    "Tokens be one of a few things:\n",
    "1. Words\n",
    "2. Characters\n",
    "3. Subwords\n",
    "\n",
    "The most common way of separating tokens is by space, assuming that the strings being fed into the tokenizer are delimited by spaces.\n",
    "\n",
    "Tokenization is the most important step in text preprocessing as it converts words into data that our models can take in. It does this by transforming the words, characters, or subwords into tokens and then these tokens are used to generate vocabularies. These vocabularies can then be used by our models to operate on text data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:07.444034Z",
     "start_time": "2020-11-27T21:01:59.599036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Using BERT Fast Tokenizer to encode text into input ids\n",
    "\n",
    "# Training tokens\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = 80,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Validation Tokens\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = 80,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")\n",
    "\n",
    "# Testing tokens\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = 80,\n",
    "    padding=True,\n",
    "    truncation=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:08.098035Z",
     "start_time": "2020-11-27T21:02:07.446034Z"
    }
   },
   "outputs": [],
   "source": [
    "# Store sequences, attention masks, and lables as torch tensors\n",
    "\n",
    "# Train tensors\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "\n",
    "# Validation tensors\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "\n",
    "# Testing tensors\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Dataloader\n",
    "\n",
    "PyTorch has a Dataset inheritable class that can be used with the PyTorch framework. The Dataset inheritable class represents a Python iterable over a dataset that supports map-style or iterable-style datasets.\n",
    "\n",
    "* Map-Style - Represents a map of Key-Value pairs to data samples within the dataset.\n",
    "* Iterable-Style - Represents an iterable dataset like that which could be streamed from a database, remote server, or even generated in real-time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:08.103036Z",
     "start_time": "2020-11-27T21:02:08.099033Z"
    }
   },
   "outputs": [],
   "source": [
    "batch = 128 # Batch size for datalaoder and subsequent model\n",
    "\n",
    "\n",
    "# Training dataloader\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_loader = DataLoader(train_data, sampler=train_sampler, batch_size=batch)\n",
    "\n",
    "# Validation dataloader\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_loader = DataLoader(val_data, sampler = val_sampler, batch_size=batch)\n",
    "\n",
    "# Testing dataloader\n",
    "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
    "test_sampler = SequentialSampler(test_data)\n",
    "test_loader = DataLoader(test_data, sampler = test_sampler, batch_size=batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Architecture\n",
    "\n",
    "Using transfer learning is the heart of our model. The BERT model is already trained with 110 million parameters. It is very important that we do not train the base model further, so we freeze the parameters of our base model by disallowing gradient calculations.\n",
    "\n",
    "We inherit from the PyTorch `nn` module so that we can start building our neural network. In our `__init__` all we are taking in is our `BERT` model that was instantiated earlier. After our `BERT` model is in-place we follow that by passing the outputs from the pre-trained model into our `LSTM` layer. Our inputs are then passed through a series of `fully connected layer`, with all layers after the `LSTM` layer are separated with a `batchnorm` layer. Our inputs are then softmaxed to return a vector with lower values minimized and larger values maximized on a 0-to-1 scale.\n",
    "\n",
    "#### LSTM\n",
    "\n",
    ">The Long Short Term Memory architecture was motivated by an analysis of error flow in existing RNNs which found that long time lags were inaccessible to existing architectures, because backpropagated error either blows up or decays exponentially.<br><br>\n",
    "An LSTM layer consists of a set of recurrently connected blocks, known as memory blocks. These blocks can be thought of as a differentiable version of the memory chips in a digital computer. Each one contains one or more recurrently connected memory cells and three multiplicative units – the input, output and forget gates – that provide continuous analogues of write, read and reset operations for the cells. … The net can only interact with the cells via the gates.\n",
    "<br><br>— Alex Graves, et al., Framewise Phoneme Classification with Bidirectional LSTM and Other Neural Network Architectures, 2005.\n",
    "\n",
    "#### Batch Normalization\n",
    "\n",
    "The issue with deep neural networks is that model weights are updated backwards from outputs to inputs, but in reality model layers are updated simultaneously during the updating process, therefore the model is always chasing a moving target. \n",
    "\n",
    "Batch normalization has taken up this issue and seeks to solve it:\n",
    "\n",
    "> Batch normalization provides an elegant way of reparametrizing almost any deep network. The reparametrization significantly reduces the problem of coordinating updates across many layers.\n",
    "<br><br>— Page 318, Deep Learning, 2016.\n",
    "\n",
    "It does this by scaling the output of the layers. Standardizing the activations during each mini-batch, such as activations from a previous layer. This means that the assumptions a previous layer makes about the subsequent layer's weight spread will not change.  This stabilizes and speeds up the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:08.112035Z",
     "start_time": "2020-11-27T21:02:08.104036Z"
    }
   },
   "outputs": [],
   "source": [
    "# Freeze BERT Parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:08.122038Z",
     "start_time": "2020-11-27T21:02:08.114034Z"
    }
   },
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    \n",
    "    def __init__(self, bert):\n",
    "        '''\n",
    "        Transfer learning deep neural network based on Google AI's BERT\n",
    "        NLP architecture. Takes an instantiated BERT model as input.\n",
    "        '''\n",
    "        \n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert\n",
    "        \n",
    "        self.droput = nn.Dropout(0.1)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.lstm = nn.LSTM(768,512, bidirectional=True, num_layers=2, dropout=.1)\n",
    "        self.bn = nn.BatchNorm1d(1024)\n",
    "        self.fc1 = nn.Linear(1024,512)\n",
    "        self.bn1 = nn.BatchNorm1d(512)\n",
    "        self.fc2 = nn.Linear(512,256)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.fc3 = nn.Linear(256,128)\n",
    "        self.bn3 = nn.BatchNorm1d(128)\n",
    "        self.fc4 = nn.Linear(128,2)\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        \n",
    "\n",
    "    def forward(self, sent_id):\n",
    "        '''\n",
    "        Forward pass for model\n",
    "        '''\n",
    "        _, x = self.bert(sent_id)\n",
    "        \n",
    "        x = x.unsqueeze(0)\n",
    "        x, _ = self.lstm(x)\n",
    "        x = x.squeeze(0)\n",
    "        x = self.bn(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn3(x)\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        x = self.softmax(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdamW \n",
    "\n",
    "**AdamW** is the newest generation of adaptive optimizers that are paving the way for super-fast convergance and improving generalization performance.\n",
    "\n",
    "AdamW works by essentially decoupling the weight decay and the optimization step. This allows the two to optimize separately and therefore find an optimal rate for moth. This results in faster convergance and better overall generalization for the models.\n",
    "\n",
    "![AdamW](Images/adamw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:10.635034Z",
     "start_time": "2020-11-27T21:02:08.125033Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Weights: [1.02776019 0.9737    ]\n"
     ]
    }
   ],
   "source": [
    "# Model instantiation \n",
    "model = BERT_Arch(bert)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # Select device programatically\n",
    "model = model.to(device) # Send model to device (GPU locally)\n",
    "\n",
    "# AdamW optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 2e-5) \n",
    "\n",
    "# Computation of class weights for training\n",
    "class_weights = compute_class_weight('balanced', [0,1], train_labels)\n",
    "print(\"Class Weights:\",class_weights)\n",
    "weights= torch.tensor(class_weights,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# Negative log-likelihood loss with weights passed\n",
    "cross_entropy = nn.NLLLoss(weight=weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:10.639037Z",
     "start_time": "2020-11-27T21:02:10.636034Z"
    }
   },
   "outputs": [],
   "source": [
    "epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:10.650034Z",
     "start_time": "2020-11-27T21:02:10.640034Z"
    }
   },
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    \"\"\"\n",
    "    Training function that returns average loss, total accuracy, and predictions\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    total_preds=[]\n",
    "    total_acc=[]\n",
    "    t0 = time.time()\n",
    "    # iterate over batches\n",
    "    for step, batch in enumerate(train_loader):\n",
    "    \n",
    "        if step % 100 == 0 and not step == 0:\n",
    "          lapsed = time.time() - t0\n",
    "          print('  Batch {:>5,}  of  {:>5,}.  Batch took {} secs'.format(step,\n",
    "                                                                            len(train_loader),\n",
    "                                                                            round(lapsed, 3)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "        \n",
    "        # Pulling apart batch\n",
    "        sent_id, mask, labels = batch\n",
    "        \n",
    "        # Start model\n",
    "        model.zero_grad()      \n",
    "        preds = model(sent_id) #Get predictions\n",
    "        loss = cross_entropy(preds, labels) # Passing through NNL for loss\n",
    "        total_loss = total_loss + loss.item() # Collect total loss\n",
    "\n",
    "        loss.backward() # Backpropagation\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) #Clipping to avoid exploding grads\n",
    "        optimizer.step() #Step AdamW\n",
    "        \n",
    "        preds_max = F.softmax(preds, dim=1) # Softmax to sum k-real vector to 1\n",
    "        preds_max = torch.argmax(preds_max, dim=1) # Argmax pulls index of highest value\n",
    "        wrong = torch.where(preds_max!=labels, # where to generate correct/incorrect tensor\n",
    "                           torch.tensor([1.]).to(device),\n",
    "                           torch.tensor([0.]).to(device))\n",
    "        tot_wrong = int(torch.sum(wrong).detach().cpu()) # sum total incorrect for acc calc\n",
    "        acc = 1 - tot_wrong/len(labels) # Normalized accuracy calculation\n",
    "        total_acc.append(acc) # Appends accuracy \n",
    "\n",
    "        preds=preds.detach().cpu().numpy() # Send predictions to CPU\n",
    "        total_preds.append(preds)\n",
    "    \n",
    "    # Epoch training loss\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    total = time.time() - t0\n",
    "    print('\\nTime in seconds: {}'.format(round(total,3)))\n",
    "    print('Average accuracy: {}'.format((np.average(total_acc))))\n",
    "    \n",
    "\n",
    "    \n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    return avg_loss, total_preds, total_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-27T21:02:10.657036Z",
     "start_time": "2020-11-27T21:02:10.651033Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "    \n",
    "    \"\"\"\n",
    "    Similar to training, but with model in eval mode and predictions\n",
    "    with no local gradient calculation required.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nEvaluating...\")\n",
    "    t0 = time.time()\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    total_loss = 0\n",
    "    total_accuracy = 0\n",
    "\n",
    "    # Save predictions\n",
    "    total_preds = []\n",
    "\n",
    "    # iterate through loader\n",
    "    for step,batch in enumerate(val_loader):\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            lapsed = time.time() - t0\n",
    "            print('  Batch {:>5,}  of  {:>5,}. \\n  Eval took {} secs'.format(step,\n",
    "                                                                            len(val_loader),\n",
    "                                                                            round(lapsed, 3)))\n",
    "            \n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id)\n",
    "            loss = cross_entropy(preds,labels)\n",
    "            total_loss = total_loss + loss.item()\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            total_preds.append(preds)\n",
    "\n",
    "    avg_loss = total_loss / len(val_loader) \n",
    "    total_preds  = np.concatenate(total_preds, axis=0)\n",
    "\n",
    "    return avg_loss, total_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:47.484384Z",
     "start_time": "2020-11-27T21:02:37.471034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------\n",
      "Epoch 1 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.791 secs\n",
      "  Batch   200  of    533.  Batch took 69.511 secs\n",
      "  Batch   300  of    533.  Batch took 104.305 secs\n",
      "  Batch   400  of    533.  Batch took 139.159 secs\n",
      "  Batch   500  of    533.  Batch took 174.03 secs\n",
      "\n",
      "Time in seconds: 185.383\n",
      "Average accuracy: 0.6603759976473391\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.351 secs\n",
      "\n",
      "  Training Loss: 0.639\n",
      "  Validation Loss: 0.636\n",
      "---------------------------------------------\n",
      "Epoch 2 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.926 secs\n",
      "  Batch   200  of    533.  Batch took 69.893 secs\n",
      "  Batch   300  of    533.  Batch took 104.801 secs\n",
      "  Batch   400  of    533.  Batch took 139.723 secs\n",
      "  Batch   500  of    533.  Batch took 174.714 secs\n",
      "\n",
      "Time in seconds: 186.073\n",
      "Average accuracy: 0.7059918401381816\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.425 secs\n",
      "\n",
      "  Training Loss: 0.696\n",
      "  Validation Loss: 0.71\n",
      "---------------------------------------------\n",
      "Epoch 3 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.951 secs\n",
      "  Batch   200  of    533.  Batch took 69.933 secs\n",
      "  Batch   300  of    533.  Batch took 104.893 secs\n",
      "  Batch   400  of    533.  Batch took 139.857 secs\n",
      "  Batch   500  of    533.  Batch took 174.89 secs\n",
      "\n",
      "Time in seconds: 187.514\n",
      "Average accuracy: 0.7151798277941571\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 35.742 secs\n",
      "\n",
      "  Training Loss: 0.71\n",
      "  Validation Loss: 0.678\n",
      "---------------------------------------------\n",
      "Epoch 4 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 37.66 secs\n",
      "  Batch   200  of    533.  Batch took 72.665 secs\n",
      "  Batch   300  of    533.  Batch took 107.835 secs\n",
      "  Batch   400  of    533.  Batch took 145.183 secs\n",
      "  Batch   500  of    533.  Batch took 183.923 secs\n",
      "\n",
      "Time in seconds: 196.804\n",
      "Average accuracy: 0.7212622658506805\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 36.327 secs\n",
      "\n",
      "  Training Loss: 0.716\n",
      "  Validation Loss: 0.693\n",
      "---------------------------------------------\n",
      "Epoch 5 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 38.71 secs\n",
      "  Batch   200  of    533.  Batch took 77.61 secs\n",
      "  Batch   300  of    533.  Batch took 114.966 secs\n",
      "  Batch   400  of    533.  Batch took 151.753 secs\n",
      "  Batch   500  of    533.  Batch took 188.201 secs\n",
      "\n",
      "Time in seconds: 199.914\n",
      "Average accuracy: 0.7253715119568779\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 35.017 secs\n",
      "\n",
      "  Training Loss: 0.722\n",
      "  Validation Loss: 0.699\n",
      "---------------------------------------------\n",
      "Epoch 6 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 38.512 secs\n",
      "  Batch   200  of    533.  Batch took 75.671 secs\n",
      "  Batch   300  of    533.  Batch took 112.113 secs\n",
      "  Batch   400  of    533.  Batch took 149.415 secs\n",
      "  Batch   500  of    533.  Batch took 186.678 secs\n",
      "\n",
      "Time in seconds: 198.723\n",
      "Average accuracy: 0.7319353241609339\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 34.609 secs\n",
      "\n",
      "  Training Loss: 0.729\n",
      "  Validation Loss: 0.678\n",
      "---------------------------------------------\n",
      "Epoch 7 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 36.887 secs\n",
      "  Batch   200  of    533.  Batch took 72.47 secs\n",
      "  Batch   300  of    533.  Batch took 108.554 secs\n",
      "  Batch   400  of    533.  Batch took 144.357 secs\n",
      "  Batch   500  of    533.  Batch took 180.796 secs\n",
      "\n",
      "Time in seconds: 192.189\n",
      "Average accuracy: 0.7325514086184818\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 35.906 secs\n",
      "\n",
      "  Training Loss: 0.73\n",
      "  Validation Loss: 0.681\n",
      "---------------------------------------------\n",
      "Epoch 8 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 36.409 secs\n",
      "  Batch   200  of    533.  Batch took 74.449 secs\n",
      "  Batch   300  of    533.  Batch took 112.017 secs\n",
      "  Batch   400  of    533.  Batch took 148.146 secs\n",
      "  Batch   500  of    533.  Batch took 184.5 secs\n",
      "\n",
      "Time in seconds: 196.582\n",
      "Average accuracy: 0.7314204469311176\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 36.047 secs\n",
      "\n",
      "  Training Loss: 0.73\n",
      "  Validation Loss: 0.76\n",
      "---------------------------------------------\n",
      "Epoch 9 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 37.131 secs\n",
      "  Batch   200  of    533.  Batch took 74.441 secs\n",
      "  Batch   300  of    533.  Batch took 111.165 secs\n",
      "  Batch   400  of    533.  Batch took 147.465 secs\n",
      "  Batch   500  of    533.  Batch took 182.461 secs\n",
      "\n",
      "Time in seconds: 194.379\n",
      "Average accuracy: 0.7313311053783614\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 38.085 secs\n",
      "\n",
      "  Training Loss: 0.73\n",
      "  Validation Loss: 0.623\n",
      "---------------------------------------------\n",
      "Epoch 10 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 37.475 secs\n",
      "  Batch   200  of    533.  Batch took 75.694 secs\n",
      "  Batch   300  of    533.  Batch took 113.176 secs\n",
      "  Batch   400  of    533.  Batch took 152.091 secs\n",
      "  Batch   500  of    533.  Batch took 191.72 secs\n",
      "\n",
      "Time in seconds: 206.155\n",
      "Average accuracy: 0.7327712725959677\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 39.116 secs\n",
      "\n",
      "  Training Loss: 0.731\n",
      "  Validation Loss: 0.759\n",
      "---------------------------------------------\n",
      "Epoch 11 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 43.548 secs\n",
      "  Batch   200  of    533.  Batch took 88.079 secs\n",
      "  Batch   300  of    533.  Batch took 131.481 secs\n",
      "  Batch   400  of    533.  Batch took 175.893 secs\n",
      "  Batch   500  of    533.  Batch took 220.53 secs\n",
      "\n",
      "Time in seconds: 235.221\n",
      "Average accuracy: 0.7327245078769469\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 42.742 secs\n",
      "\n",
      "  Training Loss: 0.732\n",
      "  Validation Loss: 0.722\n",
      "---------------------------------------------\n",
      "Epoch 12 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 44.802 secs\n",
      "  Batch   200  of    533.  Batch took 85.556 secs\n",
      "  Batch   300  of    533.  Batch took 126.375 secs\n",
      "  Batch   400  of    533.  Batch took 166.464 secs\n",
      "  Batch   500  of    533.  Batch took 206.936 secs\n",
      "\n",
      "Time in seconds: 218.906\n",
      "Average accuracy: 0.7363628495488251\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 35.737 secs\n",
      "\n",
      "  Training Loss: 0.735\n",
      "  Validation Loss: 0.717\n",
      "---------------------------------------------\n",
      "Epoch 13 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 38.961 secs\n",
      "  Batch   200  of    533.  Batch took 75.694 secs\n",
      "  Batch   300  of    533.  Batch took 112.358 secs\n",
      "  Batch   400  of    533.  Batch took 150.216 secs\n",
      "  Batch   500  of    533.  Batch took 186.39 secs\n",
      "\n",
      "Time in seconds: 198.158\n",
      "Average accuracy: 0.7389677141963726\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 34.566 secs\n",
      "\n",
      "  Training Loss: 0.738\n",
      "  Validation Loss: 0.68\n",
      "---------------------------------------------\n",
      "Epoch 14 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 36.341 secs\n",
      "  Batch   200  of    533.  Batch took 76.464 secs\n",
      "  Batch   300  of    533.  Batch took 113.76 secs\n",
      "  Batch   400  of    533.  Batch took 148.832 secs\n",
      "  Batch   500  of    533.  Batch took 183.91 secs\n",
      "\n",
      "Time in seconds: 195.272\n",
      "Average accuracy: 0.7365969058042229\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.636 secs\n",
      "\n",
      "  Training Loss: 0.735\n",
      "  Validation Loss: 0.677\n",
      "---------------------------------------------\n",
      "Epoch 15 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.969 secs\n",
      "  Batch   200  of    533.  Batch took 69.93 secs\n",
      "  Batch   300  of    533.  Batch took 106.296 secs\n",
      "  Batch   400  of    533.  Batch took 142.487 secs\n",
      "  Batch   500  of    533.  Batch took 178.662 secs\n",
      "\n",
      "Time in seconds: 190.815\n",
      "Average accuracy: 0.737722748965127\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 35.664 secs\n",
      "\n",
      "  Training Loss: 0.737\n",
      "  Validation Loss: 0.736\n",
      "---------------------------------------------\n",
      "Epoch 16 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 40.757 secs\n",
      "  Batch   200  of    533.  Batch took 82.892 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   300  of    533.  Batch took 124.456 secs\n",
      "  Batch   400  of    533.  Batch took 166.038 secs\n",
      "  Batch   500  of    533.  Batch took 207.584 secs\n",
      "\n",
      "Time in seconds: 221.094\n",
      "Average accuracy: 0.7369614844843504\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 41.157 secs\n",
      "\n",
      "  Training Loss: 0.736\n",
      "  Validation Loss: 0.743\n",
      "---------------------------------------------\n",
      "Epoch 17 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 42.161 secs\n",
      "  Batch   200  of    533.  Batch took 84.294 secs\n",
      "  Batch   300  of    533.  Batch took 122.222 secs\n",
      "  Batch   400  of    533.  Batch took 158.501 secs\n",
      "  Batch   500  of    533.  Batch took 199.987 secs\n",
      "\n",
      "Time in seconds: 213.682\n",
      "Average accuracy: 0.7384996016855773\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 39.862 secs\n",
      "\n",
      "  Training Loss: 0.738\n",
      "  Validation Loss: 0.665\n",
      "---------------------------------------------\n",
      "Epoch 18 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 41.464 secs\n",
      "  Batch   200  of    533.  Batch took 83.373 secs\n",
      "  Batch   300  of    533.  Batch took 122.822 secs\n",
      "  Batch   400  of    533.  Batch took 161.168 secs\n",
      "  Batch   500  of    533.  Batch took 199.214 secs\n",
      "\n",
      "Time in seconds: 210.75\n",
      "Average accuracy: 0.740186156154144\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 37.588 secs\n",
      "\n",
      "  Training Loss: 0.739\n",
      "  Validation Loss: 0.668\n",
      "---------------------------------------------\n",
      "Epoch 19 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 41.035 secs\n",
      "  Batch   200  of    533.  Batch took 81.908 secs\n",
      "  Batch   300  of    533.  Batch took 123.415 secs\n",
      "  Batch   400  of    533.  Batch took 165.076 secs\n",
      "  Batch   500  of    533.  Batch took 204.377 secs\n",
      "\n",
      "Time in seconds: 216.886\n",
      "Average accuracy: 0.7401370648321868\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 36.542 secs\n",
      "\n",
      "  Training Loss: 0.739\n",
      "  Validation Loss: 0.749\n",
      "---------------------------------------------\n",
      "Epoch 20 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 40.612 secs\n",
      "  Batch   200  of    533.  Batch took 82.546 secs\n",
      "  Batch   300  of    533.  Batch took 123.269 secs\n",
      "  Batch   400  of    533.  Batch took 163.24 secs\n",
      "  Batch   500  of    533.  Batch took 203.539 secs\n",
      "\n",
      "Time in seconds: 215.417\n",
      "Average accuracy: 0.7385161205664255\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.594 secs\n",
      "\n",
      "  Training Loss: 0.738\n",
      "  Validation Loss: 0.664\n",
      "---------------------------------------------\n",
      "Epoch 21 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.983 secs\n",
      "  Batch   200  of    533.  Batch took 69.957 secs\n",
      "  Batch   300  of    533.  Batch took 104.94 secs\n",
      "  Batch   400  of    533.  Batch took 139.907 secs\n",
      "  Batch   500  of    533.  Batch took 174.88 secs\n",
      "\n",
      "Time in seconds: 186.259\n",
      "Average accuracy: 0.7400528418058906\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.435 secs\n",
      "\n",
      "  Training Loss: 0.74\n",
      "  Validation Loss: 0.729\n",
      "---------------------------------------------\n",
      "Epoch 22 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 35.001 secs\n",
      "  Batch   200  of    533.  Batch took 70.075 secs\n",
      "  Batch   300  of    533.  Batch took 105.299 secs\n",
      "  Batch   400  of    533.  Batch took 149.966 secs\n",
      "  Batch   500  of    533.  Batch took 195.458 secs\n",
      "\n",
      "Time in seconds: 210.549\n",
      "Average accuracy: 0.7397464281991721\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 44.672 secs\n",
      "\n",
      "  Training Loss: 0.739\n",
      "  Validation Loss: 0.709\n",
      "---------------------------------------------\n",
      "Epoch 23 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 44.123 secs\n",
      "  Batch   200  of    533.  Batch took 83.897 secs\n",
      "  Batch   300  of    533.  Batch took 123.438 secs\n",
      "  Batch   400  of    533.  Batch took 167.884 secs\n",
      "  Batch   500  of    533.  Batch took 214.694 secs\n",
      "\n",
      "Time in seconds: 227.596\n",
      "Average accuracy: 0.7408022406116919\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 37.515 secs\n",
      "\n",
      "  Training Loss: 0.74\n",
      "  Validation Loss: 0.678\n",
      "---------------------------------------------\n",
      "Epoch 24 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 39.312 secs\n",
      "  Batch   200  of    533.  Batch took 103.824 secs\n",
      "  Batch   300  of    533.  Batch took 188.971 secs\n",
      "  Batch   400  of    533.  Batch took 274.559 secs\n",
      "  Batch   500  of    533.  Batch took 358.749 secs\n",
      "\n",
      "Time in seconds: 386.325\n",
      "Average accuracy: 0.7425772059918401\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 82.434 secs\n",
      "\n",
      "  Training Loss: 0.742\n",
      "  Validation Loss: 0.704\n",
      "---------------------------------------------\n",
      "Epoch 25 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 83.738 secs\n",
      "  Batch   200  of    533.  Batch took 169.92 secs\n",
      "  Batch   300  of    533.  Batch took 256.784 secs\n",
      "  Batch   400  of    533.  Batch took 343.502 secs\n",
      "  Batch   500  of    533.  Batch took 430.265 secs\n",
      "\n",
      "Time in seconds: 458.253\n",
      "Average accuracy: 0.7419881101283541\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 83.745 secs\n",
      "\n",
      "  Training Loss: 0.742\n",
      "  Validation Loss: 0.715\n",
      "---------------------------------------------\n",
      "Epoch 26 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 85.871 secs\n",
      "  Batch   200  of    533.  Batch took 170.607 secs\n",
      "  Batch   300  of    533.  Batch took 248.237 secs\n",
      "  Batch   400  of    533.  Batch took 293.204 secs\n",
      "  Batch   500  of    533.  Batch took 341.48 secs\n",
      "\n",
      "Time in seconds: 357.559\n",
      "Average accuracy: 0.7429115388337949\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 41.805 secs\n",
      "\n",
      "  Training Loss: 0.743\n",
      "  Validation Loss: 0.638\n",
      "---------------------------------------------\n",
      "Epoch 27 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 39.761 secs\n",
      "  Batch   200  of    533.  Batch took 78.7 secs\n",
      "  Batch   300  of    533.  Batch took 117.248 secs\n",
      "  Batch   400  of    533.  Batch took 156.079 secs\n",
      "  Batch   500  of    533.  Batch took 202.124 secs\n",
      "\n",
      "Time in seconds: 232.308\n",
      "Average accuracy: 0.7416112004526639\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 85.694 secs\n",
      "\n",
      "  Training Loss: 0.742\n",
      "  Validation Loss: 0.723\n",
      "---------------------------------------------\n",
      "Epoch 28 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 89.458 secs\n",
      "  Batch   200  of    533.  Batch took 178.533 secs\n",
      "  Batch   300  of    533.  Batch took 267.345 secs\n",
      "  Batch   400  of    533.  Batch took 357.982 secs\n",
      "  Batch   500  of    533.  Batch took 447.532 secs\n",
      "\n",
      "Time in seconds: 475.909\n",
      "Average accuracy: 0.742006024970964\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 87.704 secs\n",
      "\n",
      "  Training Loss: 0.741\n",
      "  Validation Loss: 0.675\n",
      "---------------------------------------------\n",
      "Epoch 29 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 61.859 secs\n",
      "  Batch   200  of    533.  Batch took 112.736 secs\n",
      "  Batch   300  of    533.  Batch took 159.674 secs\n",
      "  Batch   400  of    533.  Batch took 200.227 secs\n",
      "  Batch   500  of    533.  Batch took 280.141 secs\n",
      "\n",
      "Time in seconds: 308.651\n",
      "Average accuracy: 0.7441418464665415\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 84.862 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.706\n",
      "---------------------------------------------\n",
      "Epoch 30 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 87.047 secs\n",
      "  Batch   200  of    533.  Batch took 177.209 secs\n",
      "  Batch   300  of    533.  Batch took 269.264 secs\n",
      "  Batch   400  of    533.  Batch took 359.855 secs\n",
      "  Batch   500  of    533.  Batch took 449.348 secs\n",
      "\n",
      "Time in seconds: 477.891\n",
      "Average accuracy: 0.7439252397331666\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 83.463 secs\n",
      "\n",
      "  Training Loss: 0.743\n",
      "  Validation Loss: 0.719\n",
      "---------------------------------------------\n",
      "Epoch 31 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 86.073 secs\n",
      "  Batch   200  of    533.  Batch took 175.157 secs\n",
      "  Batch   300  of    533.  Batch took 261.759 secs\n",
      "  Batch   400  of    533.  Batch took 348.025 secs\n",
      "  Batch   500  of    533.  Batch took 435.469 secs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Time in seconds: 460.008\n",
      "Average accuracy: 0.7449631373030764\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 79.16 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.738\n",
      "---------------------------------------------\n",
      "Epoch 32 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 87.758 secs\n",
      "  Batch   200  of    533.  Batch took 174.939 secs\n",
      "  Batch   300  of    533.  Batch took 262.638 secs\n",
      "  Batch   400  of    533.  Batch took 346.752 secs\n",
      "  Batch   500  of    533.  Batch took 387.256 secs\n",
      "\n",
      "Time in seconds: 398.624\n",
      "Average accuracy: 0.7446548624140087\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.396 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.675\n",
      "---------------------------------------------\n",
      "Epoch 33 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.939 secs\n",
      "  Batch   200  of    533.  Batch took 69.86 secs\n",
      "  Batch   300  of    533.  Batch took 104.77 secs\n",
      "  Batch   400  of    533.  Batch took 139.694 secs\n",
      "  Batch   500  of    533.  Batch took 174.591 secs\n",
      "\n",
      "Time in seconds: 185.945\n",
      "Average accuracy: 0.7444212714791983\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.385 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.704\n",
      "---------------------------------------------\n",
      "Epoch 34 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.985 secs\n",
      "  Batch   200  of    533.  Batch took 69.914 secs\n",
      "  Batch   300  of    533.  Batch took 104.84 secs\n",
      "  Batch   400  of    533.  Batch took 139.762 secs\n",
      "  Batch   500  of    533.  Batch took 174.68 secs\n",
      "\n",
      "Time in seconds: 186.037\n",
      "Average accuracy: 0.7454482340153072\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.391 secs\n",
      "\n",
      "  Training Loss: 0.745\n",
      "  Validation Loss: 0.763\n",
      "---------------------------------------------\n",
      "Epoch 35 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.908 secs\n",
      "  Batch   200  of    533.  Batch took 69.847 secs\n",
      "  Batch   300  of    533.  Batch took 104.756 secs\n",
      "  Batch   400  of    533.  Batch took 139.672 secs\n",
      "  Batch   500  of    533.  Batch took 174.585 secs\n",
      "\n",
      "Time in seconds: 185.935\n",
      "Average accuracy: 0.7441602266297388\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.379 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.656\n",
      "---------------------------------------------\n",
      "Epoch 36 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.892 secs\n",
      "  Batch   200  of    533.  Batch took 69.79 secs\n",
      "  Batch   300  of    533.  Batch took 104.698 secs\n",
      "  Batch   400  of    533.  Batch took 139.619 secs\n",
      "  Batch   500  of    533.  Batch took 174.541 secs\n",
      "\n",
      "Time in seconds: 185.888\n",
      "Average accuracy: 0.746269524851842\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.378 secs\n",
      "\n",
      "  Training Loss: 0.746\n",
      "  Validation Loss: 0.742\n",
      "---------------------------------------------\n",
      "Epoch 37 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.909 secs\n",
      "  Batch   200  of    533.  Batch took 69.815 secs\n",
      "  Batch   300  of    533.  Batch took 104.696 secs\n",
      "  Batch   400  of    533.  Batch took 139.582 secs\n",
      "  Batch   500  of    533.  Batch took 174.479 secs\n",
      "\n",
      "Time in seconds: 185.834\n",
      "Average accuracy: 0.7446543970934214\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.411 secs\n",
      "\n",
      "  Training Loss: 0.744\n",
      "  Validation Loss: 0.707\n",
      "---------------------------------------------\n",
      "Epoch 38 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.911 secs\n",
      "  Batch   200  of    533.  Batch took 69.833 secs\n",
      "  Batch   300  of    533.  Batch took 104.851 secs\n",
      "  Batch   400  of    533.  Batch took 139.766 secs\n",
      "  Batch   500  of    533.  Batch took 174.677 secs\n",
      "\n",
      "Time in seconds: 186.024\n",
      "Average accuracy: 0.746649691771643\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.374 secs\n",
      "\n",
      "  Training Loss: 0.746\n",
      "  Validation Loss: 0.769\n",
      "---------------------------------------------\n",
      "Epoch 39 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.886 secs\n",
      "  Batch   200  of    533.  Batch took 69.791 secs\n",
      "  Batch   300  of    533.  Batch took 104.703 secs\n",
      "  Batch   400  of    533.  Batch took 139.629 secs\n",
      "  Batch   500  of    533.  Batch took 174.54 secs\n",
      "\n",
      "Time in seconds: 185.899\n",
      "Average accuracy: 0.7470775540516394\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.389 secs\n",
      "\n",
      "  Training Loss: 0.746\n",
      "  Validation Loss: 0.732\n",
      "---------------------------------------------\n",
      "Epoch 40 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.922 secs\n",
      "  Batch   200  of    533.  Batch took 69.828 secs\n",
      "  Batch   300  of    533.  Batch took 104.738 secs\n",
      "  Batch   400  of    533.  Batch took 139.657 secs\n",
      "  Batch   500  of    533.  Batch took 174.565 secs\n",
      "\n",
      "Time in seconds: 185.921\n",
      "Average accuracy: 0.7478511495279788\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.365 secs\n",
      "\n",
      "  Training Loss: 0.747\n",
      "  Validation Loss: 0.705\n",
      "---------------------------------------------\n",
      "Epoch 41 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.928 secs\n",
      "  Batch   200  of    533.  Batch took 69.848 secs\n",
      "  Batch   300  of    533.  Batch took 104.768 secs\n",
      "  Batch   400  of    533.  Batch took 139.699 secs\n",
      "  Batch   500  of    533.  Batch took 174.616 secs\n",
      "\n",
      "Time in seconds: 185.962\n",
      "Average accuracy: 0.7490828531224872\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.422 secs\n",
      "\n",
      "  Training Loss: 0.749\n",
      "  Validation Loss: 0.667\n",
      "---------------------------------------------\n",
      "Epoch 42 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.948 secs\n",
      "  Batch   200  of    533.  Batch took 69.887 secs\n",
      "  Batch   300  of    533.  Batch took 104.813 secs\n",
      "  Batch   400  of    533.  Batch took 139.752 secs\n",
      "  Batch   500  of    533.  Batch took 174.686 secs\n",
      "\n",
      "Time in seconds: 186.053\n",
      "Average accuracy: 0.7465319656630632\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.374 secs\n",
      "\n",
      "  Training Loss: 0.746\n",
      "  Validation Loss: 0.75\n",
      "---------------------------------------------\n",
      "Epoch 43 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.924 secs\n",
      "  Batch   200  of    533.  Batch took 69.854 secs\n",
      "  Batch   300  of    533.  Batch took 104.776 secs\n",
      "  Batch   400  of    533.  Batch took 139.681 secs\n",
      "  Batch   500  of    533.  Batch took 174.592 secs\n",
      "\n",
      "Time in seconds: 185.947\n",
      "Average accuracy: 0.7468576900741535\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.384 secs\n",
      "\n",
      "  Training Loss: 0.747\n",
      "  Validation Loss: 0.745\n",
      "---------------------------------------------\n",
      "Epoch 44 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.909 secs\n",
      "  Batch   200  of    533.  Batch took 69.829 secs\n",
      "  Batch   300  of    533.  Batch took 104.736 secs\n",
      "  Batch   400  of    533.  Batch took 139.656 secs\n",
      "  Batch   500  of    533.  Batch took 174.603 secs\n",
      "\n",
      "Time in seconds: 185.96\n",
      "Average accuracy: 0.7465173080645642\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.377 secs\n",
      "\n",
      "  Training Loss: 0.747\n",
      "  Validation Loss: 0.714\n",
      "---------------------------------------------\n",
      "Epoch 45 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.935 secs\n",
      "  Batch   200  of    533.  Batch took 69.846 secs\n",
      "  Batch   300  of    533.  Batch took 104.759 secs\n",
      "  Batch   400  of    533.  Batch took 139.673 secs\n",
      "  Batch   500  of    533.  Batch took 174.586 secs\n",
      "\n",
      "Time in seconds: 185.942\n",
      "Average accuracy: 0.7489509347359957\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.382 secs\n",
      "\n",
      "  Training Loss: 0.749\n",
      "  Validation Loss: 0.641\n",
      "---------------------------------------------\n",
      "Epoch 46 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.92 secs\n",
      "  Batch   200  of    533.  Batch took 69.818 secs\n",
      "  Batch   300  of    533.  Batch took 104.738 secs\n",
      "  Batch   400  of    533.  Batch took 139.675 secs\n",
      "  Batch   500  of    533.  Batch took 174.606 secs\n",
      "\n",
      "Time in seconds: 185.962\n",
      "Average accuracy: 0.7454922068108044\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.389 secs\n",
      "\n",
      "  Training Loss: 0.745\n",
      "  Validation Loss: 0.756\n",
      "---------------------------------------------\n",
      "Epoch 47 / 50\n",
      "---------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   100  of    533.  Batch took 34.94 secs\n",
      "  Batch   200  of    533.  Batch took 69.874 secs\n",
      "  Batch   300  of    533.  Batch took 104.812 secs\n",
      "  Batch   400  of    533.  Batch took 139.739 secs\n",
      "  Batch   500  of    533.  Batch took 174.651 secs\n",
      "\n",
      "Time in seconds: 186.008\n",
      "Average accuracy: 0.7478104339765925\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.398 secs\n",
      "\n",
      "  Training Loss: 0.748\n",
      "  Validation Loss: 0.725\n",
      "---------------------------------------------\n",
      "Epoch 48 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.926 secs\n",
      "  Batch   200  of    533.  Batch took 69.847 secs\n",
      "  Batch   300  of    533.  Batch took 104.739 secs\n",
      "  Batch   400  of    533.  Batch took 139.638 secs\n",
      "  Batch   500  of    533.  Batch took 174.552 secs\n",
      "\n",
      "Time in seconds: 185.907\n",
      "Average accuracy: 0.7483097229667353\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.345 secs\n",
      "\n",
      "  Training Loss: 0.748\n",
      "  Validation Loss: 0.669\n",
      "---------------------------------------------\n",
      "Epoch 49 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.9 secs\n",
      "  Batch   200  of    533.  Batch took 69.811 secs\n",
      "  Batch   300  of    533.  Batch took 104.704 secs\n",
      "  Batch   400  of    533.  Batch took 139.588 secs\n",
      "  Batch   500  of    533.  Batch took 174.46 secs\n",
      "\n",
      "Time in seconds: 185.8\n",
      "Average accuracy: 0.7496998682212097\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.332 secs\n",
      "\n",
      "  Training Loss: 0.749\n",
      "  Validation Loss: 0.748\n",
      "---------------------------------------------\n",
      "Epoch 50 / 50\n",
      "---------------------------------------------\n",
      "  Batch   100  of    533.  Batch took 34.912 secs\n",
      "  Batch   200  of    533.  Batch took 69.805 secs\n",
      "  Batch   300  of    533.  Batch took 104.695 secs\n",
      "  Batch   400  of    533.  Batch took 139.567 secs\n",
      "  Batch   500  of    533.  Batch took 174.449 secs\n",
      "\n",
      "Time in seconds: 185.802\n",
      "Average accuracy: 0.7468998015873016\n",
      "\n",
      "Evaluating...\n",
      "  Batch   100  of    115. \n",
      "  Eval took 33.384 secs\n",
      "\n",
      "  Training Loss: 0.747\n",
      "  Validation Loss: 0.723\n",
      "\n",
      "------------------------\n",
      "Finished\n",
      "------------------------\n"
     ]
    }
   ],
   "source": [
    "# Creating lists to store epoch accuracy and losses\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "total_acc = []\n",
    "epoch_acc = []\n",
    "\n",
    "# Save flag for save state\n",
    "save = False\n",
    "\n",
    "# For save state generation \n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# Training loop for model\n",
    "for epoch in range(epochs):\n",
    "    print('---------------------------------------------')\n",
    "    print('Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    print('---------------------------------------------')\n",
    "    \n",
    "    #train model\n",
    "    train_loss, _, total_acc = train()\n",
    "\n",
    "    #evaluate model\n",
    "    valid_loss, _ = evaluate()\n",
    "    \n",
    "    epoch_acc.append(np.average(total_acc))\n",
    "    \n",
    "    #save the best model\n",
    "    if save:\n",
    "        if valid_loss < best_valid_loss:\n",
    "            best_valid_loss = valid_loss\n",
    "            torch.save(model.state_dict(), 'Data/BERT_weights.pt')\n",
    "\n",
    "    # append training and validation loss\n",
    "    train_losses.append(abs(train_loss))\n",
    "    valid_losses.append(abs(valid_loss))\n",
    "\n",
    "    print('\\n  Training Loss: {}'.format(abs(round(train_loss, 3))))\n",
    "    print('  Validation Loss: {}'.format(abs(round(valid_loss, 3))))\n",
    "print('\\n------------------------')   \n",
    "print('Finished')\n",
    "print('------------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T21:22:29.452745Z",
     "start_time": "2020-12-01T21:22:29.148744Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eZgcZbn+/3lmJpM9mWSSEEjIJEKCBESURUBEDijCT0Q9bsSR5SCGL8hRXDiKUeSIEXdUQDygsmUEOR5QUBRFRRBBiSIiREII2QiEbDNZJpNMZp7fH0+/TE1PVXVVdfWauq+rr+6qrq56u5b3fu9ne0VVyZAhQ4YMGfLRUOkGZMiQIUOG6kRGEBkyZMiQwRcZQWTIkCFDBl9kBJEhQ4YMGXyREUSGDBkyZPBFRhAZMmTIkMEXGUHsgRCRX4rIWWlvW0mIyAoReVMJ9nu/iJyb+9wuIr+Osm2C48wQkW0i0pi0rSH7VhHZP+39Bhwr8TmoNETkeBFZU+l2VBMygqgR5DoP9+oXkR2e5fY4+1LVU1T1prS3rUaIyCUi8oDP+kkisktEDo66L1XtUNWTUmrXIEJT1VWqOkZV+9LYf61DRGbmiG1b3ut9lW7bnoSmSjcgQzSo6hj3WURWAOeq6n3524lIk6ruLmfbqhy3AJeLyCxVfc6z/nTgCVX9Z4XalSEaWrL7uXLIFESNw8liEfmUiLwI3CAiE0Tk5yKyXkQ25z5P9/zGazY5W0T+KCJfz237nIicknDbWSLygIhsFZH7ROQaEVkU0O4obbxcRB7K7e/XIjLJ8/0ZIrJSRDaKyIKg86Oqa4DfAWfkfXUmcFOhduS1+WwR+aNn+c0i8i8R6RKRqwHxfLefiPwu174NItIhIi25724BZgB350bF/+UZMTflttlHRO4SkU0iskxEPuTZ92UicruI3Jw7N0+KyOFB5yDvP4zP/W597vx9VkQact/tLyJ/yP2fDSLy49x6EZErReSl3Hf/KKC89hORv+S2/ZmITMzt5xci8p957fmHiLwjStvzfnejiHxPRH6TOwd/EJE2z/fHiMijuTY8KiLHeL6bKCI3iMja3DX/ad6+P5H7ry+IyH/EbVs9ISOI+sBUYCLQBszHrusNueUZwA7g6pDfvw54GpgEfBX4gYhIgm1/BPwFaAUuY2in7EWUNr4f+A9gCtAMfBJAROYC1+b2v0/ueL6deg43edsiIgcAhwK3RmzHEOTI6v+Az2Ln4lng9d5NgCty7TsQ2Bc7J6jqGcAq4G05s9JXfQ5xK7Am9/t3A18SkRM9358G3Aa0AHdFaXMOVwHjgVcAb8SI0nWClwO/BiZg5/Oq3PqTgOOAObnjvQ/YGHKMM4Fzcm3fDXwnt/4m4ANuIxF5NTANuCdi2/PRnmvzJODvQEduvxOBX+SO2wp8E/iFiLTmfncLMAo4CLu3rvTscyp2fqYBHwSuEZEJCdtX+1DV7FVjL2AF8Kbc5+OBXcCIkO0PBTZ7lu/HTFQAZwPLPN+NAhSYGmdbrHPdDYzyfL8IWBTxP/m18bOe5QuAX+U+Xwrc5vludO4cvClg36OALcAxueWFwM8Snqs/5j6fCTzi2U6wDv3cgP2+A3jM7xrmlmfmzmUTRiZ9wFjP91cAN+Y+Xwbc5/luLrAj5NwqsD/QCOwE5nq+Ow+4P/f5ZuA6YHre708AlgJHAQ0FruP9wJfz2rYrd+zhwCZgdu67rwPfDdiPOx+dea8Dc9/fmHcPjMmds32xwcBf8vb3cO767Q30AxN8jnk8NkBo8qx7CTiq1M90tb4yBVEfWK+qPW5BREaJyP/kTAhbgAeAFgmOkHnRfVDV7tzHMTG33QfY5FkHsDqowRHb+KLnc7enTft4962q2wkZ0eba9L/AmTm1046NZpOcK4f8Nqh3WUSmiMhtIvJ8br+LsJFuFLhzudWzbiU2qnXIPzcjnHkqBJMwJbYyYL//hRHdX3Jmq3Ny/+13mEK5BlgnIteJyLiQ43iv+0pgGDBJVXcCtwMfyJm15mGj+dA2q2qL57XE7ziqug0jn31yr5V5+3H/c1/s3G4OON5GHezz8N53exwygqgP5Jfk/QRwAPA6VR2HmQfAYyMvAV4AJorIKM+6fUO2L6aNL3j3nTtma/DmgBHCe4E3A2OBnxfZjvw2CIP/7xXYdTkkt98P5O0zrIzyWuxcjvWsmwE8X6BNhbAB6MXMaUP2q6ovquqHVHUfTFl8V3Lhsar6HVU9DDPLzAEuDjmO9zzMyB1zQ275JoygTwS6VfXhIv6P9/yPwcysa3Ovtrxt3f9cjZ3bliKOu8cgI4j6xFhMKnfm7LGfL/UBVXUlsBi4TESaReRo4G0lauNPgFNF5FgRaQa+QOF7+UHMRHEdZprYVWQ7fgEcJCL/nhu5fwQztTmMBbbl9juNoR3qOswPMASquhr4E3CFiIwQkUMwe3hHxLb5Qi2E9nZgoYiMzTl1P46pG0TkPTLgoN+MkVifiBwhIq8TkWHAdqAHM+cE4QMiMjdH3F8AfpI7NjlC6Ae+QWH1UAj/n+ceuBz4c+7c3QPMEZH3i0iTWGjsXODnqvoC8EuM/CaIyDAROS74EHs2MoKoT3wLGImN2h4BflWm47YDR2Pmni8CP8Zs3n5I3EZVfRL4MOYUfwHrzEITnHImoJuxkeXNxbZDVTcA7wG+jP3f2cBDnk3+G3gt0IWRyR15u7gC+KyIdIrIJ30OMQ+zw68F7gQ+r6q/idK2AvhPrJNfDvwRO4c/zH13BPBnEdmGOb4/qhYaPA64HjvPK7H/+/WQY9yC+QheBEZg5OnFzcCryBFTAXTK4DyIj3u++xFG6JuAw7D7D1XdCJyKqcONmOns1Nw1A/NR9AL/wnwMF0Voxx4JyTliMmRIHbkwyX+paskVTIbagYicCcxX1WOL2MeNwBpV/WxqDcswBJmCyJAacqaI/USkQUROBt4O/LTQ7zLsOciZnS7ATH0ZqhwZQWRIE1OxMMdtWAz6+ar6WEVblKFqICJvAdZj/pcfVbg5GSIgMzFlyJAhQwZfZAoiQ4YMGTL4om6K9U2aNElnzpxZ6WZkyJAhQ03hr3/96wZVnez3Xd0QxMyZM1m8eHGlm5EhQ4YMNQURyc86fxmZiSlDhgwZMvgiI4gMGTJkyOCLjCAyZMiQIYMvMoLIkCFDhgy+yAgiQ4YMGTL4IiOIDBkyVBc6OmDmTGhosPeOoorYZigCdRPmmiFDhjpARwfMnw/duXmnVq60ZYD29sq1aw9FpiAyZMhQPViwYIAcHLq7bX2GsiMjiAwZMlQPVq2Ktz5DSZERRIYMGaoHM2bEW5+hpMgIIkOGDNWDhQth1KjB60aNsvUZyo6MIDJkyFA9aG+H666D8eNtedQoW84c1BVBRhAZMmSoLrS3wxln2OdDDsnIoYLICCJDhgzxUI48hY0b7X3FivT3nSEysjyIDBkyREe58hQcQbz4IvT0wIgR6e07Q2RkCiJDhgzRUa48BUcQkIW4VhAZQWTIkCE6ypWnsHEjtLXZ58zMVDGUlCBE5GQReVpElonIp32+v1JE/p57LRWRTs93M0Tk1yKyRESeEpGZpWxrhgwZIqBceQobN8Jhh9nnjCAqhpIRhIg0AtcApwBzgXkiMte7jap+TFUPVdVDgauAOzxf3wx8TVUPBI4EXipVW2sGWRGzDJXGwoUwfPjgdWnnKezaBVu3wqteBU1NGUFUEKVUEEcCy1R1uaruAm4D3h6y/TzgVoAckTSp6m8AVHWbqnaH/Lb+4ZyDK1eC6oBzsBBJZKSSIU20t8O55w4st7Wln6ewebO9T5kC++5r93qGiqCUBDENWO1ZXpNbNwQi0gbMAn6XWzUH6BSRO0TkMRH5Wk6R5P9uvogsFpHF69evT7n5VYYkzsGkpJIhQxhe+Up7v/BCG92nnafgHNStrTaoyRRExVBKghCfdRqw7enAT1S1L7fcBLwB+CRwBPAK4OwhO1O9TlUPV9XDJ0+eXHyLqxlJnINZZcwMpcCGDfa+fXtp9u8IYuLEjCAqjFISxBpgX8/ydGBtwLankzMveX77WM48tRv4KfDakrSyVpDEOZhVxsxQCpSLIFpbzYS1di3s3FmaY5USdWDeLSVBPArMFpFZItKMkcBd+RuJyAHABODhvN9OEBEnC04AniphW6sfSYqYZZUxM5QC5SSImTPtc60NaurEvFsygsiN/C8E7gWWALer6pMi8gUROc2z6TzgNlVVz2/7MPPSb0XkCcxcdX2p2loTcEXMhg2z5RkzCjsHyxFxkmHPg+vAy0kQteaorhPzbklLbajqPcA9eesuzVu+LOC3vwEOKVnjahHt7fC5z8Fzz8GTT8KYMYW3X7wYvvUtW25rM3LIip9lKAblUBDNzTB69ABB1Jofok7Mu1ktplrDli32vmNHYYIAOOIIex8/vvYesgzViXIQRGsriMC0adDYWHv37owZ/qqnxsy7WamNWoIqdHXZ556eaL9x23V1QWdn+LYZMhSCaukJYtMmIwiwRLnp02uPIOpk4qOMIGoJO3bA7t0Dn6P+xqHW7LgZqg/d3QODjlIqiIkTB5ZrMdTV+QxHjrTliRNrcuKjjCBqCU49QHwFAbX3kGWoPjj10NJSehOTw8yZtTm4aW+HY4+1z+ecU3PkABlB1Ba8BJFEQWQEkaFYuAijtja7t/r7S3OMfIJ4/nmr0ZQWypWj4Eh06dLS7L/EyAiilpCUIBoazP5Zi6OwDNUFpyBcKe78UM5ioepPEKqwenXgz2KhnDkK7vxkBJGh5EhqYho5sjbtuBmqD/kEkbaZads26O0dTBBpzwtRzhwFd5xnnx3wHyZApZKyM4KoJSRVECNH2kNWbwRRB6UMag6OIFy4ZtoE4U2ScygiWc73Fkk5RyH0NuzutuTW3t6i9l+ppOyMIGoJSRTEjh02n2+tOvqCUCelDGoOGzZYfsK+uTJr5SCI6dOt9405wAm6RbZNTK8ETcHbsLsbDjrIPufMTGGEkv/dokXwiU/A27s7eI6Z9NHAc8zk7d0dZUnKzgiiluCS5CC6gvCamDZtGryPWkadlDKoOWzYYCGbY8factoEsWmTvXvDXIcNK5gL4dfpfvrT/rfIZ/DJUQD48IdjN/cznylwG27fDoceap+XLg0lFL/vzjwTTljXwfXMZyYraUCZyUquZz6vX9lRchGdEUQtIamJacSIATtuvaiIOillUHPYuBEmTbIyGBCJIGJ1YjkF8ab3tQ7ePudD89uXX8d61lmwZo3/Ia7e1M4fz7qObTIGBV5snMauEWPhf/4HNm4MbK93fVsb/Od/FrgN+/qsCm1bm1UyWLo0cFzzwQ9aJGz+d6pwBQsYzeAvRtPNQhZw1lklFtGqWhevww47TOseH/2oakODKqh+/evRfvOWt6geeaTqI4/Y7+6+u7RtLBfa2uz/5L/a2irdsvrGCSfoujmv11OnPqoK+sHJP9NFi4I3X7RIddSowZdo1CgN/M1fzrpaFXQKLw7a/tljz9BtrfsO2deIEapjx/rfCiL+60G1qUn1Ftp1Ga9QUD1++J9097Dh+uIr36jjRuwctO3IkarnnGPv+ftxj2P+a+pUVd261Ra++lXVww9XffObQ9sU9OrD/0d9SCqPALBYA/rVTEHUErq6bBpGiO+krtWiZ0Gok1IG5UJapojNyzbwl2dbWfaiKYjt67eHjlrjWgIf/KkpiE1MHLT9jx+ZyYiNz7Oru3fQ9j09Nn21H1SH3iIjR5qg3r0bxrGFLYwD4P6dR3NO/w/Y619/4M6ek3iOtpft/e/Y0cEPf+j/yLW0DD2GCKxfDxd/2P74h/9rND99ag4bHl6K+E2jhokMJ/LzsbbR3zeyioD1KYrojCBqCV1d5rxrbIzvpJ4yxd7rhSBcKYPx4215woSaLGVQDhSyexcyp3jX73x+A+v6JrEdI4jRbH+5w8//zQ03BFs0V660773bX301NHZtpItx7GbYoO2f2T2TRvqZToDdyAduuuy2Nuu029rg+usH5h7yEgTAzX3t3MnbOYE/MJNVg+z98/BnwM2bhx7ju9+FAw6An9xs5rftjOKx7jlM3LaK6ZN6GDFi8D7cuCZozLNi/sKBkh2eL77Z6j8YSrUeYJC0qLXXHmFiOuEE1WOOUR0zRvXjH4/2m1e9SvUd77DPBxyg+u53l659UbFokelgEXsPs1EUwsc+Zrr68svTal1NIOgU+q0PssaNG2cmmnxzyrnnDjULDRumeszR/dpDs36Z/9IJbFQF/QjfGmQKimriCXrdQrs+y6wh60+f8ltV0OP53ZDvWlvjmbHc+fgbh+rPeNsg08zqxhm+DVtBWyxzzowZqnP5pyroe/ixns6PVEFPnPrP0Ns/8Ltvf3vgoHvvrbpoUWzzXRAIMTFVvGNP67VHEMRhh6mecorqpEmq558f7Tf77686b559fstbzBZaSaR1Vzucc47t4+KL021nCZAWLwadwvPP9+/Y43bSQa9xskUV9JN8VZvpUQW9hIXhvxmnevawRfocbdqH6HO06dnDFum4cf7b/6bpZF3ccPiQ//bTbz6rCnpe8w99b50459adv2W8Qm+hfdB++gPs/f1IrNtWRPVw/qIK+lbu1teyWBX0ndyR7KL/4x8DB77xxkH/pdh7KiOIesH++6uefrrqvvuq/sd/RPvNtGkD2553npFLJZG2c/nd77bfn3demq2MhDij+DBejPuQT5uWXqcf5zWT5zyddL/20qhf5DO+zlv3ej+LtLd58B/vbR6l72eR7/Z/5gh9/lUnDT0fO3eqiujj77w0NZLd0DBJv8v5g/cTcn/GuU5tbarHcb8qpnrG0qUKekXLl5M1+MEHB9ry0Y8m20cAMoKoF0yerDp/vurs2UYUUdDaqnrBBfb5S1+yS75tW+naWAhBdgeRZPt785vt904llQlxRvEjRwZH2kycGJ04fvAD1c99Llnn7neM1lb/bRsb/de7yKXff/wubWtT7WSc/mDsR0PNWKsb/b9Y3djmu/1zTfsFX8vp01XPOiu9i9jcrPqpT0W7sDGZaNEi1XcMv0cV9EgeUVB9gan6zBvPSdbWn//c2jJihOpxxyXbRwDCCKKkTmoROVlEnhaRZSLyaZ/vrxSRv+deS0WkM+/7cSLyvIhcXcp21gy2bDGn7MiR8Z3UUB3z+06f7r8+qWfNJf6VKAEwyFl78cX+0TnXXjt0/Y4dwZE2mzb57+cjHxnqWP7gB+Hyy/1zvMBiF/zg56y97jr49rf9naLz5/uv/9gZVmbj+He1smIFjN97NOe8bzvt7cEO1ml9/iE10/pW+W6/d3NeoT4v0qwntnOnVYcdN27wehf84BrnTlbM4If2dvjYeeak3sEo2tqg4YDZ7N+XsGify4E65hj4+99LU0XXByUjCBFpBK4BTgHmAvNEZK53G1X9mKoeqqqHAlcBd+Tt5nLgD6VqY01h5057OYKIEuaqOpBJDdUR6vqa1wxdlzA8taMDlv3VHpw/37clUuhmnKgdv+ifc86BOXPghRdiNzcW/IgDYOrUwf2XQ1jH7qYhX7HC+pUVK2zZ9YX5xPHd7/qvP+GQXB2mSZPsffTolxPlgvYlbf7EL20zhkYYXbub4d2d5SEIN6DIJwiwP3PRRca4zzyTODLuuMPsAv5j2ShWrIApx85JXtXVEcQb32htf+65ZPuJiyBpUewLOBq417N8CXBJyPZ/At7sWT4MuA04G7i60PHq3sS0bp1JzKuuUn3jG6PJzJ077Tdf/KItP/+8LV9zTUmbGojHH7cMpTe8YSB8JoIhOcymv4Z9VEEf49UFLQFxzEJhJpimJtUJE+KZZ4IibYKOEfRylrg4/o/UcOWV1oiNG2351a9WPe208N/EMdm89JJ9/53v+O/rs5+1E9zbW9z/UFVdtsyOddNN/t/feKN9v3Rp8mNce63tY+1aW/7KV2y5szP+vq64wn77hz/Y+09+krxdeaBCJqZpgLeA+5rcuiEQkTZgFvC73HID8A3g4hK2r7bgRhBxTExOZTgT09Sp0NycXlXMOOjrgw99yPIV7rwT3vY2CxZ3w9mQ4/rF8H/0ozbCHo+dl3FsGZSA5dfeT3wiulmou3ugbpzfX7nqqnij+G9/O56ZJ2gQ7SxxfoogbH0qmXIbNtjvW1ps2aMgAuGkRVOTLU+ZEmyy8SvU50Vbm538oBoacRCmIMBkIhQ3j4O7qVxZErfPZ56Jv6+uLlM0Rx5p7489lrxdMVBKgvDLGdSAbU8HfqKqfbnlC4B7VDV0hhARmS8ii0Vk8fr164toag3ASxAjRkQzMTkScSYmV0QmpaqYhfoYb5902eRr4C9/gW99yzqA8eMH15bCvw8LKoa2cSM0spsxWAc1DnvgV66EK64Y2t4zzoB162L97UDMmBHfPONMOlHNPEHEkShRPK3Kt24in4ZctxGFIMD+5IQJ9vnLXw4eEBQiiDR9aIUIYvZse0+DINzzVwzpdHUNPPsHHlg2gqgKExPwGHCMZ7kDWAWsADYAW4Avhx2v7k1M991n0vL++y3KY/bswr957jn7zQ9/OLDuTW+y2kwxkCQy1WtZ2JeVupXRem/Dybroln7b4BOfsPAen+0LmWvcq4VNqqDbGak9NBc0zwTVzYlrFkrVbBOC1MxFaYUWv/vdqgceOLD8jndYImYUOJPi5z4XvM3Pfmbb/OUv/t8/84x978kDSIy77rJ9Pfqo//f9/WZHjJpv5IdPf9oSURx6euxifv7z8ff1/verzppln884w5LlUgIVMjE9CswWkVki0oyphLvyNxKRA4AJwMNunaq2q+oMVZ0JfBK4WVWHREHtUcg3MUVREPkmJkg0L0SSwqkLFrga9m2spI1RdPPz/rew4LNCRwd84/vjYccO9m/rpaMDLrlkqFLo6yOwdk1rK0wdYedkDdMZzi5aRu7kqquC29Tfn45ZqFzVPALNRXGRVuXbDRsGj+6jKohduwbUbJhz1ZX6DlIQ++5rFyINR7V7noIUhIipiGIVhPfGGj7cbqJiFARYoMcLL6QniUNQMoJQ1d3AhcC9wBLgdlV9UkS+ICKneTadB9yWY7IMQUjDxARGEOvWRS72t2MHjBnj/92IEfClLw02C910E9xxBxyz0tWwX4UADShXsIBjVnaYtaPLbvbOVV2cfXbwdMOqwZ331y81M8EaLHT2+m9s4cILg4ueBYV7xjUL1RyCQojjhhZv2DAQwQTRCcIb4xtGEIVMTMOHwz77pEMQzsTkOl0/zJmTzF/g0N094H/w7jMJQbgQdxiIBCyDmamkeRCqeo+qzlHV/VR1YW7dpap6l2eby8LUgareqKoXlrKdNQHviCeuk9pLEAXmhfD6AfbeG/bbz55v52N0GDbMKmIuWDDYtH322fCudwXXsP8SC+juhi7sZh9PF7t3ByuFoE69vR3eeqydkxPOtNnN3n2SPfRhhV5jO3frAQsXWufqRRKHRrEE0dRUmCCamoJH9ZDe1LmFfBBgnfmqVdErJ+cjX0G4fS5dag9MHHgVhJuA6O9/T9auGMiqudYKvDe0UxCFbjJHIvkmJvAliHxf5osv2utTn4IbbxzcSd9wA+y1l/9hp0yBGfibL9x6L0FAsFII69RfJk2XfJc7R0GO37rq9OOgvd2ixhxmzIh/QlSDCaLQfeju3QMPhLVrgwc3GzfaTHJBowVIb+rcLVuMjPJLq3rhHNXLliU7xvbt/gSxdWt885CXIFpa7DzUuoLIkCK6uuxmGzbMFEF/vw3hw+CnIEKS5fxq96vCbbf5d9LPP+9/2PXrgxOkXG37fIIIUwqBcB2Pmx/Zk01d14ogCbxmnn/8I/4J2brV7rd8glAtrGbddXn1q+09qIPfGJJF7TBzptkjC937hbBliw22wsiomLBUCFYQSfbpJQgwM1NGEBlehvcGcR1+Ienr56Tee29oauLJX6wY5Dv43veCn9sgX2aoaTvArLFi/kJGjRpMEAWVQhCcgvAhiAwe9PXBn/40YE4JSvAIw4a8LGqIPu2oIydHEEFmpigEsW6dkUNzc3EzHzmCCEOxoa5hBBFnn6qDfRBgBPHMM8E1XFJCRhC1Ai9BuA6/EEHkRnbHnzJyILfgtka2TpzBk/esHOQ7OP/84N0EEUHopG7OwwuDJMGx323nuutgzD72X/Zr7Upu/nGEkGdiypCHxx+3juStb7XlYggiP4oJChOEuy6HHGLvQT6EQgTR0QGLFtnnYvI5XJsKEcTYsZZcWgxB5DupZ8wwcouzz23bbNSUTxBg17aEyAiiVuCnIApI+0fuNwJZtnbkoOfpsU0zmd63Ysj248fHS84qaOvfbz977+4eJAna2+GBx+2/fOPSruTmn64usyO7aVgzgvDHgw/a+zveYe+VUhCvfKV1jmEKYuJE/+/AbKBuOjiHsPlLwxCFIKC4SCY/BdHYaM9FHILwRjA6OIIosaM6I4gqhG9VhBAFEVRF4Zd32Pc9DJiYurtt+saZrBhy3C1b4vsBQs1CGzZYjKyfI9D9l7xs6ljo6rKH3O0rIwh/PPigXUxn4nH5BnFQDEF4Q0rb2oIJYtOmcAWRVj6Ha1MUgigmF8LPSQ3xQ139CGKffWDy5JL7ITKCqCCiVhCdPx+6VnexsnM8M2fCO99vCuKeO3p8tz/3XDj1VNix2RTGDgbPZ7uSNvbhBYYzWIG4EhKpOXfzo168cM72YgjCW/68sbHk9tiahKoRxBveMND5lltBOIIYMwZmzfIniO5uU8RhBJFWPodrU1QF8dJLye5TPwXh9rlsmfmGosAvqU/Ewl0zgqhP+HXsH/ygrfOrPbTjhS7uWzyelSuhO9fhf+WyHVxwwdDte3rgF7+AcU1DFQTAhjEzAdjXU0sxcZ2fMIQRBPjWY4oFp6pE7OGJoiDSKFpXS1i61Dq4444bKLKXhCA2bjQS9o5i45iYRo+23wcRRKEkOSjg9IoJpz4LoZhIJj8fhNvnrl3RlY+fggAzM/3zn7avEiEjiArBL6R0507/OQAAxrKFzn67oV2H39i7I7BPFIF3ntLDLobRz8BMMqNGwTsvmgnA66asKG2eQKkJwjsKjEIQaRWtqyU4/8Mb3gTbLf4AACAASURBVGD+mpaW5Api0qTBYaFxFIS7TrNm2fHz1V4UgnBOL9dR7rtv8hs3jokJ4puZ+vttpBakICA66YQRRG8vPPVUvLbFQEYQFUIcs2kTvYym++XQUGcyGkGwk3rGDDjoFTtg5MghPoU3n2vZ1Iu+uKK0eQLlUhAQjSD8WDmpk7NW8OCDZqs+4ABbbm1N7oPI77yTEITLw8lXEVEIAgZIAuCuu5LduK42VFiZDYf99rOHJ66CcPdZGEFEJZ0wgoCSOqozgqgQgrKQW1uH3lNTR1rH5wjCKYiR7PDd/mXVvWMHzWNHDPUpTJtmcr/UU4+WgyDiKIg0nZy1ggcfhGOPHRj5t7YWpyC8iGNiGjvWPs+aZe9JCQLg4IPt/Z//LLxtUHsgmoIYMSJZgb0wgthrLzsfUfcZVDdq//3tGpTQD5ERRAXQ22s+2vwkzqAKolcvtE60p3mwghjf3BNecdQ73agXTU0mz0s59eiuXfYghj3waZiY4iiINJ2ctYDnn7eO+A1vGFg3cWL5CSLfxATBBBEW5uowe7Y9QEkJIkodpvzjJVUQfj6IH/3Ins2rrormB+vqMp9ZftXMxkbLLckIor7wzW9atYCPfjRaBdG3H2+d6PvPH09bG/TkCGL+GTvCK47u2OFPEJBe0bMguAe+VApCNb6JaeHCoeejJN75KoHX/+CQpoIYOdJu3jgEMWmSdZr5914cBTFsmJnMnnwyUtN92wPRCSJJgb0gBeH8YL29thzFD+aUsl9ZkNe8xkxM/f3R2xYDGUGUGc8+C5ddBu98J1x5ZcSQ0lwn+sbTxrNiBaxebyamo14dodRGUDGytIqeBcEvLDIfxRBET4+VXHAP+dixhQmivd3qkzuMHVvfVfwefNBGna76JyQjCFX7Tf61FLEOMI6JScQ/kmnTJiOO/PIsQTj44PIqiK4uKzIWFUEEkcQPll+HyYvXvMbO7/Ll0dsWAxlBlBGqcN55lkwaNrHNEOQ7qSJmUgeamMAI4vnnSxciF4UgWlrs4XCjqTjIPydRw1zdaLqpyWy49UoOYARx9NGDa7W3ttp5inPOu7osZt/vWkYp+Z0fMeRHEFHqMHlx8ME2qtq2LfpvvO2BeAoC4pmZ3DnJJ4gkfrAwgnjxxYE2liBsOyOIMuLmm+G3v7VpeadNi/HD/M4wai2mQiYm1eCZeopFVAUByVRE/kM+bpw9lIWSj9zo+bjjrI5NNWRflyI3Y9MmG2Efd9zg9a4T3rw5+r786jA5FCII1cEKAgYIwmuySUIQkCzEMylBxHFUBymIJH6wIILo6LAJ2KFkYdsZQZQBHR3mEz77bFPQ3mclEvIJorHR7LBRFESQicnVuJ89uzQJY6UmCD8FAYVHlC7E87TTzLb3yCPxj50mSpWb8dBDtj+v/wEGnMBxzExh17IQQezcaWolX0Fs2za4DXEJ4qCD7D2JmSkuQbS1mQpLQhD5TuokyX5BBFGGsO2MIEoM9/yvWWPLO3eamSnW8+93Q0eZlzpIQXR0mAMESpcwFjbqdCgFQRRSBI4g3vpWI1rnyK0USvWQP/igDSKOPHLw+iTlNoohCL971y+SKS5BzJpl93Y5CKKpyfIh4piYghSEy+NwJoSJEwv7wYIIogxh2yUlCBE5WUSeFpFlIjJkWlERuVJE/p57LRWRztz6Q0XkYRF5UkT+ISLvK2U7S4lUnv+uLpMeXgdelHmpg5zUCxYM/W3aCWMbNthNPWxY8DZpm5i864PgCGLGDHPe/vGP8Y+dJkr1kD/4IBxxxNABguuE4yTLFUMQLucg38QEQwkiSoirQ2MjzJ2bjCC6usxZ7heCGoS4BfaCfBBgZOAU/Mc/XtgPFlQWpAxh2yUjCBFpBK4BTgHmAvNEZK53G1X9mKoeqqqHAlcBd+S+6gbOVNWDgJOBb4lIS6naWkqk8vz7jSCizEsd5KQuR8JYoSQ5qJyCGDPGIgWOPRb+/OeS1rIpiFI85N3dsHjxUPMSJFMQYSHLaSiIvj7zicRREGB+iCShrlFmk8vH7NnWqUcNJw1LlAMbuI0ZUzgyKj+c24s0a1MFoJQK4khgmaouV9VdwG3A20O2nwfcCqCqS1X1mdzntcBLwOQStrUkWL/e/I5+iPX8+90gURWEH0EEHdzNzJYGSk0QSRWEd6R67LF2jsowdWMgSvGQ//nPFgLsRxBJfRDDhvk7z5IQxNixRgYuF6Kz0zrCuARx0EE2x3Xc0iH5s7NFwZw5dq8EzbObj0IEAVYCxamzsP309fm3twyTr5eSIKYB3hCZNbl1QyAibcAs4Hc+3x0JNAPPlqCNJUNvL7z73Xbd8q08sZ//pAoiyMTk1ymBjezSSrjxq92TjzQURBITk5cgoLJmJveQO1Pc5MnFPeQdHZZkA/D//t9Qv9LYsWZTj0sQra3+I+4kJiawwAinIFwHn0RBQHwVEbVQnxdxi/Z1d9s1DTOxTp5cWEEE1WFyKPHk66UkCD/9FpSKeDrwE1UdFKMoInsDtwD/oapDei4RmS8ii0Vk8fo4SSxlwEUXwQMPwI03wve/XyTJBxFEmIJQNY+4n4LIH3nMmGGdyh/+AMcfb+uLDbn0S6zKR7EEMXr0QIx/EoKYOtVyISrtqG5vt3MO8MUvFkcO8+cPnM81a4YGH4jET5YLU4NJFAQMzoWIk0XtRTkJIm4uRNBcEF6kQRAlRikJYg3gtVlMB9YGbHs6OfOSg4iMA34BfFZVfWMRVfU6VT1cVQ+fPLmyFihvKHtrK3z3u3Dxxf6lM2I//0lMTE5dBOVBeBu1ciXccQf8+79bZ7lqVfHRTVFMTMVMGpT/kMchCG9HdOyxpiDilFEoBVy7X3gh+T6iRkTEreiaBkHkK4hZswbuv6QEMX26Xfe4juokBLHPPtbhR1UQQbPJeTFpUmGCCCrUVyaUkiAeBWaLyCwRacZI4K78jUTkAGAC8LBnXTNwJ3Czqv5vCduYCvJD2TdtMqJ41atSOkASE5P7LigPwg9//evQdUmim3bssAekEEFA8nIb+efEFTKL44MAI4iNG+Hpp+O3IU2kQRBRgw/SVhC7dwc7+oMqp86aZb954YXkBCFifohyEERDg6nNOCamKApiw4bwwUm9KghV3Q1cCNwLLAFuV9UnReQLInKaZ9N5wG2qg87Se4HjgLM9YbCegjLVBb+BW38/fO5zKR0giYJw3wUpCD+kFd0UpVCfQ1KCyH/IGxutswojCMfe+QQBlfVDuPkJoDiCiBoRFbeia5i5sFBF1y1b/ENKvZFMcSq55sPVZIqjAJMQBJiZKY6JqVAY7eTJdt3DFFi9EgSAqt6jqnNUdT9VXZhbd6mq3uXZ5jJV/XTe7xap6jAXApt7lW5WjCJR0qjRvj7LOs2/oQspCEcQcRREWiGXUbKoHdJSEFC4HtPWrXY+vR3RnDn2oKbph4hbOsM7u5qrrZMEF100dJ1fREQcBeFMQEkJwpXZyHdw5xNEQ8PAlKhxcPDB9vuXXor+m6QEMXu2FcXbvbvwtlEVBISbmeqZIPYUlDRfxXUecZ3UhXwQfkgr5LJcBJH/kI8bN3QqSy/8omVEBvwQaSBJ6QxHao2NxSkI99+nTQuPiIjjg+jsNJIIMv9EURB+nbFzyjuCmDAhOCY8DHFLbvT1WVuTEMTGjUYOzc2FiT+qDwIygqh3RB24JULQDVIKE5OLbnI37t57Jwu5LAdB+MWyF1IQrlPMN2Uce6yNDNcGxVDEQJLUedfmV7zCFEQSh7mqhcydcIJFL4VFRLS22gAiaAJ0Lwpdy6QEMWKEOX4dQcT1PzjEnV0ubpkNh44OuOkm+xyF+OMoiLBcCJf1HbuAWzrICKJI9Pfb1LjDhxceuCVCEEGUwsQE1uh77rHP116b7E9Uq4kpyNbt/BAPPRS/HflIYm90I/85cyyBJsmc0X/8o5HcWWcV3jZOslyxBJFfydULF8mUH1kWB1OmWNuihromJYgFCyxs3Isw4o/qg4DCCmLs2GTqKgVkBFEkvvc9+P3vbX6HQgO3RCikIIJGm0lMTA5O/iedUGjDBmPKCRMKb5uEIIL8MkkVxGteY6O9NMxMQdnoYfZG1+YDDrD3JGamm26ySK53vavwtnHKbZRKQcBALkQxCiJuJFNSgohL/Gn6IJKYw1JCRhBF4Lnn4L/+C046Cc49t0QHCVMQEBxemMTE5DB5sv2uGIJoaRk8UU0Qxo+PP2lQkF8mKUEMGwZHHZWOo9pvBF/I3lgsQXR3w+23W+p+lAJ0cQiiUERasQSxejWsW5ecICBeJFPSvIK4jsYoBDF2rPkzChFEhfwPkBFEMApEovT3wznn2NfXXx+v7lcsFCKIID9EkjwIB5ddnZQgomRRO7j/FWfinvwyGw5JCQLMzJTGBEL/+MfgDO8o9sZiCeLOO400zz472vZxKrqW2sTU32//N0mIq8PBB9txokx+lVRBxA3giOKkFimcLJcRRBUiJBLF8UZjI9x/P7z3valW1x2KMBMTBBNEMQoCipuzOkoWtUOSchtBo0BHEEEjybB5j3futM6qpSV5iZGlS80h9bGPwRvfCMccE83e6P6PK+cQN9T1xhuts/UrzueHuCam5uZgZVKMgpg5c2ibkiBOyY2kBOECOJqbbTmM+Pv7bYBWiCCgcMG+aicIETlVRPYsIgmIRNn20QUv84bDrbemPxnbIBRSEEGO6qROaoe2tuoliKBzMnas+SeCSDNozoGODvjOd+xzMSVGrrzSzFUXXmhEE/U/uWSyqVOtw42jIFavtnlszzwzuiMzrpN60qRgiRxGEH7TjXrhciGgOIKIE+qalCDAyODEE+Hww8OJ391/Ucx9heoxVTtBYCUynhGRr4rIgaVuUFUgwPE0auOqUs/wNxRbtlink9/RF1IQxTipwQhi/fpooZD5KJeC8DMxeb/PR34WtUMaEyitX28j+TPPhL32sv/V2Rntt975CfbeOx5B3HKLdcRnnhn9N8OHW+cVhyCC4EbJfgTR3W2j6aDOePp0k+JQHEFMmGAhs6UmCDDiL3Rdo5T6dihEEElKk6eIggShqh8AXoOV274hN9PbfBGpTGBuORBgM1pFwPoU59kZAhfFkD+Ci6ogiiEIiK8iVCunIJISRBqp8Ndea9fi4x8faFscBeHaHocgXO7DccdZDkUcRE2WK3QtGxttsOJHEIU646amgWetGIKA6JMHuTa52l1xMWFCYYIIm00uH/Xgg1DVLcD/YZP+7A28E/ibiPxnCdtWOQQ4pL7Z6u+QKrkPwu8GKeSkduv97O1RkJQguruto6ykggjKpg6Kty82FX7HDrj6apvn+sCcyG5psVDcKGUZvAQxdWo0H0RHh5HJM89YxxjXHBa13EaUgIOgiq5Bc0E4dHQMJCd+4APF2WoPOgieespMjGHYsqW4vIKWFpv9LixiKq6C2LLFPxqxp8fWVzNBiMjbRORObDKfYcCRqnoK8GrgkyVuX2XQ3g5f//rA8rRpcN11vO7b7UPuq5Rn+BuKIIKIYmIaMSJ5eFVSgoiTJAfVoSCKLTFyyy02Cvyk53GIE53lOi2IpiBcEMW6dba8cWN8n0nUgn1R1GAQQYQpCPcfXPLZCy8kLy0PpiB27Bg8z7Ufis0raGkZKNcRBEcQUX0Q4O+ornCZDYimIN4DXKmqh6jq11T1JQBV7QbOKWnrKokTTxz4fMMN0N7OSSfZwMFZfEoww99QFFIQYSampOYlMJtuU1P1EkRj49BOPYwgVIOd1C5CZZ99bLm1NfqF7e+Hb34TXvtai1xycIXnovgh8k1MW7eGd0BJynnkI4qC6OuLluWchCDS+A9erFlj73PmhEehJS3U5xDlusZVEOBvZqoRgvg88Be3ICIjRWQmgKr+tjTNqgJ4b4BlywD4yU+sn3nggZLN8DcUSRVE0HSjUdHYaFnBpSaI5mZrZ1wTk59fJowgnLknKN6+vd1Gnw0NcP750S5sR4eZhJ5+2vwVP/rRwHdxiC+fICDczJSGzyQKQThTSilMTGmWQO7ogC9/2T4XikIrliBcdYC0CCKsYF+NEMT/At7pPvty6+ob3hsgVwP+1lvNxHzIIWVsR1IF0dNTnIKAZKGujiDiOB3jltsIOidhBBGWJOfgqnRGqfnvTCTuwd6wYXCnFEdBbN062AcB4WamNMoHt7YaAQTNQd7RAa9+tX2+/PJw008SBZFmCeQ4UWhpKYjNm4O3ieOkrgMTU5OqvuxByX1uLl2TqgTuwR4xApYtY/Vqq8Qwb14Js6b9UIyTuhgFAckIIs5kQQ5xCSLoIY9CEIWIa86caLOGFTKRFKsgwghi4cKhZUziOsMmTjRy8GufIz/nQM4nv3wUIgg/BZFWaXmIp0aKDRuthImpymsxrffOACcibwdCUv/qBO4GOPRQeOYZbr/dFufNK2Mb+vuDb+goTuo0FMTzzwfXe/LDhg3xJ39JS0EMH24qIKmCAJsU5plnCtf1KdQpRVUQ/f2DFUQUgmhvN59HU1NyZ1hYNnVc/0AhE5NfB+f8Pm1txTv04qiRcvogojipJ060/1/DJqb/B3xGRFaJyGrgU8B5pW1WFcDdAIcfDsuX8+Mf9XH44TYtbdmwfbt1VJVwUoM9tKoDDsAo2LDBbnqXABUFaREEBNdjijqt5ezZ5q9wEUJBKNQpRVUQ7hq7Tqu11Tr+QqGuPT1w8snJnWFhBBHXPxCmIJqagpVse7u1vViHXhw1Um0+iMZGuxa1ShCq+qyqHgXMBeaq6jGquizKzkXkZBF5WkSWicinfb6/0jPn9FIR6fR8d5aIPJN7RShynzI6Oy2D+ZBDYNcuXvrb6vKqBwiXmC6/odQmJohnZoqTJOeQlokJzJxRrIKAwmamhQuHxtJ7OyXXvkL/K99O39BgmdhhCqK/31SOq92UBGEEEdc/MHq0kWo+gqYbTRtOjbj/tM8+/mokX60lgeus0/JBQHCyXI2YmBCRtwIXAB8TkUtF5NIIv2kErgFOwchlnojM9W6jqh9zc04DVwF35H47EYueeh1wJPB5EYkwuUCK6Ow0OZnrMGazjPe+t6wtCB9BNDQYSZTSSe2KqVUbQSRREFEJwnW6hRzV7e3WhtGj/U0kTU2WrVvIxOTnyC2UC7FmjQ0A0iAIv2zquP6BMAVRrs6tvZ2X7cC33OKvRhyJFdOmKNe1u9u2GzYs2j6DCvZ1dQ2uDFwBREmU+x7wPuA/AcHyItoi7PtIYJmqLs85tm8D3h6y/Tzg1tzntwC/UdVNqroZ+A1wcoRjpoccQej+RhCn7P8M06cn3FfcSewdCknMsHmp0zAx7buvdX7VRhBhHU8YQYwaVVhVzZhhD3YhgujstFHkpZcGm0ii/K8kBOHUTTEEEVawz43I3ci/kH9g9GjzU+VnjZeTIKCw4i22DpNDoXpMUWaT8yKoHlOF6zBBNAVxjKqeCWxW1f8GjgYCps0ahGmAt0D7mty6IRCRNmAWlq0d67clQ44gHn9pb7oZyYltEUIf/ZBkEnuHQgQRNi91Giam5mbrrMpBENu3RytLUaj8wLhx/qU2grKo89HUZHWNChGEq/vjSk37IUphN79Oq1C5DUcQbv6IJGhpMQIIyoV4wxvsfr322sL+gaCKrmGVXEuBQgOatEw2UQgiqnkJggmiwnWYIBpBOBtGt4jsA/RinXkh+Bkeg0JDTgd+oqqukEqk3+aKBi4WkcXrwwpeJUGOIG67vYFn2Z9XNkVyuwxFMRmjURREKU1MEC/UNW6hPoc4ZSkKPeRhTuqok9JECXV94gl7DyOIYhTE+vXBhLl0qXXKLuIpCRobzeEaRBBLltj7gREKOAcRRLkVhBvQBDnT01IQEyaE+yDiEsSkSXYd8nNSaoQg7haRFuBrwN+AFQyYgsKwhsFKYzqwNmDb0/P2Gem3qnqdqh6uqodPdvHEKaFrZSc/f6iFr3wFljfsT88TCRVEMRmjlVYQYASxYkW0bbdutalDkxJE1JwB72/yEWZiikoQs2db9nxQEhlYaemxY4PnoIZ4CsI70t57byPboEiqpUuNxIp1/oZVdE2LIMqpICB8QFMuE1OU2eS8mDzZ7rV80ql2gshNFPRbVe1U1f/DfA+vVNWCTmrgUWC2iMwSkWaMBO7yOcYBwATgYc/qe4GTRGRCzjl9Um5dWdDRATvWbmZtt8U8/6t/NiPWLudHtxSoFJmPXbuCHVVRMkarRUGsXh3eWTokyaKGeARR6JykRRA9PZYDEoR//tPUQ1gnXYyCgGA/hCOIYhFWsG/JEvs+ysArzMRU7gicaiCIJCYmGGpmqnaCUNV+4Bue5Z2qGsmbqKq7gQuxjn0JcLuqPikiX/Am3mHO6dtUBzKTVHUTcDlGMo8CX8itKwsWLIDxdNKJEcQy9mc4u/juJRHmvPXikkuMJPJLbkfNGHVF6YIcXkFO6r4+G8mnRRC9vdHmKEiSRQ3JFESYiWnHDmuzF1GKzjm4zjfIzKQ6QBBhiKIg/OoVuXIbfn6IXbusZlQaBBFWj+mpp2Du3GgqpVpMTBA+oCmkPqOiFE5qqD2CyOHXIvIukfh6VlXvUdU5qrqfqi7MrbtUVe/ybHOZqg7JkVDVH6rq/rnXDXGPXQzWrexhJD0vE8QzWCTTyOdj+CF+8Qur8nnBBfCDHwyMXoNitP0QVJTOIcjEVOx0o17ECXWNW6jPIW0FAYMd1arxFQQEO6rXrbOO9VWvCt+PUxBhWdlbthiRe5VmmIJ49lnr/EpNEEuWRDMvgT9B9PdbWGm5TUwzZhiJ+pFrmj6Irq5gVb2nKIgcPo4V59spIltEZKuIRPAm1i4Omm6dkFdBALxuYkQ/xJo1cNZZVuzsG98wMvj97+27r3wlesZoodr1QSamYqcb9SJOslw5CSJMQcBgM9P27dZpRCWIadOMXIMIwk1tGUVB9PYG+4lcO/P/S1jBvjRCXB2CCGL9eltfDEGkkXOQBGH3a1htqDhoaTHSDwqqiOuD8KvoumuXPcfVThCqOlZVG1S1WVXH5ZYrl9pXBlz6EZOPjiDWsg/djKT9dSEKwpvrsP/+NoK9/faBUfxBB1mCzSOPRG9IoRFEIQVRjwRRyEzgHn7vwxs1Sc7BXcNiCSLK//IjiOZm67z9RsFpE8S2bUNrbcVxUIM/QaQ1Wo8Ld78GFeobPTpeGRg/FKrHlFRBeJPlqiCLGqBgip6IHOe3XlUfSL851YHTjhtMEDPaGtjVtx8HNgV0GC7XwYWz7txpD/mjjw48yI2NcOSR8PDD/vvwQyGCCFIQaZqYRo+2jiQqQTQ2xh/1lFpBRK3k6sWcOcFzHD/xBEyZUtiB6+1IgkJSg+z0U6cGK4gpU+IVQwyCI8xNmwZUC5j/AcwHEQV+BFFoutFSoZCCSKPDjUIQcXwQw4fbefIqiCqowwTRTEwXe16fA+4GLithmyqPzgGCuPNOi/JsOWL2yxMHDYFfrsOuXUNzHY46Ch5/fOi2QUiqINI0MUH0UFeXAxHXXTV8uL2iKoh8m70XYQQRVUGA+SGWL/fPRYjioIbkCgKCs6nTimCC4HpMS5ZYBxcWwutFNSmIsWPNR1BKgihUsC+ugoChyXK1QhCq+jbP683AwUCBUpc1Dg9BvDxI3H9/cxD6TYoeNdfh6KPt94sXR2tHFAVRaic1RE+WS5Ik5xC13Eahc+LnpE5KEL29Q69hf78pizgEERbxUq0E8cpXRif6MIIot4KA4Pu12PmoHcImDervt+cvLkHkF+yrFYLwwRqMJOoXHoJ4ub+bPdtUgV/p66jVL1/3OnuP6odIamIqhYJwpULCUA6CKDQK9FMQUUt9exEU6rpypXWEUQjCdSRJFcSLLw4+51u22Lq0CSI/WS5OBBOYmhs2zN/EVAkb+owZlTMxucFZEgXh9UGkFZJbJKIU67tKRL6Te10NPAg8XvqmVRBBCgL8HZcLF0bLdZg82fYTxQ+hGs3EtHPn0HC7NJ3UYM737u7CcxhXk4JIw8QEQ6+3c1AXCnGF4kxMU6fagMQ7SnVtSYsg/Ar2bdlig6Co/geH/IqulTIxQfCAphwEEWeyIC9q1cQELAb+mns9DHxKVT9Q0lZVGp2d7G4Yxq6GkQO+QNdh+Pkh2tvhzW+2z4VmxzrqKFMQhUbj3d1mjiqkIMBIwotSmJigsJmpGgjCld/OJ4iRI+MR5l57WdRZEEFE6UALOTNdqKSfGcYvF+Lpp+29lCamf/3L3uMoCAgmiEqZmLZuHXo/pUUQLjcpjCCS+iBcv1BDBPETYJGq3qSqHcAjIhLz39cYOjvpbm6hdZIMzAmzzz7hsfHLl8OJJxaeHevoo81MUKizjSIxg6YdLYWJCcLbrGodTdwyGw5pmZgaGoZOGhQnSc5BZGD6US+eeMLOR5SOZtQoi+oK+l87d5qfI8jEBIMJYulSa9d++0X7D4UwerRF23kJIm6Iq3df1RDFBMH3a1oE0dBg96ufD6IYgti5cyB/pIYI4reAt6cZCdxXmuZUCTo72dbUMngwHBYb/+yzFhr4trcV3vdRR9l7IT9ElDhoRwD5BJG2iSkKQXR1meKptIKAofWYkhAE+Fd1jRrBBNaZh5VlCLPTO4Lw5kIsXWrmvrSUocjQZLklS8yfEJeE/BSEi04rN/zuV6fW0upwg65r3NnkHNxz4/wQXV3h0XplQhSCGKGqL88nmPtc9wqiy+t/cNh/f38T091323sUgjjkELvwhfwQUUYQQfNSp21imjDBzC1hoa5Jk+Qc0lIQMJQg4pT69mL2bPvPLpGst9dMMFEJAsL/V5id3i+bOs0IJoeJEwc7qZcssWPEncXMjyAqoR7AnyDy5/4uFkEEUYyCgAE/RBWU2YBoBLFdRF7rFkTkMCCkdkAdoLOTTdoytK+bPds/1PXuu80m/YpXFN53UxMccUQ6BFEuE5Pzq4QpiDQIYts2/zBiBzencKEHGEfEdAAAIABJREFUJw0TE9j17u+34nhg6rG3Nx5BhCmIMIIYO9Y6GUcQqqUhiHwF8dRT8c1L4G9iqlQW8OTJ9mx479e0neaFCCKJkxpqkiAuAv5XRB4UkQeBH2NVWusXnZ1s6A1QEPmhrp2d8MADcNppRMbRR8Njj4XX6KkmBQHlIQgInzRo61brKJOYmJL4RvJDXeNEMDkkVRAig3Mh1q2z/19KgujpMV9aGgRRSQUhMjTUNW2CCJo0aE9TEKr6KPBK4HzgAuBAVf1rqRtWSWhnJy/tClAQMNgP8atfWbZtFPOSw1FH2W/+9rfgbYpVEA0N6dovZ84sD0EUCgmFeCamuJVcvci/3v/8pzmd40z1mVRBwOCpR9OsweSFlyCeecYUU60rCLABjTfJsdwKIqkPwksQFa7DBNHyID4MjFbVf6rqE8AYEbmg9E2rIDo72Rzkg4DBfoi777aL65LgoiCKozqOgvBzUo8cWfyMY160tdmIyW++ZygPQUSN7PDOS71jh0WHJCGI1lYbKXoJYvbseMosqYKAwQqilASxaZMRqYtgipsDAf4KotIEUQkTU1In9dixFlHmdVLXgoIAPqSqL58JVd0MfKh0TaowenqQnp7BWdQO+WWgd++GX/4STj01XoXIqVNtRB7mh+jqsg4+TKaHmZjSNC9B4UimDRvsBh8zJtn+S6UgkmRRezFnzsD1fuKJeP4HsP+VVEF4CeLppy0iKGp9pKiYONHMptu3m/9BJBkJjRlTPSYmsPt13bqBZyPt6qgtLeYzy6/VldQHITI4Wa6GCKLBO1mQiDQCzaVrUoXRNTAXxBAF0dBg4X9OQTz0kI2q45iXHI4+urCCGDuWgUQMH4SZmNJyUDtEIYgkhfoc0lYQW7YMmJcgOUHMnm2j9+5uC1CISxAtLaZm/JzvUQhiyxY79tKl1pZiS1Xnw5sst2QJzJqV7N4ZPdruQ5fVXw0mJhgwM5XCBwFD79ekJiaoWYK4F7hdRE4UkROAW4FflrZZFYRfHSYvvMlTd91lo+aTTop/nKOOsjmPVwdMYxolZjtMQZSKIIJCXYvJoob0CULVRrRJSn17MXu2XaO//c32mURBgL/zfcsWi2oLUnveqUdLEcEEQwkiif8BBkbMroOsBhMTDAxoSmFigqGO6u5uu6ZJ/H+OIHp7bT81QhCfwpLlzgc+DPyDwYlzgRCRk0XkaRFZJiJDphXNbfNeEXlKRJ4UkR951n81t25Jrg5Uigb1EPjVYfLCW9X17rvh3/4tmVnl6KPt3U9FdHTAj39sHdPMmbbshyAFUQoT0157GRmGKYiknTCkb2Jy26ehIAB+9jN7T6IgwP9/FZpS1iXLrVlj91wpCeKll4yEkvgfYHBF19277R6spInJFcrMJ4i02hRURiXubHJeTJpkz5Hzn9UCQahqP/AIsBw4HDgRWFLodzlT1DXAKcBcYJ6IzM3bZjZwCfB6VT0IC6lFRI4BXg8cglWOPQJ4Y+R/VQyiKIhdu+B3vzMlESe81YtXv9o68Xw/hJt8yHX6K1fash9JBDmpS2FiuvVWMx987Wv+pLVxY3UpCEiHIFynfMcd5gNwgQpREVbyu5Cd3hHEww/bqLIUBOHOy+LF5swvVkFs317ZSq4O06aZedZrYhoxwgY5aSCIIJLMBeHgFESVlNmAEIIQkTkicqmILAGuBlYDqOq/qerVEfZ9JLBMVZer6i7gNuDtedt8CLgm5/hGVV/KrVdgBObrGA4Mo1xzUOQu+K5RLf6DcNdBfPOb9n7qqcmO09wMhx02VEF85jNDJxTq7h46+RCUz8TkSMs55PxIq1gTk3t4CymIhobCDkAvQRTrpHYKYvlyG13H9QFEURBBcATxQG7yxlIqiIcesvc0CKKShfochg0zkvAqiDQ73DCCiOugdpg82drp/BDVTBDAvzC18DZVPVZVrwJC0lyHYBo5UslhTW6dF3OAOSLykIg8IiInA6jqw8DvgRdyr3tVtaBqSQW5C944MWBKR9dh/OpXpgKC5oKIgvHjbXTY0GA20/POiz75EFiHKuKvINI0MfnNmOclrb4+G6kXQxBQuNyGiw0vZG3MVxDDhycnzHHjbIpPiG9egnBlVMiRO2mSEdIf/2jLpVQQf/qTvdeLgoDBoa5p+0Sck9rPB1GMggAzJ0LVE8S7gBeB34vI9SJyIhDHD+C3bX6N6yZgNnA8MA/4voi0iMj+wIHAdIxUTvCbG1tE5ovIYhFZvN5bS70Y5AiieUoAQfzhDwOfV6wI9g8UQkcH3JereahqBHDddcEjVD8iEjEiKLWCKERanZ1mfioXQRSCG7k6gmhtTR5d1dEx0Ka7745/vcNKfkepTLvXXrZdS0vx59cPzc0DpUn22Sd5p+SnIOqZIEphYnLX10VJVjNBqOqdqvo+LIv6fuBjwF4icq2IRAnbWQN4g7anA2t9tvmZqvaq6nPA0xhhvBN4RFW35YoD/hI4yqeN16nq4ap6+ORCE8hHRWcnvTKMsVN8OtiODhvlO3R1BfsHCmHBgoEicF6MHz/0BvObfMjBb17qtJ3UQSqpqQkuu8wKEAJcfnlywoTCBBHVTJCvIJKal5xpzc230dkZ/3qHKYgonZYzM82Zk27ioxfOzJRUPUD1mZjACGLNGlO4aRPE6NE2mEvTSe36sFogCAdV3a6qHap6KtbJ/x3wjUjKw6PAbBGZJSLNwOnAXXnb/BT4NwARmYSZnJYDq4A3ikiTiAzDHNRlMzF1SQuTp/g8jIVMLXEQNCrfvNmURFtb4cmHwH9e6rSd1AsXDr3phw+30ed//zeszfH+hg3JCROiKYhyEkQa17uQkzoqQcQp7xEX7vykRRDVYmKaMcP8ZmvXpk8QQaXci/VBQM2YmIZAVTep6v+o6gkRtt2NFfW7F+vcb1fVJ0XkCyLiQn/uBTaKyFOYz+FiVd2ITVL0LPAENr3p46p6d5y2JkZnJ5v9KrlCPP9AIYTNY93ebuarQpMPgf+81GmbmNrbh5LWD37g3/EmJUyIpiDimJi2bk1e6hvSud7Dhhm5JlEQHR1w//32+a67ilNnYcd46qmBz0mPUa0mJrDrVYraRn4F+9LwQTgFUenzh/kASgZVvQe4J2/dpZ7PCnw89/Ju0wecRwXQt9EIwtdiFTQZehJH9cKFNtr2jlDDTElBKIeJCYwk8onqjDP8t01CmBBNQURx1DY32/8vVkGkdb39Rpp9fdaZBnUCzrzl7g9nzoTwAUMcuGO4AcbmzcmP4SUIl01dDSYmsGtYisS9IAWRlCAmTDC/07p1A/dwhRFLQewJ2L2hMzgHws/UkqRTB/9ReZgpKQj5CkK1NHkQfghTQUmQloKAgXIbSUt9Q3rX2+9/FTLDpGnODEKax/AzMVWaILzJcrVAEI2NA4OZKjAvQUYQQ9C/uTM4izqtTt27v6impCDkK4jeXttfOQgiTcIEeyiC6hZBvPo048YNFGtLqiDSut5+BfsKmWHSNGcGIc1jNDdbB+dMTKNGxZ+VLm2MHm2RQUuW2D1VDoIoxkkNA2amjCCqEw1dIQoC0unU00S+k9qpiXLI07QJ04UO+pUU37nTXnEIwtWNSkoQkM71bmkZqiAKEUTa6qzUxxAZKPld6UquXrS1WRVeKL0Por/fnsWkTmrICKLa0bgtREFUI/JNTI4syqEgIF3CLBQSCvFMTG6q0GIIIg0kURBpq7NyHMMRRKUruXoxY8bAPBelVhDuOcwURJ2ip4em3oC5IKoV+SamUkw3Wi6EEUTc+jTjxg08vMUUEUwDYQoiaKSdtjorxzGqVUG4PJa0O92WFiMFRwzFlPp2cB1PlRBEhY2EVYbcQ7xFWl62dlQ98hWE+1wuBZEm0lQQ3g6qGhVElFwBv8ixtJHmMapRQbhIJiiNggC7X0eMSD6bnBeZgqhi5B7ivrEtofP0VBWCFES9EUQSBeFQaYJoabGseS+RV0uuQJrwKohq+V+lJAhXj8mRf9LZ5LzICKKK4S50zcgHhjqpMxOToZoIwi+but4JoppMTA6lUhDOUZ2Gienpp+39298OnwumTMgIwovcA9wQVMm1GrEnmJg6OuDcc+3zqadGe2hcZ9DcXNwDmwb8Sn47gkg6h3c1Yk81MeUriKT3W0eHVShwCJsLpkzICMKLQpVcqxEjRljug8sdqDcTk8v2dfM6rF0b7aFxnUExlVzTgt//2rLFyCHtOaYriWo0Mf3qVwPX//DD0+1s0yaIBQsGHOoOaSdHxkRGEF7kLvTwvWqIIPInDSpnHkTa8Js0KGm2r+ugKm1eAv/S0NXUiaaF0aPN3LJrV3WYmNzgQnOzDKxale6IPP+6FuukLkdyZExkBOFB/ya70KOn1RBB5M9LXcsKAoaWpUj60FQTQQQpiHolCKiO/1bqciX5kwYV66QuR3JkTGQE4UHPi53sYhjjp9ZQ55o/L3UtO6k7Ouxh+973zHZ8yikDo798FHpoqpEg9gQF4VANCqLUI/IRI6zsfVompnIkR8ZERhAe7FyXy6L2mwuiWhFkYqo1BZE/7/WqVWY/Pvjgof8lykPj5lj+2c8qHw0S5KSuZ4Kohv9WjhG5N5u6WIIoR3JkTGQE4UFvWCXXakW9mJj8zAFgETHXXx/voenogC99aWC50tEgY8ZYGec9SUFUw38rx4jcSxBpJMpVWa23jCA86N9UY3WYYKiCqFUTU5g5IO5Ds2DB0EmUKhkNIjLUt1LvBFENJqZyjMi9Bfu6u62CbXNzevuvMLJSGx5IpxHE3FpWED09NotZrYVPpjkZUxVGgwwpt7F1a3V0ommi2hQElL5cSUvLQAh2MXNBVCkyBeGBq+RaUyYmPyd1rZmXIF1zQBVGgwwq2Kda/wqi3v5bEPJ9EBlBRIeInCwiT4vIMhH5dMA27xWRp0TkSRH5kWf9DBH5tYgsyX0/s5RtBWje3sn2ppbass74Oalr6g/kkKY5oAqjQQYpiB07SjOBTaVRbSamcqDOCaJkJiYRaQSuAd4MrAEeFZG7VPUpzzazgUuA16vqZhGZ4tnFzcBCVf2NiIwB+kvVVocROzvZNaaGciDA30ldiwoC0jMHuH0sWGBmpRkzjBwq6fBraRmYn6Ie6zDBYIKopxIiYZgwwQhCtfjZ5KoQpfRBHAksU9XlACJyG/B24CnPNh8CrlHVzQCq+lJu27lAk6r+Jrd+Wwnbaejpobmvh76xNUYQfk7qWlQQaaMcpbLjwKsg6p0gXNTWnoCWFit1091tr2IquVYhSnkVpwGrPctrcuu8mAPMEZGHROQRETnZs75TRO4QkcdE5Gs5RVI6vFwttMYIws9JXasKop7h9UHUO0HU2/8Kg7fcRh2amEpJEH7ZZvlpsU3AbOB4YB7wfRFpya1/A/BJ4AjgFcDZQw4gMl9EFovI4vXr1xfX2lqs5Ar146Sud4wfb8TQ358RRD0hI4jEWAPs61meDqz12eZnqtqrqs8BT2OEsQZ4TFWXq+pu4KfAa/MPoKrXqerhqnr45GKTF3IE0TSpRgkiMzFVN8aPNzv11q31TxB7ioMaBhNEHfogSkkQjwKzRWSWiDQDpwN35W3zU+DfAERkEmZaWp777QQRcb3+CQz2XaSOnheNIEZMrTGCaGoye29mYqpueMtt1CtB3HmnvT/6aOXLm5QL3oJ9mQ8iOnIj/wuBe4ElwO2q+qSIfEFETsttdi+wUUSeAn4PXKyqG1W1DzMv/VZEnsDMVdeXqq0AW1cbQYzcu8YIQmTwpEGZiak64S3YV48E4WppOVS6vEm5UOcmppJmUqvqPcA9eesu9XxW4OO5V/5vfwMcUsr2edG91ghizPQaIwgYPC91reZB1Dv8FEQ9mWLCSmtXUzRZ2qhzgthDYtEKw5mYxrfVIEF456XOFER1wqsgtm61MtHDh1e2TWmiGsublAPeeakzgqhf9K63uSBap9dg55pvYsoURPUhX0HUk3qA6ixvUg4MG2Z+hxdesOXMB1Gf6MtVcp00uYbmgnDINzFlCqL6kO+DqCf/A1RneZNyoaUFnn/ePmcKok6Rq+TaUoMWppcVhGpGENUK77Sj9UgQVTjZTdnQ0gJrcxH8dUYQWbnvHBq3WKE+qUEB8bKCcGamzMRUfRg+3K5LvSoIqL7yJuWCt85WnRFEpiByGLa9kx3Da1E+MOCkrtXpRvcUuHIb9UoQeyomTIAXX7TPGUHUJ4b3dLJrVA0TRE9P7U43uqfAFezLCKK+0NJiJVQgc1LXK0bv6mR3rZX6dshMTLUBN+1oRhD1Ba/jMlMQ9YkxfZ1orVVydcgURG3ATS6TEUR9ISOI+kbf9h5G0oNMqFGCcArCEUSmIKoT48fD+vVG5hlB1A8ygqhvbH6uRiu5OmRO6tqAN14+I4j6gSvYB5kPoh7RtdIIYvheNUwQmYmp+jF+POzaZZ8zgqgfZAqivrFlVY2W+nYYMQL6+qzGj1vOUH3wdiQZQdQPMoKob2x/voYrucKAYti8efByhuqCy6aG+qvFtCfDEURjo9VmqiNkBMFAJddxM2qUIJxiyAiiupEpiPqE80GMGkVtlmIIRkYQwK6XjCBaZtYoQThC2LTJ3jMTU3XCqyAygqgfOOKvMwc1ZAQBQN/GOnBSQ6Ygqh2ZgqhPuGtZZ/4HyIr1AaCdNhdEc612rPkmpkxBVCcyBRELvb29rFmzhh4Xvl2t2L4dfvlL+/yb35jJqQrVxIgRI5g+fTrDYvhJSkoQInIy8G2gEfi+qn7ZZ5v3ApcBCjyuqu/3fDcOm8/6TlW9sFTtbNzSybamFibWqv0wX0FkBFGdcApCpCo7kGrDmjVrGDt2LDNnzkSq9dncuNHm3540aWBdQwNMmQKtrZVrVx5UlY0bN7JmzRpmzZoV+XclMzGJSCNwDXAKMBeYJyJz87aZDVwCvF5VDwIuytvN5cAfStVGh6ZtNVzJFQYriBEj6s5RVjdwCmLcuOwaRUBPTw+tra3VSw5giY+uUJ9Df/9AQmSVQERobW2NrcZK6YM4ElimqstVdRdwG/D2vG0+BFyjqpsBVPUl94WIHAbsBfy6hG2kowPo7OT57S3MnJlbrjV4ndSZeqhejB1rxJCZlyKjqskBBhIfo66vIJKcy1ISxDRgtWd5TW6dF3OAOSLykIg8kjNJISINwDeAi0vYPjo6YP58GI/NJrdypS3XHEl4TUy16kfZE3Drrfa+ejW1OxrJMAjNzfHW1xhKSRB+dKV5y03AbOB4YB7wfRFpAS4A7lHV1YRAROaLyGIRWbx+/frYDVywALq7oSVHEGDLCxbE3lVl4VRDZ2dGENUKNxrR3CNQs6OR6kVHh/FuQ0M6/Ltx40YOPfRQDj30UKZOncq0adNeXt7lFMK0aXZALxoaWPzSS3zkIx8prgHVAFUtyQs4GrjXs3wJcEneNt8DzvYs/xY4AugAVgErgA3AFuDLYcc77LDDNC5EVOexSHtp0H7Q52jTeSxSkdi7qixWrVK1rkd17txKtyaDH9raBq6R99XWVumWVS2eeuqpyNsuWqQ6atTgUztqlK1PA5///Of1a1/72qB1vb299mHDBtXHH1d99FF737AhnYOWAH7nFFisAf1qKaOYHgVmi8gs4HngdOD9edv8FFMON4rIJMzktFxVX57YVkTOBg5X1U+n3cALJ3Zwxcb5NGFOppms5HrmM2kiQA3Nrev1O2QKojqxalW89RkG4aKL4O9/D/7+kUdg587B67q74YMfhOuv9//NoYfCt74Vrx1nn302EydO5LHHHuO1r30t73vf+7jooovYsWMHI0eO5IYbbuCA1lbuv/9+vv71r/Pzn/+cyy67jFWrVrF8+XJWrVrFRRddVDPqomQEoaq7ReRC4F4szPWHqvqkiHwBY6y7ct+dJCJPAX3Axaq6sVRtyseXWMBougetG003X2IBNUUQXlLInNTViRkzzKzktz5D0cgnh0Lri8HSpUu57777aGxsZMuWLTzwwAM0NTVx33338ZnPfIb/+7//G/Kbf/3rX/z+979n69atHHDAAZx//vmx8hEqhZLmQajqPcA9eesu9XxW4OO5V9A+bgRuLEX7xmzyH70Fra9aZAqi+rFwofkcuj0DklGjbH2Ggig00p85059/29rg/vvTbct73vMeGhsbAejq6uKss87imWeeQUTo7e31/c1b3/pWhg8fzv/f3v0HV1Wndxx/f4gssaDihmWHGjHUBWFpIFHEHVM1Olhd2QEFXMjSKWmc7ortrMy0WKk/YrGZ6Q5M1+7KuBNXZNdiA7VAwSqsptbSWt3wKwGDVLDZlkL5VZEwoiXM0z/OufEaTn6Y3JtLznleM5l77veee+/3Czd5zvd77nmeIUOGMHLkSI4cOUJhYWFmO5YFyU610dnR20A7qrvoouAHPEBcqObPh9ra4C+WFNzW1gbtrs9qas7PdJGt+Ds07SLHxx57jFtvvZU9e/awadOmTq8zGDJkSPt2Xl4ebW1tme9YFiQ7QPTnpyrbUoHBl5guXPPnQ0tLcCFVS4sHhwzKVfz96KOPuOKK4Nv7q1atyu6b5UCyA0ScjupSgcFnEC6hchF/H3roIZYsWUJZWRnnzp3L/hv2M5l1vDRhYJoyZYpt27Yt193InauuCr4R873vwU9+kuveONdne/fuZcKECbnuRqxE/ZtK2m5mU6L2T/YMIk58ick5l2EeIOLCl5iccxnmASIufAbhnMswDxBx4TMI51yGeYCIi1Rg8ADhnMsQDxBx4UtMzrkM8wARF77E5JIuw/m+y8vL2bJly+fannrqKR544IFO90991f6uu+7i5MmT5+3zxBNPsHz58i7fd8OGDTQ3N7fff/zxx3n99de/aPczwgNEXPgSk0uyVL2NX/0qyPadgXobFRUV1NXVfa6trq6OioqKbp/7yiuvMHx478oYdwwQS5cuZdq0ab16rb7yABEXqRmELzG5OFq0CMrLO/+5777PJ0KEz/J9d/acRYu6fMs5c+bw8ssv82mYEralpYVDhw7x4osvMmXKFCZOnEh1dXXkc4uKijh+/DgANTU1XHPNNUybNo19+/a17/Pss89y/fXXM3nyZGbPns3HH3/MW2+9xcaNG1m8eDElJSUcOHCAyspKXnrpJQDq6+spLS2luLiYqqqq9r4VFRVRXV3NtddeS3FxMe+9915P/2W75AEiLnwG4ZIsC/m+CwoKmDp1Kps3bwaC2cPcuXOpqalh27ZtNDU18eabb9LU1NTpa2zfvp26ujp27tzJunXraGhoaH9s1qxZNDQ00NjYyIQJE3juuee48cYbmTFjBsuWLWPXrl1cffXV7ft/8sknVFZWsmbNGnbv3k1bWxvPPPNM++MjRoxgx44dLFy4sNtlrJ7Karpv14/8JLWLsxzl+04tM82cOZO6ujpWrlzJ2rVrqa2tpa2tjcOHD9Pc3MykSZMin79161buuecefi1MCjpjxoz2x/bs2cOjjz7KyZMnOX36NHfccUeXfdm3bx9jxoxh3LhxACxYsIAVK1awKJwJzZo1C4DrrruOdevW9XrM6XwGEQerV8OPfxxsz5njdY5d8mQpM/Pdd99NfX09O3bs4MyZM1x++eUsX76c+vp6mpqamD59eqcpvlMkRbZXVlby9NNPs3v3bqqrq7t9ne7y5qVSimcynbgHiIEudXIu9Y2Jw4f7fHLOuQEnS5mZhw0bRnl5OVVVVVRUVHDq1CmGDh3KZZddxpEjR3j11Ve7fP7NN9/M+vXrOXPmDK2trWzatKn9sdbWVkaNGsXZs2dZnfb7eskll9Da2nrea40fP56Wlhb2798PwAsvvMAtt9zSp/F1xwPEQPfII9En5x55JDf9cS5XspTvu6KigsbGRubNm8fkyZMpLS1l4sSJVFVVUVZW1uVzU3WrS0pKmD17NjfddFP7Y08++SQ33HADt99+O+PHj29vnzdvHsuWLaO0tJQDBw60t+fn5/P8889z7733UlxczKBBg7j//vszMsbOZDXdt6Q7gb8iqEn9UzP7i4h9vg08ARjQaGbfkVQCPANcSlCrusbM1nT1XolN9z1oUPC1vo6k4BfFuQHK031n3hdN9521k9SS8oAVwO3AQaBB0kYza07bZyywBCgzsw8ljQwf+hj4XTN7X9KvA9slbTGz8688SbrRo6NPzg20sqnOuQtONpeYpgL7zewDM/s/oA6Y2WGf3wdWmNmHAGZ2NLz9dzN7P9w+BBwFvpLFvg5ccSqb6py7oGQzQFwB/Ffa/YNhW7pxwDhJ/yrp7XBJ6nMkTQW+BBzo+JgjXmVTnesgLhUvLwS9+bfM5nUQUd/t6tjDi4CxQDlQCGyV9JuppSRJo4AXgAVmdt6CuqTvAt8FGJ3kJZX58z0guNjJz8/nxIkTFBQUdPpVUdczZsaJEyfI/4LXSWUzQBwErky7XwgcitjnbTM7C/yHpH0EAaNB0qXAPwCPmtnbUW9gZrVALQQnqTPcf+dcDhUWFnLw4EGOHTuW667EQn5+PoWFhV/oOdkMEA3AWEljgP8G5gHf6bDPBqACWCVpBMGS0weSvgSsB35uZn+bxT465y5QgwcPZsyYMbnuRqJl7RyEmbUBfwhsAfYCa83sXUlLJaWuN98CnJDUDLwBLDazE8C3gZuBSkm7wp+SbPXVOefc+bJ6HUR/Sux1EM451wddXQfhV1I755yLFJsZhKRjQMQVYz02Ajieoe4MJD7uZPFxJ0tPxn2VmUVeZxabANFXkrZ1Ns2KMx93svi4k6Wv4/YlJuecc5E8QDjnnIvkAeIztbnuQI74uJPFx50sfRq3n4NwzjkXyWcQzjnnInmAcM45FynxAULSnZL2Sdov6eFc9yebJK2UdFTSnrS2L0t6TdL74e3luexjpkm6UtIbkvZKelfSg2F73MedL+mXkhrDcf9Z2D5G0jvhuNeEec9iR1KepJ2SXg7vJ2XcLZJ2h+mJtoWyuiHuAAAEX0lEQVRtvf6sJzpApFW9+ybwdaBC0tdz26usWgV0rLnxMFBvZmOB+vB+nLQBf2RmE4BvAH8Q/h/HfdyfAreZ2WSgBLhT0jeAHwA/DMf9IXBfDvuYTQ8S5IBLScq4AW41s5K06x96/VlPdICgZ1XvYsPM/hn43w7NM4Gfhds/A+7u105lmZkdNrMd4XYrwR+NK4j/uM3MTod3B4c/BtwGvBS2x27cAJIKgenAT8P7IgHj7kKvP+tJDxA9qXoXd181s8MQ/DEFRnaz/4AlqQgoBd4hAeMOl1l2EZTsfY2gKuPJMNMyxPfz/hTwEJAqMlZAMsYNwUHALyRtDwuqQR8+69msBzEQ9KTqnYsBScOAvwMWmdmpJFQoM7NzQImk4QT1VSZE7da/vcouSd8CjprZdknlqeaIXWM17jRlZnZI0kjgNUnv9eXFkj6D6EnVu7g7EpZ2TZV4PZrj/mScpMEEwWG1ma0Lm2M/7pSwhO8/EZyDGS4pdWAYx897GTBDUgvBkvFtBDOKuI8bADM7FN4eJTgomEofPutJDxDtVe/CbzXMAzbmuE/9bSOwINxeAPx9DvuSceH683PAXjP7y7SH4j7ur4QzByRdDEwjOP/yBjAn3C124zazJWZWaGZFBL/P/2hm84n5uAEkDZV0SWob+G1gD334rCf+SmpJdxEcYeQBK82sJsddyhpJfwOUE6QAPgJUE5R9XQuMBv4TuNfMOp7IHrAk/RawFdjNZ2vSf0pwHiLO455EcEIyj+BAcK2ZLZX0GwRH1l8GdgK/Y2af5q6n2RMuMf2xmX0rCeMOx7g+vHsR8KKZ1UgqoJef9cQHCOecc9GSvsTknHOuEx4gnHPORfIA4ZxzLpIHCOecc5E8QDjnnIvkAcK5bkg6F2bHTP1kLLGfpKL07LrOXUiSnmrDuZ44Y2Ylue6Ec/3NZxDO9VKYe/8HYd2FX0r6Wth+laR6SU3h7eiw/auS1oc1Ghol3Ri+VJ6kZ8O6Db8Ir3xG0vclNYevU5ejYboE8wDhXPcu7rDENDftsVNmNhV4muCKfMLtn5vZJGA18KOw/UfAm2GNhmuBd8P2scAKM5sInARmh+0PA6Xh69yfrcE51xm/ktq5bkg6bWbDItpbCIryfBAmBPwfMyuQdBwYZWZnw/bDZjZC0jGgMD3FQ5iC/LWwmAuS/gQYbGZ/LmkzcJogHcqGtPoOzvULn0E41zfWyXZn+0RJzwl0js/ODU4nqHh4HbA9LRupc/3CA4RzfTM37fbfwu23CDKJAswH/iXcrgcWQnsxn0s7e1FJg4ArzewNguI3w4HzZjHOZZMfkTjXvYvDymwpm80s9VXXIZLeITjYqgjbvg+slLQYOAb8Xtj+IFAr6T6CmcJC4HAn75kH/LWkywgK3vwwrOvgXL/xcxDO9VJ4DmKKmR3PdV+cywZfYnLOORfJZxDOOeci+QzCOedcJA8QzjnnInmAcM45F8kDhHPOuUgeIJxzzkX6f43tTOhTNOUCAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Training and validation loss\n",
    "plt.title('Training and Validation loss by Epoch')\n",
    "plt.plot(train_losses, 'b-o')\n",
    "plt.plot(valid_losses, 'r-o')\n",
    "plt.legend(['Train', 'Validation'])\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Images/training_valid_loss.png')\n",
    "plt.show()\n",
    "\n",
    "# Training accuracy by epoch\n",
    "plt.title('Accuracy by Epoch')\n",
    "plt.plot(epoch_acc, 'b-o')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.savefig('Images/training_acc.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:47.917388Z",
     "start_time": "2020-11-28T00:55:47.890384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Arch(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (droput): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (lstm): LSTM(768, 512, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:47.943388Z",
     "start_time": "2020-11-28T00:55:47.938386Z"
    }
   },
   "outputs": [],
   "source": [
    "# Output directory to save to and/or be created\n",
    "output_dir = 'bert_model_save/'\n",
    "\n",
    "# Create a new directory if it doesn't exist\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Output directory\n",
    "print(\"Saving model to {}\".format(output_dir))\n",
    "\n",
    "# programatic save\n",
    "model_to_save = model.module if hasattr(model, 'module') else model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:47.958388Z",
     "start_time": "2020-11-28T00:55:47.951384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BERT_Arch(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (droput): Dropout(p=0.1, inplace=False)\n",
       "  (relu): ReLU()\n",
       "  (lstm): LSTM(768, 512, num_layers=2, dropout=0.1, bidirectional=True)\n",
       "  (bn): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc1): Linear(in_features=1024, out_features=512, bias=True)\n",
       "  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "  (bn2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc3): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (bn3): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc4): Linear(in_features=128, out_features=2, bias=True)\n",
       "  (softmax): Softmax(dim=1)\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Sanity check\n",
    "model_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:49.265384Z",
     "start_time": "2020-11-28T00:55:47.960385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Torch save for the model\n",
    "torch.save(model_to_save, 'bert_model_save/bert_model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:50.129384Z",
     "start_time": "2020-11-28T00:55:49.266387Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path of the model save and a torch load\n",
    "path = 'Data/BERT_weights.pt'\n",
    "model.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:50.272385Z",
     "start_time": "2020-11-28T00:55:50.131384Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('bert_model_save/tokenizer_config.json',\n",
       " 'bert_model_save/special_tokens_map.json',\n",
       " 'bert_model_save/vocab.txt',\n",
       " 'bert_model_save/added_tokens.json')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving tokenizer vocab and configurations for future use\n",
    "tokenizer.save_pretrained('bert_model_save/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:55:50.287385Z",
     "start_time": "2020-11-28T00:55:50.273387Z"
    }
   },
   "outputs": [],
   "source": [
    "# Testing function\n",
    "def testing():\n",
    "    print(\"\\nTesting...\")\n",
    "    t0 = time.time()\n",
    "    # Evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Save predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "\n",
    "    # iterate through loader\n",
    "    for step,batch in enumerate(test_loader):\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            lapsed = time.time() - t0\n",
    "            print('  Batch {:>5,}  of  {:>5,}. \\n  Test took {} secs'.format(step,\n",
    "                                                                            len(test_loader),\n",
    "                                                                            round(lapsed, 3)))\n",
    "\n",
    "        batch = [t.to(device) for t in batch]\n",
    "        sent_id, _, labels = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            # model predictions\n",
    "            preds = model(sent_id)\n",
    "            pred = F.softmax(preds, dim=1)\n",
    "            pred = torch.argmax(preds, dim=1)\n",
    "            total_preds.append(preds)\n",
    "            total_labels.append(labels)\n",
    "            \n",
    "    \n",
    "\n",
    "    print('-----------------------')\n",
    "    print('Testing Finished')\n",
    "    print('-----------------------')\n",
    "    return total_preds, total_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:28.192387Z",
     "start_time": "2020-11-28T00:55:50.293386Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Testing...\n",
      "  Batch   100  of    115. \n",
      "  Test took 32.914 secs\n",
      "-----------------------\n",
      "Testing Finished\n",
      "-----------------------\n"
     ]
    }
   ],
   "source": [
    "# Take testing predicitons and labels\n",
    "test_p, labels = testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:28.199387Z",
     "start_time": "2020-11-28T00:56:28.194385Z"
    }
   },
   "outputs": [],
   "source": [
    "# Convert predictions into a means that we can use to \n",
    "# generate a classification report and confusion matrices\n",
    "test_p = torch.cat(test_p)\n",
    "test_preds = torch.argmax(test_p, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:28.953387Z",
     "start_time": "2020-11-28T00:56:28.200384Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = [label.detach().cpu().numpy() for label in labels]\n",
    "test_preds = [test_pred.detach().cpu().numpy() for test_pred in test_preds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:28.958389Z",
     "start_time": "2020-11-28T00:56:28.954388Z"
    }
   },
   "outputs": [],
   "source": [
    "label_true = np.concatenate(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:29.056388Z",
     "start_time": "2020-11-28T00:56:28.962388Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.75      0.77      7106\n",
      "           1       0.78      0.80      0.79      7500\n",
      "\n",
      "    accuracy                           0.78     14606\n",
      "   macro avg       0.78      0.78      0.78     14606\n",
      "weighted avg       0.78      0.78      0.78     14606\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classification report\n",
    "print(classification_report(label_true, test_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T00:56:29.108390Z",
     "start_time": "2020-11-28T00:56:29.057388Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generating confusion matrices (Regular and normalized)\n",
    "con_mat = confusion_matrix(y_true=label_true, y_pred=test_preds)\n",
    "norm_con_mat = confusion_matrix(y_true=label_true, y_pred=test_preds, normalize='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-01T21:44:46.291276Z",
     "start_time": "2020-12-01T21:44:46.099278Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(con_mat, annot=True, fmt='g', cmap='Blues')\n",
    "plt.show()\n",
    "sns.heatmap(norm_con_mat, annot=True, cmap='Blues')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consumer trust is of the utmost importance, and much like fiat currency, the trust is what drives the market. Without customer trust a platform is doomed. It is important to implement some sort of review sort and bot counter measures in order to insure the stability of your open, semi-anonymous reviews.\n",
    "\n",
    "Here are the key take-aways: \n",
    "\n",
    "### 1. Transfer Learning\n",
    "\n",
    "Transfer learning is a must in this sort of boots-on-the-ground style deployment. Large and well-funded research labs and think-tanks have developed and open sourced this large models for this very purpose. It is always better to use a tool instead of trying to re-invent the wheel because:\n",
    "1. Cost efficiency\n",
    "2. Time efficiency\n",
    "3. Resource pipelines\n",
    "\n",
    "Pretrained model layers within these neural networks will give back time, be significantly more resource efficient, and most important cost less overall.\n",
    "\n",
    "### 2. Training Times\n",
    "\n",
    "Training length is important for BERT. We have chosen to only train for 50 epochs and have already achieved a testing accuracy, precision, and recall of 80% (+/-5%).\n",
    "\n",
    "At this batch-size (128 sequences of 80 tokens each) we are training and validating at approximately 220 seconds per epoch. At 3.6 minutes per epoch we could theoretically train 200 epochs in 12 hours. \n",
    "\n",
    "### 3. Market Backend or Customer Frontend\n",
    "\n",
    "While we have spent most of the notebook referring this as a project directed towards market places to police their own platforms. However another valid and recommended use of this technology would be producing it as a consumer facing product for any review. While this product is currently a proof of concept it is easily extensible in several forms in this matter.\n",
    "\n",
    "## Future Work\n",
    "\n",
    "### 1. Deployment\n",
    "\n",
    "Work with smaller models, such as [DistilBERT](https://arxiv.org/abs/1910.01108), that can provide a functionally smaller footprint while not sacrificing quality. (DistilBERT retains **97%** of the language understanding capabilities of BERT) This will allow a much more mobile and deployable model that could function on light-weight devices and even via webapps.\n",
    "\n",
    "### 2. Further Tuning\n",
    "\n",
    "As discussed in several places already BERT greatly benefits from increased training epochs. This would allow us to train for more time and thus further tune the model towards correct predictions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "512px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
