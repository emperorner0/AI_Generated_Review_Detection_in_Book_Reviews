{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:15:20.459427Z",
     "start_time": "2020-11-16T21:15:12.254302Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Nero_\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset, DataLoader, RandomSampler, SequentialSampler, random_split\n",
    "torch.manual_seed(42)\n",
    "\n",
    "from transformers import pipelines\n",
    "from transformers import GPT2LMHeadModel,  GPT2Tokenizer, GPT2Config, GPT2LMHeadModel\n",
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "import warnings\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:15:20.464426Z",
     "start_time": "2020-11-16T21:15:20.461427Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_calc(secs):\n",
    "    '''Takes time in seconds and returns time in Hours:Minutes:Seconds'''\n",
    "    sec_time = time.gmtime(sec)\n",
    "    return  time.strftime(\"%H:%M:%S\",sec_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:15:48.316326Z",
     "start_time": "2020-11-16T21:15:48.309327Z"
    }
   },
   "outputs": [],
   "source": [
    "client = MongoClient()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:17:01.815458Z",
     "start_time": "2020-11-16T21:17:01.813458Z"
    }
   },
   "outputs": [],
   "source": [
    "db = client['reviewdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:17:11.631468Z",
     "start_time": "2020-11-16T21:17:11.628465Z"
    }
   },
   "outputs": [],
   "source": [
    "collection = db['reciewdata']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:17:39.231478Z",
     "start_time": "2020-11-16T21:17:39.228479Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(50e6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:19:01.086398Z",
     "start_time": "2020-11-16T21:19:01.059396Z"
    }
   },
   "outputs": [],
   "source": [
    "r_idx = random.sample(range(int(100000)), 30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:21:35.399424Z",
     "start_time": "2020-11-16T21:21:34.667427Z"
    }
   },
   "outputs": [],
   "source": [
    "test = []\n",
    "ind = []\n",
    "\n",
    "reviews = collection.find()\n",
    "\n",
    "for index, review in enumerate(reviews[100000:130000]):\n",
    "    try:\n",
    "        test.append('{}'.format(review['reviewText']))\n",
    "    except KeyError:\n",
    "        ind.append(index)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T21:20:10.775463Z",
     "start_time": "2020-11-16T21:20:10.691463Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_id': ObjectId('5fb2d5d189d5902ec8a73614'),\n",
       " 'overall': 3,\n",
       " 'verified': False,\n",
       " 'reviewTime': '02 16, 2004',\n",
       " 'reviewerID': 'A1UOXCPSW03GZ6',\n",
       " 'asin': '0002005549',\n",
       " 'style': {'Format:': ' Hardcover'},\n",
       " 'reviewerName': 'CSL',\n",
       " 'reviewText': 'Using facts of computer programming and multitudes of biological research, Crichton has collaborated another page-turner on the futuristic insights of human progress.  With all of the supporting evidence, one might say that this scenario could actually occur.  Already, scientists are cloning and there\\'s nothing stopping them from making anything biologically dangerous out of genetic manipulation.\\nThe idea of the book is that technology can be too much for us to handle.  Though geniuses we are, we still make stupid mistakes.  In this case: man lives, man creates, and man gets into trouble - or really just one man gets to clean up the mess.\\nThis one man turns out to be the typical three-kids-day-care dad who knows how to program codes.  He struggles with his personal life while trying to find a new job.\\nEveryday, he encounters the same thing, kids in the bratty prattling stage, endless name calling and torment between sibling rivalries.  The children are portrayed so amusingly that they don\\'t even seem to be real.  In fact, they are the \"hell\" that parents live though.\\nFinally, we get to the big kick: the main-character\\'s wife and his pal, Jimmy, are the closest people imaginable to him.  He knows them like the back of his hand, but they are the ones who start the trouble.\\nQuestioning the rights of creation, this scenario is very unique, but like most playing God scenarios that Crichton has written, this also turns out like an action movie ready to be filmed, like the old-timer\\'s Jurassic Park.  Unlike most prescript-novels, Prey is a considerably complicated fact book in which the reader needs to truly understand and follow the fundamentals of bio-engineering.  The narration style is the key to the revelation of the plot.  And like I said: Man lives, man creates, man gets into trouble, and man might come out alive.',\n",
       " 'summary': 'Prey',\n",
       " 'unixReviewTime': 1076889600}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test1 = reviews[\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T19:36:53.072475Z",
     "start_time": "2020-11-16T19:36:46.002Z"
    }
   },
   "outputs": [],
   "source": [
    "review_data = pd.DataFrame(data=test, columns=(['reviews']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T19:36:53.073477Z",
     "start_time": "2020-11-16T19:36:46.003Z"
    }
   },
   "outputs": [],
   "source": [
    "review_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.029577Z",
     "start_time": "2020-11-13T17:07:11.022577Z"
    }
   },
   "outputs": [],
   "source": [
    "review_data.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.035577Z",
     "start_time": "2020-11-13T17:07:11.031578Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = review_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:11.040577Z",
     "start_time": "2020-11-13T17:07:11.036578Z"
    }
   },
   "outputs": [],
   "source": [
    "reviews = reviews['reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.088807Z",
     "start_time": "2020-11-13T17:07:11.041577Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewlen = []\n",
    "for review in tqdm(reviews):\n",
    "    tokens = nltk.word_tokenize(review)\n",
    "    reviewlen.append(len(tokens))\n",
    "    \n",
    "reviewlen = np.array(reviewlen)\n",
    "\n",
    "sns.distplot(reviewlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.092805Z",
     "start_time": "2020-11-13T17:07:25.089808Z"
    }
   },
   "outputs": [],
   "source": [
    "len(reviewlen[reviewlen > 768])/len(reviewlen)*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.098806Z",
     "start_time": "2020-11-13T17:07:25.093806Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Average review length: {} words.'.format(round(np.average(reviewlen), 3)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.104806Z",
     "start_time": "2020-11-13T17:07:25.099805Z"
    }
   },
   "outputs": [],
   "source": [
    "print('Max review length: {} words.'.format(np.max(reviewlen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.742808Z",
     "start_time": "2020-11-13T17:07:25.105807Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2',\n",
    "                                          bos_token='<|sot|>', eos_token='<|eot|>', pad_token='<|pad|>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.746806Z",
     "start_time": "2020-11-13T17:07:25.743805Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Max model length is {} for this model\".format(tokenizer.model_max_length))\n",
    "print(\"Beginning of sentence token {} token has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.bos_token_id), tokenizer.bos_token_id))\n",
    "print(\"End of sentence token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.eos_token_id), tokenizer.eos_token_id))\n",
    "print(\"Padding token {} has the id {}\".format(tokenizer.convert_ids_to_tokens(tokenizer.pad_token_id), tokenizer.pad_token_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:25.753808Z",
     "start_time": "2020-11-13T17:07:25.747806Z"
    }
   },
   "outputs": [],
   "source": [
    "class GPT_Finetune_Dataset(Dataset):\n",
    "\n",
    "  def __init__(self, txt_list, tokenizer, gpt2_type=\"gpt2\", max_length=200):\n",
    "\n",
    "    self.tokenizer = tokenizer\n",
    "    self.input = []\n",
    "    self.attn = []\n",
    "\n",
    "    for txt in tqdm(txt_list):\n",
    "\n",
    "      encodings_dict = tokenizer('<|sot|>'+ txt +'<|eot|>',\n",
    "                                 truncation=True, max_length=max_length, padding=\"max_length\")\n",
    "\n",
    "      self.input.append(torch.tensor(encodings_dict['input_ids']))\n",
    "      self.attn.append(torch.tensor(encodings_dict['attention_mask']))\n",
    "    \n",
    "  def __len__(self):\n",
    "    return len(self.input)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    return self.input[idx], self.attn[idx] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.255919Z",
     "start_time": "2020-11-13T17:07:25.754807Z"
    }
   },
   "outputs": [],
   "source": [
    "data = GPT_Finetune_Dataset(reviews, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.261918Z",
     "start_time": "2020-11-13T17:07:39.256918Z"
    }
   },
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .7)\n",
    "test_size = len(data) - train_size\n",
    "\n",
    "train_set, test_set = random_split(data, [train_size, test_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.267917Z",
     "start_time": "2020-11-13T17:07:39.262917Z"
    }
   },
   "outputs": [],
   "source": [
    "print('{} training samples'.format(train_size))\n",
    "print('{} test samples'.format(test_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.281918Z",
     "start_time": "2020-11-13T17:07:39.268916Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 3\n",
    "train_dataloader = DataLoader(\n",
    "            train_set,  # The training set\n",
    "            sampler = RandomSampler(train_set), # Random sampler\n",
    "            batch_size = batch_size # Trains with this batch size for memory reasons\n",
    "        )\n",
    "\n",
    "test_dataloader = DataLoader(\n",
    "            test_set, # The validation samples.\n",
    "            sampler = SequentialSampler(test_set), # Pull out batches sequentially since order doesn't matter\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:39.292917Z",
     "start_time": "2020-11-13T17:07:39.283919Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.222480Z",
     "start_time": "2020-11-13T17:07:39.295917Z"
    }
   },
   "outputs": [],
   "source": [
    "# Get config\n",
    "configuration = GPT2Config.from_pretrained('gpt2', output_hidden_states=False)\n",
    "\n",
    "# Model instantiation\n",
    "model = GPT2LMHeadModel.from_pretrained(\"gpt2\", config=configuration)\n",
    "\n",
    "# Necessary because of the custom tokens\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# Model to the GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.cuda()\n",
    "\n",
    "seed_val = 42\n",
    "\n",
    "# Setting seeds\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.227477Z",
     "start_time": "2020-11-13T17:07:45.223477Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting Parameters\n",
    "epochs = 5\n",
    "learning_rate = .00005\n",
    "warmup_steps = 50\n",
    "\n",
    "# this produces sample output every 100 steps\n",
    "sample_every = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.234477Z",
     "start_time": "2020-11-13T17:07:45.228480Z"
    }
   },
   "outputs": [],
   "source": [
    "#AdamW is a class from the huggingface library that schedules weights\n",
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = learning_rate\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T17:07:45.239480Z",
     "start_time": "2020-11-13T17:07:45.235477Z"
    }
   },
   "outputs": [],
   "source": [
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Adjusts the learning rate as the model steps through\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = warmup_steps, \n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T18:39:45.233263Z",
     "start_time": "2020-11-13T17:07:45.240477Z"
    }
   },
   "outputs": [],
   "source": [
    "timestat = time.time()\n",
    "\n",
    "stats = []\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    # training loop\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "\n",
    "    timestat = time.time()\n",
    "\n",
    "    total_train_loss = 0\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "\n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(  b_input_ids,\n",
    "                          labels=b_labels, \n",
    "                          attention_mask = b_masks,\n",
    "                          token_type_ids=None\n",
    "                        )\n",
    "\n",
    "        loss = outputs[0]  \n",
    "\n",
    "        batch_loss = loss.item()\n",
    "        total_train_loss += batch_loss\n",
    "\n",
    "        # Get sample every x batches.\n",
    "        if step % sample_every == 0 and not step == 0:\n",
    "\n",
    "            elapsed = time.time() - timestat\n",
    "            print('  Batch {:>5,}  of  {:>5,}. Loss: {:>5,}.   Elapsed: {:}.'.format(step, len(train_dataloader), batch_loss, elapsed))\n",
    "\n",
    "            model.eval()\n",
    "\n",
    "            sample_outputs = model.generate(\n",
    "                                    bos_token_id=random.randint(1,30000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=50, \n",
    "                                    max_length = 200,\n",
    "                                    top_p=0.95, \n",
    "                                    num_return_sequences=1\n",
    "                                )\n",
    "            for i, sample_output in enumerate(sample_outputs):\n",
    "                  print(\"{}: {}\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "            \n",
    "            model.train()\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)       \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = time.time() - timestat\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epoch took: {:}\".format(training_time))\n",
    "\n",
    "    # Testing loop\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in test_dataloader:\n",
    "        \n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_labels = batch[0].to(device)\n",
    "        b_masks = batch[1].to(device)\n",
    "        \n",
    "        with torch.no_grad():        \n",
    "\n",
    "            outputs  = model(b_input_ids, \n",
    "#                            token_type_ids=None, \n",
    "                             attention_mask = b_masks,\n",
    "                            labels=b_labels)\n",
    "          \n",
    "            loss = outputs[0]  \n",
    "            \n",
    "        batch_loss = loss.item()\n",
    "        total_eval_loss += batch_loss        \n",
    "\n",
    "    avg_val_loss = total_eval_loss / len(test_dataloader)\n",
    "    \n",
    "    validation_time = time.time() - timestat \n",
    "\n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T18:39:45.293263Z",
     "start_time": "2020-11-13T18:39:45.250263Z"
    }
   },
   "outputs": [],
   "source": [
    "training_df = pd.DataFrame(data=stats)\n",
    "\n",
    "training_df = training_df.set_index('epoch')\n",
    "\n",
    "training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:31:45.046163Z",
     "start_time": "2020-11-13T19:31:44.924162Z"
    }
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.5)\n",
    "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
    "plt.plot(training_df['Training Loss'], 'r-o', label=\"Training\")\n",
    "plt.plot(training_df['Valid. Loss'], 'b-o', label=\"Testing\")\n",
    "plt.title(\"Training & Testing Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2, 3, 4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:44:13.346877Z",
     "start_time": "2020-11-13T19:44:13.343876Z"
    }
   },
   "outputs": [],
   "source": [
    "params = list(model.named_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:45:54.186803Z",
     "start_time": "2020-11-13T19:45:54.181805Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in params:\n",
    "    print(param[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:48:42.171694Z",
     "start_time": "2020-11-13T19:48:42.166693Z"
    }
   },
   "outputs": [],
   "source": [
    "output_dir = './model_save/'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:49:20.881724Z",
     "start_time": "2020-11-13T19:49:20.878724Z"
    }
   },
   "outputs": [],
   "source": [
    "print(\"Saving model to {}\".format(output_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-13T19:52:16.026553Z",
     "start_time": "2020-11-13T19:52:14.581877Z"
    }
   },
   "outputs": [],
   "source": [
    "model_to_save = model.module if hasattr(model, 'module') else model\n",
    "model_to_save.save_pretrained(output_dir)\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T18:29:22.299512Z",
     "start_time": "2020-11-16T18:29:22.295509Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = []\n",
    "for review in reviews[:10]:\n",
    "    try:\n",
    "        prompts.append(\"<|sot|> \" + ' '.join(review.split()[:4]))\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T18:29:22.471508Z",
     "start_time": "2020-11-16T18:29:22.466509Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T18:29:23.021507Z",
     "start_time": "2020-11-16T18:29:23.014506Z"
    }
   },
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "gen_prompt = []\n",
    "for prompt in prompts:\n",
    "    gen_prompt.append(torch.tensor(tokenizer.encode(prompt)).unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-16T18:30:23.423455Z",
     "start_time": "2020-11-16T18:30:23.318453Z"
    }
   },
   "outputs": [],
   "source": [
    "reviewlist = []\n",
    "t = time.time()\n",
    "for x, promp in enumerate(gen_prompt):\n",
    "    t1 = time.time()\n",
    "    print('---------------------------------')\n",
    "    print('''{}: The prompt is \"{}\"'''.format(x+1, prompts[x]))\n",
    "    print('---------------------------------')\n",
    "    sample_outputs = model.generate(\n",
    "                                    promp, \n",
    "                                    bos_token_id= random.randint(1, 100000),\n",
    "                                    do_sample=True,   \n",
    "                                    top_k=30, \n",
    "                                    min_length=20,\n",
    "                                    max_length = 500,\n",
    "                                    top_p=0.95,\n",
    "                                    num_return_sequences=20\n",
    "                                    )\n",
    "    \n",
    "    for i, sample_output in enumerate(sample_outputs):\n",
    "      print(\"{}: {}\\n\\n\".format(i, tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "      reviewlist.append(\"{}\".format(tokenizer.decode(sample_output, skip_special_tokens=True)))\n",
    "    time_per_gen = time.time() - t1\n",
    "    print('This generation took {} seconds'.format(round(time_per_gen, 3)))\n",
    "totes = t - time.time()\n",
    "print('Total time was {}'.format(time_calc(totes)))\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env2",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "305.455px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
